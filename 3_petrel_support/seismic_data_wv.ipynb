{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, RobustScaler\n",
    "\n",
    "import xarray as xr\n",
    "import lexcube\n",
    "import segyio\n",
    "import pathlib\n",
    "from segysak.segy import segy_loader, well_known_byte_locs, segy_writer, segy_header_scrape\n",
    "import lasio\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tpot\n",
    "import joblib\n",
    "import ast\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.float_format = lambda x: '%.5f' % x\n",
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_rows = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal8_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal8_azr_v4.csv')\n",
    "df_bal8_v4.columns = df_bal8_v4.columns.str.lower()\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII sand','formation'] = '1_bal8_sand'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 25','formation'] = '2_bal8_25'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 20','formation'] = '3_bal8_20'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 15','formation'] = '4_bal8_15'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 10','formation'] = '5_bal8_10'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 5','formation'] = '6_bal8_5'\n",
    "well_phit_flag8 = df_bal8_v4[df_bal8_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal8_v4_flag = df_bal8_v4[df_bal8_v4.well.isin(well_phit_flag8)]\n",
    "\n",
    "ntd_top_phi_bot8_bp_v4 = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\layers\\ntd_top_phi_bot8_bp_v4.csv').drop('Unnamed: 0', axis=1)\n",
    "ntd_top_phi_bot8_bp_v4.columns = ntd_top_phi_bot8_bp_v4.columns.str.lower()\n",
    "\n",
    "df_bal10_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal10_vshclp2_v4.csv')\n",
    "df_bal10_v4.columns = df_bal10_v4.columns.str.lower()\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X sand','formation'] = '1_bal10_sand'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 50','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 40','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 20','formation'] = '3_bal10_20'\n",
    "well_phit_flag10 = df_bal10_v4[df_bal10_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal10_v4_flag = df_bal10_v4[df_bal10_v4.well.isin(well_phit_flag10)]\n",
    "\n",
    "xy8 = df_bal8_v4_flag[df_bal8_v4_flag.net == 1].groupby('well')[['xmean', 'ymean', 'phit', 'field']].agg({'xmean':'first', 'ymean':'first', 'field':'first', 'phit':'mean'}).reset_index()\n",
    "xy8 = xy8.rename(columns={'phit':'phit_net_mean'})\n",
    "xy8 = xy8.round({'xmean':0, 'ymean':0})\n",
    "xy10 = df_bal10_v4_flag[df_bal10_v4_flag.net == 1].groupby('well')[['xmean', 'ymean', 'phit', 'field']].agg({'xmean':'first', 'ymean':'first', 'field':'first', 'phit':'mean'}).reset_index()\n",
    "xy10 = xy10.rename(columns={'phit':'phit_net_mean'})\n",
    "xy10 = xy10.round({'xmean':0, 'ymean':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well traj display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "traj8 = df_bal8_v4_flag[['well','x_traj','y_traj']]\n",
    "margin = 300\n",
    "trag8_wellnames =df_bal8_v4_flag.groupby('well')[['xmean','ymean']].first().reset_index()\n",
    "trag8_wellnames['bottom_left_x'] = trag8_wellnames['xmean'] - margin/2\n",
    "trag8_wellnames['bottom_left_y'] = trag8_wellnames['ymean'] - margin/2\n",
    "trag8_wellnames['margin'] = margin\n",
    "plt.scatter(traj8.x_traj, traj8.y_traj, c='black',s=1)\n",
    "plt.scatter(trag8_wellnames.xmean, trag8_wellnames.ymean, c='red', s=5)\n",
    "for idx, txt in enumerate(trag8_wellnames.well):\n",
    "    ax.annotate(txt, (trag8_wellnames.xmean.iloc[idx], trag8_wellnames.ymean.iloc[idx]), fontsize=6)\n",
    "for idx, row in trag8_wellnames.iterrows():\n",
    "    rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "for wellname in traj8.well.unique():\n",
    "    traj8_well = traj8[traj8.well==wellname]\n",
    "    traj_lenght = ((traj8_well.x_traj.iloc[0] - traj8_well.x_traj.iloc[-1])**2 + (traj8_well.y_traj.iloc[0] - traj8_well.y_traj.iloc[-1])**2)**(1/2)\n",
    "    df = pd.DataFrame({'well':[wellname], 'traj_lenght':[traj_lenght]})\n",
    "    df_lst.append(df)\n",
    "result = pd.concat(df_lst).sort_values('traj_lenght', ascending=False)\n",
    "result.head(15).round(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDOBN_Bal8 uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'attr/HDOBN8/'\n",
    "def list_files_by_mask(directory, mask, exclude_mask=None):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    # Filter out files that match the exclude_mask\n",
    "    if exclude_mask:\n",
    "        exclude_pattern = os.path.join(directory, exclude_mask)\n",
    "        exclude_files = glob.glob(exclude_pattern)\n",
    "        files = [file for file in files if file not in exclude_files]\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "files = list_files_by_mask(path, '*', '*.xml')\n",
    "full_files = list_files_by_mask(path, '* 0-80', '*.xml')\n",
    "full_files, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare current data with nadir maps RMS\n",
    "path1, path2 = r'C:\\Petrel\\seismic_data_wv\\attr\\HDOBN8\\RMS amplitude 0-80', r'C:\\Petrel\\seismic_data_ndr\\input\\Bal8_RMS'\n",
    "def comparison_wv_ndr_attr(path1, path2):\n",
    "    path_wv = pd.read_csv(path1, delimiter=' ', skiprows=20, names=['x', 'y', 'attr_wv', 'column', 'row'])\n",
    "    path_ndr = pd.read_csv(path2, delimiter=' ', skiprows=20, names=['x', 'y', 'attr_ndr', 'column', 'row'])\n",
    "    path_xplot_wv_ndr = path_wv.set_index(['x','y']).join(path_ndr.set_index(['x','y']), how='inner', rsuffix='_ndr').reset_index()\n",
    "    sns.scatterplot(data=path_xplot_wv_ndr, x='attr_wv', y='attr_ndr', alpha=0.5)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(18, 6))\n",
    "    ax[0].scatter(path_wv.x, path_wv.y, c = path_wv.attr_wv, cmap='coolwarm', s=1)\n",
    "    ax[0].set_title(path1)\n",
    "    ax[1].scatter(path_ndr.x, path_ndr.y, c = path_ndr.attr_ndr, cmap='coolwarm', s=1)\n",
    "    ax[1].set_title(path2)\n",
    "comparison_wv_ndr_attr(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare current data with nadir maps MA\n",
    "path1, path2 = r'C:\\Petrel\\seismic_data_wv\\attr\\HDOBN8\\Minimum amplitude 0-80', r'C:\\Petrel\\seismic_data_ndr\\input\\Bal8_MA'\n",
    "def comparison_wv_ndr_attr(path1, path2):\n",
    "    path_wv = pd.read_csv(path1, delimiter=' ', skiprows=20, names=['x', 'y', 'attr_wv', 'column', 'row'])\n",
    "    path_ndr = pd.read_csv(path2, delimiter=' ', skiprows=20, names=['x', 'y', 'attr_ndr', 'column', 'row'])\n",
    "    path_xplot_wv_ndr = path_wv.set_index(['x','y']).join(path_ndr.set_index(['x','y']), how='inner', rsuffix='_ndr').reset_index()\n",
    "    sns.scatterplot(data=path_xplot_wv_ndr, x='attr_wv', y='attr_ndr', alpha=0.5)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(18, 6))\n",
    "    ax[0].scatter(path_wv.x, path_wv.y, c = path_wv.attr_wv, cmap='coolwarm', s=1)\n",
    "    ax[0].set_title(path1)\n",
    "    ax[1].scatter(path_ndr.x, path_ndr.y, c = path_ndr.attr_ndr, cmap='coolwarm', s=1)\n",
    "    ax[1].set_title(path2)\n",
    "\n",
    "comparison_wv_ndr_attr(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 300\n",
    "df_attr_map = []\n",
    "df_attr_well = []\n",
    "df_attr_intersect_map = []\n",
    "for file in full_files: \n",
    "\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter, skiprows=20, names=['x', 'y', 'value', 'column', 'row'])\n",
    "        # seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seismic_map = seism_upload(path + file, ' ')\n",
    "    seismic_map['path'] = path\n",
    "    seismic_map['attr'] = file\n",
    "    print(f\"seismic map <{path + file}> is uploaded\")\n",
    "\n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seismic_map_intersect = intersection_maps(seismic_map, df_bal8_v4_flag, 1500)\n",
    "    print(f'seismic map <{path + file}> is intersected with wells')\n",
    "    df_attr_intersect_map.append(seismic_map_intersect)\n",
    "    \n",
    "    def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        df_seism_map_zone_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            \n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({ 'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'xmean':row['xmean'],\n",
    "                                'ymean':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin':margin,\n",
    "                                'field':row['field'],\n",
    "                                'seism_att':file}, index=[0])\n",
    "            \n",
    "            df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "            df_seism_map_zone['well'] = row['well']\n",
    "            df_lst.append(df)\n",
    "            df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "        result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "        seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "        seism_map_zone['seism_att'] = file\n",
    "        return result, seism_map_zone\n",
    "    seismic_wells, seismic_map = seism_well_correl(seismic_map_intersect, xy8, margin, file)\n",
    "    # seismic_map_intersect.loc[seismic_map_intersect.value <= 1.65, 'value'] = np.nan\n",
    "    print(f\"seismic map <{path + file}> to wells dataset is done\")\n",
    "    df_attr_map.append(seismic_map)\n",
    "    df_attr_well.append(seismic_wells)\n",
    "\n",
    "df_attr_well_full = pd.concat(df_attr_well).reset_index(drop=True)\n",
    "df_attr_map_full = pd.concat(df_attr_map).reset_index(drop=True)\n",
    "df_attr_intersect_map_full = pd.concat(df_attr_intersect_map).reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "cb1 = plt.scatter(seismic_map_intersect['x'], seismic_map_intersect['y'], c=seismic_map_intersect['value'], cmap='coolwarm', s=1)\n",
    "plt.colorbar(cb1)\n",
    "plt.scatter(xy8['xmean'], xy8['ymean'], c='black', s=1)\n",
    "for idx, txt in enumerate(xy8['well']):\n",
    "    ax.annotate(txt, (xy8['xmean'].iloc[idx], xy8['ymean'].iloc[idx]), fontsize=8)\n",
    "for idx, row in seismic_wells.iterrows():\n",
    "    rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.title(path + file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "seism_map_zone = df_attr_map_full[df_attr_map_full.seism_att == 'RMS amplitude 0-80']\n",
    "cb1 = plt.scatter(seism_map_zone['x'], seism_map_zone['y'], c=seism_map_zone['value'], cmap='coolwarm', s=1, alpha=0.5)\n",
    "plt.colorbar(cb1)\n",
    "plt.scatter(traj8.x_traj, traj8.y_traj, c='black',s=1)\n",
    "plt.scatter(seismic_wells['xmean'], seismic_wells['ymean'], c='red', s=1)\n",
    "for idx, row in seismic_wells.iterrows():\n",
    "    rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "for idx, txt in enumerate(xy8['well']):\n",
    "    ax.annotate(txt, (xy8['xmean'].iloc[idx], xy8['ymean'].iloc[idx]), fontsize=8, c='black')\n",
    "plt.title('Average negative amplitude 0-80');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in df_attr_well_full.seism_att.unique():\n",
    "    seismic_wells = df_attr_well_full[df_attr_well_full.seism_att == att]\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "    sns.scatterplot(data=seismic_wells, x='phit_net_mean', y='mean', hue='field', ax=ax[0])\n",
    "    sns.scatterplot(data=seismic_wells, x='phit_net_mean', y='p25', hue='field', ax=ax[2])\n",
    "    sns.scatterplot(data=seismic_wells, x='phit_net_mean', y='p50', hue='field', ax=ax[1])\n",
    "    sns.scatterplot(data=seismic_wells, x='phit_net_mean', y='p75', hue='field', ax=ax[3])\n",
    "    plt.suptitle(f'Seismic {att} vs wells')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDOBN_Bal8 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# margin = 300\n",
    "# for file in files[:4]:\n",
    "#     if ' 0-80' not in file:\n",
    "#         def seism_upload(file, delimiter):\n",
    "#             seismic = pd.read_csv(file, delimiter=delimiter, skiprows=20, names=['x', 'y', 'value', 'column', 'row'])\n",
    "#             # seismic = seismic.round({'x':0, 'y':0})\n",
    "#             return seismic\n",
    "#         seismic_map = seism_upload(path + file, ' ')\n",
    "#         seismic_map['path'] = path\n",
    "#         seismic_map['attr'] = file\n",
    "#         print(f\"seismic map <{path + file}> is uploaded\")\n",
    "        \n",
    "#         def intersection_maps(map, wells_df, buffer):\n",
    "#             geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "#             gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "#             geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "#             gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "#             convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "#             intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "#             return intersection\n",
    "#         seismic_map_intersect = intersection_maps(seismic_map, df_bal8_v4_flag, 1500)\n",
    "#         print(f'seismic map <{path + file}> is intersected with wells')\n",
    "\n",
    "#         def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "#             wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "#             wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "#             wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "#             wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "#             seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "#             df_lst = []\n",
    "#             df_seism_map_zone_lst = []\n",
    "#             for idx, row in wells_df.iterrows():\n",
    "#                 seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "#                                                     (seism_map_short['x'] < row['xmean_max']) & \n",
    "#                                                     (seism_map_short['y'] > row['ymean_min']) &\n",
    "#                                                     (seism_map_short['y'] < row['ymean_max'])]\n",
    "#                 seism_map_zone['well'] = row['well']\n",
    "#                 mean = seism_map_zone.value.mean()\n",
    "#                 p50 = seism_map_zone.value.quantile(0.5)\n",
    "#                 p25 = seism_map_zone.value.quantile(0.25)\n",
    "#                 p75 = seism_map_zone.value.quantile(0.75)\n",
    "#                 df = pd.DataFrame({'well':row['well'], \n",
    "#                                     'phit_net_mean':row['phit_net_mean'], \n",
    "#                                     'mean': mean, \n",
    "#                                     'p50': p50, \n",
    "#                                     'p25': p25, \n",
    "#                                     'p75': p75,\n",
    "#                                     'xmean':row['xmean'],\n",
    "#                                     'ymean':row['ymean'],\n",
    "#                                     'xmean_min':row['xmean_min'],\n",
    "#                                     'xmean_max':row['xmean_max'],\n",
    "#                                     'ymean_min':row['ymean_min'],\n",
    "#                                     'ymean_max':row['ymean_max'],\n",
    "#                                     'margin':margin,\n",
    "#                                     'seism_att':file}, index=[0])\n",
    "#                 df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "\n",
    "#                 df_lst.append(df)\n",
    "#                 df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "#             result = pd.concat(df_lst).reset_index(drop=True)\n",
    "#             result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "#             result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "#             seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "            \n",
    "#             return result, seism_map_zone\n",
    "#         seismic_wells, seism_map_zone = seism_well_correl(seismic_map_intersect, xy8, margin, file)\n",
    "#         # seismic_map_intersect.loc[seismic_map_intersect.value <= 1.65, 'value'] = np.nan\n",
    "#         print(f\"seismic map <{path + file}> to wells dataset is done\")\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(15, 7))\n",
    "#         cb1 = plt.scatter(seismic_map_intersect['x'], seismic_map_intersect['y'], c=seismic_map_intersect['value'], cmap='coolwarm', s=1)\n",
    "#         plt.colorbar(cb1)\n",
    "#         plt.scatter(xy8['xmean'], xy8['ymean'], c='black', s=1)\n",
    "#         for idx, txt in enumerate(xy8['well']):\n",
    "#             ax.annotate(txt, (xy8['xmean'].iloc[idx], xy8['ymean'].iloc[idx]), fontsize=8)\n",
    "#         for idx, row in seismic_wells.iterrows():\n",
    "#             rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "#             ax.add_patch(rect)\n",
    "#         plt.title(path + file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'attr/HDOBN8/'\n",
    "# def list_files_by_mask(directory, mask, exclude_mask=None):\n",
    "#     # Construct the full pattern\n",
    "#     pattern = os.path.join(directory, mask)\n",
    "    \n",
    "#     # Use glob to get the list of files\n",
    "#     files = glob.glob(pattern)\n",
    "\n",
    "#     # Filter out files that match the exclude_mask\n",
    "#     if exclude_mask:\n",
    "#         exclude_pattern = os.path.join(directory, exclude_mask)\n",
    "#         exclude_files = glob.glob(exclude_pattern)\n",
    "#         files = [file for file in files if file not in exclude_files]\n",
    "    \n",
    "#     # Extract the relative path of each file\n",
    "#     relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "#     return relative_paths\n",
    "# files = list_files_by_mask(path, '*', '*.xml')\n",
    "# full_files = list_files_by_mask(path, '* 0-80', '*.xml')\n",
    "\n",
    "# margin = 300\n",
    "# df_attr_map = []\n",
    "# df_attr_well = []\n",
    "# df_attr_intersect_map = []\n",
    "\n",
    "# for file in full_files: \n",
    "\n",
    "#     def seism_upload(file, delimiter):\n",
    "#         seismic = pd.read_csv(file, delimiter=delimiter, skiprows=20, names=['x', 'y', 'value', 'column', 'row'])\n",
    "#         # seismic = seismic.round({'x':0, 'y':0})\n",
    "#         return seismic\n",
    "#     seismic_map = seism_upload(path + file, ' ')\n",
    "#     seismic_map['path'] = path\n",
    "#     seismic_map['attr'] = file\n",
    "#     print(f\"seismic map <{path + file}> is uploaded\")\n",
    "\n",
    "#     def intersection_maps(map, wells_df, buffer):\n",
    "#         geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "#         gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "#         geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "#         gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "#         convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "#         intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "#         return intersection\n",
    "#     seismic_map_intersect = intersection_maps(seismic_map, df_bal8_v4_flag, 1500)\n",
    "#     print(f'seismic map <{path + file}> is intersected with wells')\n",
    "#     df_attr_intersect_map.append(seismic_map_intersect)\n",
    "    \n",
    "#     def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "#         wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "#         wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "#         wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "#         wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "#         seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "#         df_lst = []\n",
    "#         df_seism_map_zone_lst = []\n",
    "#         for idx, row in wells_df.iterrows():\n",
    "#             seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "#                                                 (seism_map_short['x'] < row['xmean_max']) & \n",
    "#                                                 (seism_map_short['y'] > row['ymean_min']) &\n",
    "#                                                 (seism_map_short['y'] < row['ymean_max'])]\n",
    "            \n",
    "#             mean = seism_map_zone.value.mean()\n",
    "#             p50 = seism_map_zone.value.quantile(0.5)\n",
    "#             p25 = seism_map_zone.value.quantile(0.25)\n",
    "#             p75 = seism_map_zone.value.quantile(0.75)\n",
    "#             df = pd.DataFrame({ 'well':row['well'], \n",
    "#                                 'phit_net_mean':row['phit_net_mean'], \n",
    "#                                 'mean': mean, \n",
    "#                                 'p50': p50, \n",
    "#                                 'p25': p25, \n",
    "#                                 'p75': p75,\n",
    "#                                 'xmean':row['xmean'],\n",
    "#                                 'ymean':row['ymean'],\n",
    "#                                 'xmean_min':row['xmean_min'],\n",
    "#                                 'xmean_max':row['xmean_max'],\n",
    "#                                 'ymean_min':row['ymean_min'],\n",
    "#                                 'ymean_max':row['ymean_max'],\n",
    "#                                 'margin':margin,\n",
    "#                                 'field':row['field'],\n",
    "#                                 'seism_att':file}, index=[0])\n",
    "            \n",
    "#             df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "#             df_seism_map_zone['well'] = row['well']\n",
    "#             df_lst.append(df)\n",
    "#             df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "#         result = pd.concat(df_lst).reset_index(drop=True)\n",
    "#         result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "#         result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "#         seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "#         seism_map_zone['seism_att'] = file\n",
    "#         return result, seism_map_zone\n",
    "#     seismic_wells, seismic_map = seism_well_correl(seismic_map_intersect, xy8, margin, file)\n",
    "#     # seismic_map_intersect.loc[seismic_map_intersect.value <= 1.65, 'value'] = np.nan\n",
    "#     print(f\"seismic map <{path + file}> to wells dataset is done\")\n",
    "#     df_attr_map.append(seismic_map)\n",
    "#     df_attr_well.append(seismic_wells)\n",
    "\n",
    "# df_attr_well_full = pd.concat(df_attr_well).reset_index(drop=True)\n",
    "# df_attr_map_full = pd.concat(df_attr_map).reset_index(drop=True)\n",
    "# df_attr_intersect_map_full = pd.concat(df_attr_intersect_map).reset_index(drop=True)\n",
    "\n",
    "# df_attr_well_full.to_csv('io/df_attr_well_full.csv', index=False)\n",
    "# df_attr_map_full.to_csv('io/df_attr_map_full.csv', index=False)\n",
    "# df_attr_intersect_map_full.to_csv('io/df_attr_intersect_map_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr_well_full = pd.read_csv('io/df_attr_well_full.csv')\n",
    "df_attr_map_full = pd.read_csv('io/df_attr_map_full.csv')\n",
    "df_attr_intersect_map_full = pd.read_csv('io/df_attr_intersect_map_full.csv')\n",
    "\n",
    "def seism_attr_collection(df_attr_intersect_map_full):\n",
    "    attr_list = list(df_attr_intersect_map_full.attr.unique())\n",
    "    df1 = df_attr_intersect_map_full[df_attr_intersect_map_full.attr == attr_list[0]]\n",
    "    df2 = df_attr_intersect_map_full[df_attr_intersect_map_full.attr == attr_list[1]]\n",
    "    df3 = df_attr_intersect_map_full[df_attr_intersect_map_full.attr == attr_list[2]]\n",
    "    df12 = df1.set_index(['x','y']).join(df2.set_index(['x','y']), lsuffix='_1', rsuffix='_2').reset_index()\n",
    "    df123 = df12.set_index(['x','y']).join(df3.set_index(['x','y']), rsuffix='_3').reset_index()\n",
    "    df123 = df123.rename(columns={'column':'column_3','value':'value_3', 'row':'row_3', 'path':'path_3', 'attr':'attr_3', 'geometry':'geometry_3'})\n",
    "    df123 = df123[[ 'x', 'y', \n",
    "                    'value_1', 'attr_1',\n",
    "                    'value_2', 'attr_2',\n",
    "                    'value_3', 'attr_3']]\n",
    "    return df123\n",
    "seismic_map_v1 = seism_attr_collection(df_attr_intersect_map_full)\n",
    "\n",
    "def seism_tvdss_dip_collection(seismic_map):\n",
    "    top8 = pd.read_csv('./interv/Top_Bal8_Depth', delimiter=' ', skiprows=20, names=['x', 'y', 'top_tvd_scs', 'column', 'row'])\n",
    "    top8['top_tvd_scs'] = top8['top_tvd_scs'] * -1\n",
    "    bot8 = pd.read_csv('./interv/Bot_Bal8_Depth', delimiter=' ', skiprows=20, names=['x', 'y', 'bot_tvd_scs', 'column', 'row'])\n",
    "    bot8['bot_tvd_scs'] = bot8['bot_tvd_scs'] * -1\n",
    "    dip8 = pd.read_csv('./interv/Bal8_Dip_Angle', delimiter=' ', skiprows=20, names=['x', 'y', 'dip8', 'column', 'row'])\n",
    "    seismic_map_v2 = seismic_map.set_index(['x','y']).join(top8.drop(['column', 'row'], axis=1).set_index(['x','y'])).reset_index()\n",
    "    seismic_map_v3 = seismic_map_v2.set_index(['x','y']).join(bot8.drop(['column', 'row'], axis=1).set_index(['x','y'])).reset_index()\n",
    "    seismic_map_v3['bal8_thick'] = seismic_map_v3['bot_tvd_scs'] - seismic_map_v3['top_tvd_scs']\n",
    "    seismic_map_v4 = seismic_map_v3.set_index(['x','y']).join(dip8.set_index(['x','y'])).reset_index().drop(['column', 'row'], axis=1)\n",
    "    return seismic_map_v4\n",
    "seismic_map_v2 = seism_tvdss_dip_collection(seismic_map_v1)\n",
    "seismic_map_v3 = seismic_map_v2[['x', 'y', 'value_1', 'value_2', 'value_3', 'top_tvd_scs', 'bal8_thick', 'dip8']]\n",
    "seismic_map_v3 = seismic_map_v3.rename(columns={'value_1':'ana0_80', 'value_2':'ma0_80', 'value_3':'rms0_80'})\n",
    "\n",
    "margin = 300\n",
    "wells_df = df_attr_well_full[['well', 'phit_net_mean', 'xmean', 'ymean', 'margin', 'field']].drop_duplicates()\n",
    "def seism_well_preprocessing(seismic_map_v3, df_attr_well_full, margin):\n",
    "    def seism_well_correl_v2(seism_map, wells_df, margin, value, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "        seism_map_short = seism_map[['x', 'y', value]]\n",
    "\n",
    "        df_lst = []\n",
    "        df_seism_map_zone_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            \n",
    "            mean = seism_map_zone[value].mean()\n",
    "            p50 = seism_map_zone[value].quantile(0.5)\n",
    "            p25 = seism_map_zone[value].quantile(0.25)\n",
    "            p75 = seism_map_zone[value].quantile(0.75)\n",
    "            df = pd.DataFrame({ 'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                value+'_avg': mean, \n",
    "                                value+'_p50': p50, \n",
    "                                value+'_p25': p25, \n",
    "                                value+'_p75': p75,\n",
    "                                'xmean':row['xmean'],\n",
    "                                'ymean':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin':margin,\n",
    "                                'field':row['field'],\n",
    "                                'seism_att':file}, index=[0])\n",
    "            \n",
    "            df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "            df_seism_map_zone['well'] = row['well']\n",
    "            df_lst.append(df)\n",
    "            df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "        result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "        seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "        seism_map_zone['seism_att'] = file\n",
    "        return result, seism_map_zone\n",
    "    seismic_wells_ana, seismic_square_ana = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'ana0_80', 'ana0_80')\n",
    "    seismic_wells_ma, seismic_square_ma = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'ma0_80', 'ma0_80')\n",
    "    seismic_wells_rms, seismic_square_rms = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'rms0_80', 'rms0_80')\n",
    "    seismic_wells_tvdss, seismic_square_tvdss = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'top_tvd_scs', 'top_tvd_scs')\n",
    "    seismic_wells_thick, seismic_square_thick = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'bal8_thick', 'bal8_thick')\n",
    "    seismic_wells_dip, seismic_square_dip = seism_well_correl_v2(seismic_map_v3, df_attr_well_full, margin, 'dip8', 'dip8')\n",
    "\n",
    "    drop_list_v1 = ['xmean', 'ymean', 'xmean_min', 'xmean_max', 'ymean_min', 'ymean_max', 'margin', 'field', 'seism_att', 'bottom_left_x', 'bottom_left_y']\n",
    "    drop_list_v2 = ['well','phit_net_mean']\n",
    "    seismic_wells_ana = seismic_wells_ana.drop(drop_list_v1, axis=1)\n",
    "    seismic_wells_ma = seismic_wells_ma.drop(drop_list_v1, axis=1)\n",
    "    seismic_wells_rms = seismic_wells_rms.drop(drop_list_v1, axis=1)\n",
    "    seismic_wells_tvdss = seismic_wells_tvdss.drop(drop_list_v1, axis=1)\n",
    "    seismic_wells_thick = seismic_wells_thick.drop(drop_list_v1, axis=1)\n",
    "\n",
    "    df_attr_final_init = pd.concat([seismic_wells_ana, \n",
    "                                    seismic_wells_ma.drop(drop_list_v2, axis=1), \n",
    "                                    seismic_wells_rms.drop(drop_list_v2, axis=1), \n",
    "                                    seismic_wells_tvdss.drop(drop_list_v2, axis=1), \n",
    "                                    seismic_wells_thick.drop(drop_list_v2, axis=1),\n",
    "                                    seismic_wells_dip.drop(drop_list_v2, axis=1)], axis=1).reset_index(drop=True)\n",
    "    df_attr_final_init.columns\n",
    "\n",
    "    feature_list = ['well','phit_net_mean','xmean','ymean','ana0_80_avg', 'ma0_80_avg', 'rms0_80_avg', 'top_tvd_scs_avg', 'bal8_thick_avg','dip8_avg']\n",
    "    df_attr_final = df_attr_final_init[feature_list]\n",
    "    df_well_attr_final = df_attr_final.rename(columns={ 'ana0_80_avg':'ana0_80', \n",
    "                                                        'ma0_80_avg':'ma0_80', \n",
    "                                                        'rms0_80_avg':'rms0_80', \n",
    "                                                        'top_tvd_scs_avg':'top_tvd_scs', \n",
    "                                                        'bal8_thick_avg':'bal8_thick',\n",
    "                                                        'dip8_avg':'dip8',\n",
    "                                                        'xmean':'x', 'ymean':'y'})\n",
    "    return df_well_attr_final\n",
    "df_well_attr_final = seism_well_preprocessing(seismic_map_v3, wells_df, margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_well_attr_final.iloc[:,:5]\n",
    "# Generation 20 - Current best internal CV score: 0.41814972520472315\n",
    "# df_well_attr_final.iloc[:,:6]\n",
    "# Generation 20 - Current best internal CV score: 0.43406389993742367\n",
    "# df_well_attr_final.iloc[:,:]\n",
    "# Generation 20 - Current best internal CV score: 0.4697519194296129\n",
    "# df_well_attr_final.iloc[:,:] + field\n",
    "# Generation 12 - Current best internal CV score: 0.42649841178519277\n",
    "# df_well_attr_final.iloc[:,:] + MinMaxScaler\n",
    "# Generation 20 - Current best internal CV score: 0.50922249695856\n",
    "# df_well_attr_final.iloc[:,:].drop('rms0_80', axis=1)\n",
    "# Generation 12 - Current best internal CV score: 0.4549541785965697\n",
    "# df_well_attr_final.iloc[:,:].drop('rms0_80', axis=1) + MinMaxScaler to X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Just simple prediction with all features w/o minmaxscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_generation(seismic_map, well_data):\n",
    "    X_test = seismic_map.copy()\n",
    "\n",
    "    outliers_drop = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20'])] #outliers\n",
    "    near_neighbor_drop = outliers_drop[~outliers_drop.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "    validation_wells = [\"B02Z\", \"B05\", \"B08Z\", \"B12\", \"B14Z\", \"B19\", \"C01\", \"C03Z\", \"C10\", \"C14Z\", \"C20Z\",\"D02Z\",\"D03\",\"D04Z\",\"D07\"]\n",
    "\n",
    "    X = near_neighbor_drop.drop('phit_net_mean', axis=1)\n",
    "    y = near_neighbor_drop['phit_net_mean']\n",
    "    X_train = X[~X.well.isin(validation_wells)]\n",
    "    y_train = y[~X.well.isin(validation_wells)]\n",
    "    X_val = X[X.well.isin(validation_wells)]\n",
    "    y_val = y[X.well.isin(validation_wells)]\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=142)\n",
    "\n",
    "    well_train = X_train['well']\n",
    "    well_val = X_val['well']\n",
    "\n",
    "    result = {'X_train':X_train.drop('well', axis=1),\n",
    "              'well_train':well_train, \n",
    "              'y_train':y_train, \n",
    "              'X_val':X_val.drop('well', axis=1),\n",
    "              'well_val':well_val, \n",
    "              'y_val':y_val, \n",
    "              'X_test':X_test, \n",
    "              'well_data':well_data}\n",
    "    return result\n",
    "result = train_test_generation(seismic_map_v3, df_well_attr_final)\n",
    "X_train8, y_train8, X_val8,y_val8, X_test8 = result['X_train'], result['y_train'], result['X_val'], result['y_val'], result['X_test']\n",
    "\n",
    "display(f'X_train8 shape: {X_train8.shape}')\n",
    "display(X_train8.head(3))\n",
    "display(f'X_test8 shape: {X_test8.shape}') \n",
    "display(X_test8.head(3))\n",
    "\n",
    "plt.scatter(X_test8.x, X_test8.y, c=X_test8.ana0_80, cmap='coolwarm', s=1)\n",
    "plt.scatter(X_train8.x, X_train8.y, c='black',  s=10)\n",
    "plt.scatter(X_val8.x, X_val8.y, c='green',  s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "tregr8.fit(X_train8, y_train8)\n",
    "name = 'ex_1_v2'\n",
    "joblib.dump(tregr8.fitted_pipeline_, f'./report/models/tregr_{name}.pkl')\n",
    "tregr8.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtest_xval_prediction(X_test, X_val8, y_val8, X_train8, y_train8, model_name):\n",
    "    model = joblib.load(f'./report/models/tregr_{model_name}.pkl')\n",
    "\n",
    "    y_pred_train = model.predict(X_train8)\n",
    "    train_df = pd.DataFrame({'x': X_train8.iloc[:,0], 'y': X_train8.iloc[:,1],'phit_pred': y_pred_train, 'phit_true':y_train8})\n",
    "    \n",
    "    y_pred_val = model.predict(X_val8)\n",
    "    val_df = pd.DataFrame({'x': X_val8.iloc[:,0], 'y': X_val8.iloc[:,1],'phit_pred': y_pred_val, 'phit_true':y_val8})\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],'phit_pred': y_pred})\n",
    "    return model_df, val_df, train_df\n",
    "model_df8, val_df8, train_df8 = xtest_xval_prediction(X_test8, X_val8, y_val8, X_train8, y_train8, 'ex_1')\n",
    "\n",
    "rng = 0.0115\n",
    "def validation_qc(val, train, rng):\n",
    "    val['qc_up'] = val['phit_true']  + rng\n",
    "    val['qc_down'] = val['phit_true'] - rng\n",
    "    val['qc'] = 'norm'\n",
    "    val.loc[val['phit_pred'] >= val['qc_up'], 'qc'] = 'bigger'\n",
    "    val.loc[val['phit_pred'] <= val['qc_down'], 'qc'] = 'lower'\n",
    "    val['rng'] = rng\n",
    "    display(val.qc.value_counts(normalize=True))\n",
    "    display(val.qc.value_counts())\n",
    "\n",
    "    train['qc_up'] = train['phit_true']  + rng\n",
    "    train['qc_down'] = train['phit_true'] - rng\n",
    "    train['qc'] = 'norm'\n",
    "    train.loc[train['phit_pred'] >= train['qc_up'], 'qc'] = 'bigger'\n",
    "    train.loc[train['phit_pred'] <= train['qc_down'], 'qc'] = 'lower'\n",
    "    train['rng'] = rng\n",
    "\n",
    "    return val, train\n",
    "val_df8, train_df8 = validation_qc(val_df8, train_df8, rng)\n",
    "\n",
    "def display_xplot_map(val_df, model_df, rng):\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    gs = GridSpec(1, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sns.scatterplot(data=val_df, x='phit_true', y='phit_pred', c='#1190e6', s=30, alpha=0.5, ec='black', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--', ax=ax1)\n",
    "    ax1.grid()\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    cb1 = ax2.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', s=1)\n",
    "    ax2.scatter(val_df.x, val_df.y, c='green', s=10)\n",
    "    colorbar1 = plt.colorbar(cb1)\n",
    "display_xplot_map(val_df8,model_df8, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df8\n",
    "sns.scatterplot(data=train_df8, x='phit_true', y='phit_pred', c='blue', s=30, alpha=0.5, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "display(train_df8.qc.value_counts(normalize=True))\n",
    "display(train_df8.qc.value_counts())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_val = result['well_val']\n",
    "well_val_out = val_df8[val_df8.qc != 'norm'].join(well_val, how='inner')\n",
    "val_df8_well = val_df8.join(well_val, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(model_df8['x'], model_df8['y'], c=model_df8['phit_pred'], cmap='coolwarm', s=1)\n",
    "plt.scatter(val_df8_well[~val_df8_well.well.isin(well_val_out.well)].x, \n",
    "            val_df8_well[~val_df8_well.well.isin(well_val_out.well)].y, c='green', s=10)\n",
    "plt.scatter(well_val_out.x, well_val_out.y, c='red', s=10)\n",
    "for idx, txt in enumerate(well_val_out.well):\n",
    "    plt.annotate(txt, (well_val_out.x.iloc[idx], well_val_out.y.iloc[idx]), fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=val_df8_well, x='phit_true', y='phit_pred', c='#1190e6', s=50, alpha=0.5, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "for idx, txt in enumerate(well_val_out.well):\n",
    "    plt.annotate(txt, (well_val_out.phit_true.iloc[idx], well_val_out.phit_pred.iloc[idx]), fontsize=8)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gempy as gp\n",
    "import gempy_viewer as gpv\n",
    "\n",
    "data_path = 'https://raw.githubusercontent.com/cgre-aachen/gempy_data/master/'\n",
    "\n",
    "geo_model: gp.data.GeoModel = gp.create_geomodel(\n",
    "    project_name='Tutorial_ch1_1_Basics',\n",
    "    extent=[0, 2000, 0, 2000, 0, 750],\n",
    "    refinement=4,  # * Here we define the number of octree levels. If octree levels are defined, the resolution is ignored.\n",
    "    importer_helper=gp.data.ImporterHelper(\n",
    "        path_to_orientations=data_path + \"/data/input_data/getting_started/simple_fault_model_orientations.csv\",\n",
    "        path_to_surface_points=data_path + \"/data/input_data/getting_started/simple_fault_model_points.csv\",\n",
    "        hash_surface_points=\"4cdd54cd510cf345a583610585f2206a2936a05faaae05595b61febfc0191563\",\n",
    "        hash_orientations=\"7ba1de060fc8df668d411d0207a326bc94a6cdca9f5fe2ed511fd4db6b3f3526\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Prediction is based on 1 selected seism attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_generation(seismic_map, well_data):\n",
    "    X_test = seismic_map.copy()\n",
    "\n",
    "    outliers_drop = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20'])] #outliers\n",
    "    near_neighbor_drop = outliers_drop[~outliers_drop.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "    validation_wells = [\"B02Z\", \"B05\", \"B08Z\", \"B12\", \"B14Z\", \"B19\", \"C01\", \"C03Z\", \"C10\", \"C14Z\", \"C20Z\",\"D02Z\",\"D03\",\"D04Z\",\"D07\"]\n",
    "\n",
    "    X = near_neighbor_drop.drop('phit_net_mean', axis=1)\n",
    "    y = near_neighbor_drop['phit_net_mean']\n",
    "    X_train = X[~X.well.isin(validation_wells)]\n",
    "    y_train = y[~X.well.isin(validation_wells)]\n",
    "    X_val = X[X.well.isin(validation_wells)]\n",
    "    y_val = y[X.well.isin(validation_wells)]\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=142)\n",
    "\n",
    "    well_train = X_train['well']\n",
    "    well_val = X_val['well']\n",
    "\n",
    "    result = {'X_train':X_train.drop('well', axis=1),\n",
    "              'well_train':well_train, \n",
    "              'y_train':y_train, \n",
    "              'X_val':X_val.drop('well', axis=1),\n",
    "              'well_val':well_val, \n",
    "              'y_val':y_val, \n",
    "              'X_test':X_test, \n",
    "              'well_data':well_data}\n",
    "    return result\n",
    "df_well_attr_final_ex2 = df_well_attr_final.iloc[:,:5]\n",
    "seismic_map_v3_ex2 = seismic_map_v3.iloc[:,:3]\n",
    "result = train_test_generation(seismic_map_v3_ex2, df_well_attr_final_ex2)\n",
    "X_train8, y_train8, X_val8,y_val8, X_test8 = result['X_train'], result['y_train'], result['X_val'], result['y_val'], result['X_test']\n",
    "\n",
    "display(f'X_train8 shape: {X_train8.shape}')\n",
    "display(X_train8.head(3))\n",
    "display(f'X_test8 shape: {X_test8.shape}') \n",
    "display(X_test8.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "tregr8.fit(X_train8, y_train8)\n",
    "name = 'ex_2'\n",
    "joblib.dump(tregr8.fitted_pipeline_, f'./report/models/tregr_{name}.pkl')\n",
    "tregr8.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtest_xval_prediction(X_test, X_val8, y_val8, X_train8, y_train8, model_name):\n",
    "    model = joblib.load(f'./report/models/tregr_{model_name}.pkl')\n",
    "\n",
    "    y_pred_train = model.predict(X_train8)\n",
    "    train_df = pd.DataFrame({'x': X_train8.iloc[:,0], 'y': X_train8.iloc[:,1],'phit_pred': y_pred_train, 'phit_true':y_train8})\n",
    "    \n",
    "    y_pred_val = model.predict(X_val8)\n",
    "    val_df = pd.DataFrame({'x': X_val8.iloc[:,0], 'y': X_val8.iloc[:,1],'phit_pred': y_pred_val, 'phit_true':y_val8})\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],'phit_pred': y_pred})\n",
    "    return model_df, val_df, train_df\n",
    "model_df8, val_df8, train_df8 = xtest_xval_prediction(X_test8, X_val8, y_val8, X_train8, y_train8, 'ex_2')\n",
    "\n",
    "rng = 0.0115\n",
    "def validation_qc(val, train, rng):\n",
    "    val['qc_up'] = val['phit_true']  + rng\n",
    "    val['qc_down'] = val['phit_true'] - rng\n",
    "    val['qc'] = 'norm'\n",
    "    val.loc[val['phit_pred'] >= val['qc_up'], 'qc'] = 'bigger'\n",
    "    val.loc[val['phit_pred'] <= val['qc_down'], 'qc'] = 'lower'\n",
    "    val['rng'] = rng\n",
    "    display(val.qc.value_counts(normalize=True))\n",
    "    display(val.qc.value_counts())\n",
    "\n",
    "    train['qc_up'] = train['phit_true']  + rng\n",
    "    train['qc_down'] = train['phit_true'] - rng\n",
    "    train['qc'] = 'norm'\n",
    "    train.loc[train['phit_pred'] >= train['qc_up'], 'qc'] = 'bigger'\n",
    "    train.loc[train['phit_pred'] <= train['qc_down'], 'qc'] = 'lower'\n",
    "    train['rng'] = rng\n",
    "\n",
    "    return val, train\n",
    "val_df8, train_df8 = validation_qc(val_df8, train_df8, rng)\n",
    "\n",
    "def display_xplot_map(val_df, model_df, rng):\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    gs = GridSpec(1, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sns.scatterplot(data=val_df, x='phit_true', y='phit_pred', c='#1190e6', s=30, alpha=0.5, ec='black', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--', ax=ax1)\n",
    "    ax1.grid()\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    cb1 = ax2.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', s=1)\n",
    "    ax2.scatter(val_df.x, val_df.y, c='green', s=10)\n",
    "    colorbar1 = plt.colorbar(cb1)\n",
    "display_xplot_map(val_df8,model_df8, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df8\n",
    "sns.scatterplot(data=train_df8, x='phit_true', y='phit_pred', c='blue', s=30, alpha=0.5, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "display(train_df8.qc.value_counts(normalize=True))\n",
    "display(train_df8.qc.value_counts())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exersice 3\n",
    "Only 3 seismic attributes are the base for phit prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_generation(seismic_map, well_data):\n",
    "    X_test = seismic_map.copy()\n",
    "\n",
    "    outliers_drop = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20'])] #outliers\n",
    "    near_neighbor_drop = outliers_drop[~outliers_drop.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "    validation_wells = [\"B02Z\", \"B05\", \"B08Z\", \"B12\", \"B14Z\", \"B19\", \"C01\", \"C03Z\", \"C10\", \"C14Z\", \"C20Z\",\"D02Z\",\"D03\",\"D04Z\",\"D07\"]\n",
    "\n",
    "    X = near_neighbor_drop.drop('phit_net_mean', axis=1)\n",
    "    y = near_neighbor_drop['phit_net_mean']\n",
    "    X_train = X[~X.well.isin(validation_wells)]\n",
    "    y_train = y[~X.well.isin(validation_wells)]\n",
    "    X_val = X[X.well.isin(validation_wells)]\n",
    "    y_val = y[X.well.isin(validation_wells)]\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=142)\n",
    "\n",
    "    well_train = X_train['well']\n",
    "    well_val = X_val['well']\n",
    "\n",
    "    result = {'X_train':X_train.drop('well', axis=1),\n",
    "              'well_train':well_train, \n",
    "              'y_train':y_train, \n",
    "              'X_val':X_val.drop('well', axis=1),\n",
    "              'well_val':well_val, \n",
    "              'y_val':y_val, \n",
    "              'X_test':X_test, \n",
    "              'well_data':well_data}\n",
    "    return result\n",
    "df_well_attr_final_ex3 = df_well_attr_final[['well', 'phit_net_mean', 'x', 'y', 'ana0_80', 'ma0_80', 'rms0_80']]\n",
    "seismic_map_v3_ex3 = seismic_map_v3[['x', 'y', 'ana0_80', 'ma0_80', 'rms0_80']]\n",
    "result = train_test_generation(seismic_map_v3_ex3, df_well_attr_final_ex3)\n",
    "X_train8, y_train8, X_val8,y_val8, X_test8 = result['X_train'], result['y_train'], result['X_val'], result['y_val'], result['X_test']\n",
    "\n",
    "display(f'X_train8 shape: {X_train8.shape}')\n",
    "display(X_train8.head(3))\n",
    "display(f'X_test8 shape: {X_test8.shape}') \n",
    "display(X_test8.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "tregr8.fit(X_train8, y_train8)\n",
    "name = 'ex_3'\n",
    "joblib.dump(tregr8.fitted_pipeline_, f'./report/models/tregr_{name}.pkl')\n",
    "tregr8.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtest_xval_prediction(X_test, X_val8, y_val8, X_train8, y_train8, model_name):\n",
    "    model = joblib.load(f'./report/models/tregr_{model_name}.pkl')\n",
    "\n",
    "    y_pred_train = model.predict(X_train8)\n",
    "    train_df = pd.DataFrame({'x': X_train8.iloc[:,0], 'y': X_train8.iloc[:,1],'phit_pred': y_pred_train, 'phit_true':y_train8})\n",
    "    \n",
    "    y_pred_val = model.predict(X_val8)\n",
    "    val_df = pd.DataFrame({'x': X_val8.iloc[:,0], 'y': X_val8.iloc[:,1],'phit_pred': y_pred_val, 'phit_true':y_val8})\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],'phit_pred': y_pred})\n",
    "    return model_df, val_df, train_df\n",
    "model_df8, val_df8, train_df8 = xtest_xval_prediction(X_test8, X_val8, y_val8, X_train8, y_train8, 'ex_3')\n",
    "\n",
    "rng = 0.0115\n",
    "def validation_qc(val, train, rng):\n",
    "    val['qc_up'] = val['phit_true']  + rng\n",
    "    val['qc_down'] = val['phit_true'] - rng\n",
    "    val['qc'] = 'norm'\n",
    "    val.loc[val['phit_pred'] >= val['qc_up'], 'qc'] = 'bigger'\n",
    "    val.loc[val['phit_pred'] <= val['qc_down'], 'qc'] = 'lower'\n",
    "    val['rng'] = rng\n",
    "    display(val.qc.value_counts(normalize=True))\n",
    "    display(val.qc.value_counts())\n",
    "\n",
    "    train['qc_up'] = train['phit_true']  + rng\n",
    "    train['qc_down'] = train['phit_true'] - rng\n",
    "    train['qc'] = 'norm'\n",
    "    train.loc[train['phit_pred'] >= train['qc_up'], 'qc'] = 'bigger'\n",
    "    train.loc[train['phit_pred'] <= train['qc_down'], 'qc'] = 'lower'\n",
    "    train['rng'] = rng\n",
    "\n",
    "    return val, train\n",
    "val_df8, train_df8 = validation_qc(val_df8, train_df8, rng)\n",
    "\n",
    "def display_xplot_map(val_df, model_df, rng):\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    gs = GridSpec(1, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sns.scatterplot(data=val_df, x='phit_true', y='phit_pred', c='#1190e6', s=30, alpha=0.5, ec='black', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--', ax=ax1)\n",
    "    ax1.grid()\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    cb1 = ax2.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', s=1)\n",
    "    ax2.scatter(val_df.x, val_df.y, c='green', s=10)\n",
    "    colorbar1 = plt.colorbar(cb1)\n",
    "display_xplot_map(val_df8,model_df8, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df8\n",
    "sns.scatterplot(data=train_df8, x='phit_true', y='phit_pred', c='blue', s=30, alpha=0.5, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "display(train_df8.qc.value_counts(normalize=True))\n",
    "display(train_df8.qc.value_counts())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_generation(seismic_map, well_data):\n",
    "    X_test = seismic_map.copy()\n",
    "\n",
    "    outliers_drop = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20'])] #outliers\n",
    "    near_neighbor_drop = outliers_drop[~outliers_drop.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "    validation_wells = [\"B02Z\", \"B05\", \"B08Z\", \"B12\", \"B14Z\", \"B19\", \"C01\", \"C03Z\", \"C10\", \"C14Z\", \"C20Z\",\"D02Z\",\"D03\",\"D04Z\",\"D07\"]\n",
    "\n",
    "    X = near_neighbor_drop.drop('phit_net_mean', axis=1)\n",
    "    y = near_neighbor_drop['phit_net_mean']\n",
    "    X_train = X[~X.well.isin(validation_wells)]\n",
    "    y_train = y[~X.well.isin(validation_wells)]\n",
    "    X_val = X[X.well.isin(validation_wells)]\n",
    "    y_val = y[X.well.isin(validation_wells)]\n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=142)\n",
    "\n",
    "    well_train = X_train['well']\n",
    "    well_val = X_val['well']\n",
    "\n",
    "    result = {'X_train':X_train.drop('well', axis=1),\n",
    "              'well_train':well_train, \n",
    "              'y_train':y_train, \n",
    "              'X_val':X_val.drop('well', axis=1),\n",
    "              'well_val':well_val, \n",
    "              'y_val':y_val, \n",
    "              'X_test':X_test, \n",
    "              'well_data':well_data}\n",
    "    return result\n",
    "df_well_attr_final_ex4 = df_well_attr_final[['well', 'phit_net_mean', 'x', 'y', 'top_tvd_scs', 'bal8_thick', 'dip8']]\n",
    "seismic_map_v3_ex4 = seismic_map_v3[['x', 'y', 'top_tvd_scs', 'bal8_thick', 'dip8']]\n",
    "result = train_test_generation(seismic_map_v3_ex4, df_well_attr_final_ex4)\n",
    "X_train8, y_train8, X_val8,y_val8, X_test8 = result['X_train'], result['y_train'], result['X_val'], result['y_val'], result['X_test']\n",
    "\n",
    "display(f'X_train8 shape: {X_train8.shape}')\n",
    "display(X_train8.head(3))\n",
    "display(f'X_test8 shape: {X_test8.shape}') \n",
    "display(X_test8.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "tregr8.fit(X_train8, y_train8)\n",
    "name = 'ex_4'\n",
    "joblib.dump(tregr8.fitted_pipeline_, f'./report/models/tregr_{name}.pkl')\n",
    "tregr8.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtest_xval_prediction(X_test, X_val8, y_val8, X_train8, y_train8, model_name):\n",
    "    model = joblib.load(f'./report/models/tregr_{model_name}.pkl')\n",
    "\n",
    "    y_pred_train = model.predict(X_train8)\n",
    "    train_df = pd.DataFrame({'x': X_train8.iloc[:,0], 'y': X_train8.iloc[:,1],'phit_pred': y_pred_train, 'phit_true':y_train8})\n",
    "    \n",
    "    y_pred_val = model.predict(X_val8)\n",
    "    val_df = pd.DataFrame({'x': X_val8.iloc[:,0], 'y': X_val8.iloc[:,1],'phit_pred': y_pred_val, 'phit_true':y_val8})\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],'phit_pred': y_pred})\n",
    "    return model_df, val_df, train_df\n",
    "model_df8, val_df8, train_df8 = xtest_xval_prediction(X_test8, X_val8, y_val8, X_train8, y_train8, 'ex_4')\n",
    "\n",
    "rng = 0.0115\n",
    "def validation_qc(val, train, rng):\n",
    "    val['qc_up'] = val['phit_true']  + rng\n",
    "    val['qc_down'] = val['phit_true'] - rng\n",
    "    val['qc'] = 'norm'\n",
    "    val.loc[val['phit_pred'] >= val['qc_up'], 'qc'] = 'bigger'\n",
    "    val.loc[val['phit_pred'] <= val['qc_down'], 'qc'] = 'lower'\n",
    "    val['rng'] = rng\n",
    "    display(val.qc.value_counts(normalize=True))\n",
    "    display(val.qc.value_counts())\n",
    "\n",
    "    train['qc_up'] = train['phit_true']  + rng\n",
    "    train['qc_down'] = train['phit_true'] - rng\n",
    "    train['qc'] = 'norm'\n",
    "    train.loc[train['phit_pred'] >= train['qc_up'], 'qc'] = 'bigger'\n",
    "    train.loc[train['phit_pred'] <= train['qc_down'], 'qc'] = 'lower'\n",
    "    train['rng'] = rng\n",
    "\n",
    "    return val, train\n",
    "val_df8, train_df8 = validation_qc(val_df8, train_df8, rng)\n",
    "\n",
    "def display_xplot_map(val_df, model_df, rng):\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    gs = GridSpec(1, 3, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sns.scatterplot(data=val_df, x='phit_true', y='phit_pred', c='#1190e6', s=30, alpha=0.5, ec='black', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--', ax=ax1)\n",
    "    sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--', ax=ax1)\n",
    "    ax1.grid()\n",
    "    ax2 = fig.add_subplot(gs[0, 1:])\n",
    "    cb1 = ax2.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', s=1)\n",
    "    ax2.scatter(val_df.x, val_df.y, c='green', s=10)\n",
    "    colorbar1 = plt.colorbar(cb1)\n",
    "display_xplot_map(val_df8,model_df8, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=train_df8, x='phit_true', y='phit_pred', c='blue', s=30, alpha=0.5, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "display(train_df8.qc.value_counts(normalize=True))\n",
    "display(train_df8.qc.value_counts())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = df_well_attr_final\n",
    "outliers = ['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20']\n",
    "near_neighbor = ['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07']\n",
    "contouring_wells = [    \"B01Y\",\t\"B02\",\t\"B10\",\t\"B21\",\t\"B27Z\",\t\"B34\",\t\"B34Z\",\t\n",
    "                        \"B37\",\t\"B39\",\t\"B40\",\t\"B42Z\",\t\"B43\",\t\"B44\",\t\"C02\",\t\n",
    "                        \"C08Z\",\t\"C21Z\",\t\"C27Y\",\t\"C32\",\t\"C33Z\",\t\"C36\",\t\"C39\",\t\n",
    "                        \"C40\",\t\"C42\",\t\"C43\",\t\"D09Z\",\t\"D12Z\",\t\"D13Y\",\t\"D15\",\t\n",
    "                        \"D19Z\",\t\"D20\",\t\"D23X\",\t\"D27\",\t\"D34\",\t\"D37\"]\n",
    "drop_wells_list = set(outliers + near_neighbor + contouring_wells)\n",
    "well_data_v2 = well_data[~well_data.well.isin(drop_wells_list)]\n",
    "well_data_cont_wells = well_data[well_data.well.isin(contouring_wells)]\n",
    "\n",
    "X = well_data_v2.drop('phit_net_mean', axis=1)\n",
    "y = well_data_v2['phit_net_mean']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.27, random_state=8, shuffle=True)\n",
    "plt.scatter(X_train.x, X_train.y, c='red',  s=20)\n",
    "plt.scatter(well_data_cont_wells.x, well_data_cont_wells.y, c='blue',  s=20, marker='x')\n",
    "plt.scatter(X_val.x, X_val.y, c='green',  s=20, marker='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in [97, 6, 82, 79, 52, 19]:\n",
    "    def validation_wells_selection(well_data, num):\n",
    "        outliers = ['B39', 'D02Y', 'D34', 'C36', 'B31', 'B20']\n",
    "        near_neighbor = ['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07']\n",
    "        contouring_wells = [    \"B01Y\",\t\"B02\",\t\"B10\",\t\"B21\",\t\"B27Z\",\t\"B34\",\t\"B34Z\",\t\n",
    "                                \"B37\",\t\"B39\",\t\"B40\",\t\"B42Z\",\t\"B43\",\t\"B44\",\t\"C02\",\t\n",
    "                                \"C08Z\",\t\"C21Z\",\t\"C27Y\",\t\"C32\",\t\"C33Z\",\t\"C36\",\t\"C39\",\t\n",
    "                                \"C40\",\t\"C42\",\t\"C43\",\t\"D09Z\",\t\"D12Z\",\t\"D13Y\",\t\"D15\",\t\n",
    "                                \"D19Z\",\t\"D20\",\t\"D23X\",\t\"D27\",\t\"D34\",\t\"D37\"]\n",
    "        drop_wells_list = set(outliers + near_neighbor + contouring_wells)\n",
    "\n",
    "        well_data_v2 = well_data[~well_data.well.isin(drop_wells_list)]\n",
    "        data_cont_wells = well_data[well_data.well.isin(contouring_wells)]\n",
    "\n",
    "        X = well_data_v2\n",
    "        y = well_data_v2['phit_net_mean']\n",
    "        data_train, data_val, y_train, y_val = train_test_split(X, y, test_size=0.27, random_state=num, shuffle=True)\n",
    "        data_train_final = pd.concat([data_train, data_cont_wells])\n",
    "\n",
    "        return data_train_final, data_val\n",
    "    data_train_final, data_val = validation_wells_selection(df_well_attr_final, num)\n",
    "    data_train_final.to_csv(f'./report/models_cv/data_train_{num}.csv', index=False)\n",
    "    data_val.to_csv(f'./report/models_cv/data_val_{num}.csv', index=False)\n",
    "    \n",
    "    X_train8 = data_train_final.drop(['well','phit_net_mean'], axis=1)\n",
    "    y_train8 = data_train_final['phit_net_mean']\n",
    "    tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "    tregr8.fit(X_train8, y_train8)\n",
    "    joblib.dump(tregr8.fitted_pipeline_, f'./report/models_cv/tregr_{num}.pkl')\n",
    "    tregr8.fitted_pipeline_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_lst = []\n",
    "model_df_lst = []\n",
    "map_phit_lst = []\n",
    "for num in [97, 6, 82, 79, 52, 19]:\n",
    "    print('*'*25)\n",
    "    print(f'model num: {num}')\n",
    "    print('*'*25)    \n",
    "    X_test8 = seismic_map_v3\n",
    "    data_train = pd.read_csv(f'./report/models_cv/data_train_{num}.csv')\n",
    "    data_val = pd.read_csv(f'./report/models_cv/data_val_{num}.csv')\n",
    "    X_train8 = data_train.drop(['well','phit_net_mean'], axis=1)\n",
    "    y_train8 = data_train['phit_net_mean']\n",
    "    X_val8 = data_val.drop(['well','phit_net_mean'], axis=1)\n",
    "    y_val8 = data_val['phit_net_mean']\n",
    "\n",
    "    def xtest_xval_prediction(X_test, X_val8, y_val8, X_train8, y_train8, num):\n",
    "        model = joblib.load(f'./report/models_cv/tregr_{num}.pkl')\n",
    "\n",
    "        y_pred_train = model.predict(X_train8)\n",
    "        train_df = pd.DataFrame({'x': X_train8.iloc[:,0], 'y': X_train8.iloc[:,1],'phit_pred': y_pred_train, 'phit_true':y_train8})\n",
    "        \n",
    "        y_pred_val = model.predict(X_val8)\n",
    "        val_df = pd.DataFrame({'x': X_val8.iloc[:,0], 'y': X_val8.iloc[:,1],'phit_pred': y_pred_val, 'phit_true':y_val8})\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],'phit_pred': y_pred})\n",
    "        return model_df, val_df, train_df\n",
    "    model_df8, val_df8, train_df8 = xtest_xval_prediction(X_test8, X_val8, y_val8, X_train8, y_train8, f'{num}')\n",
    "    model_df8['num'] = num\n",
    "    map_phit_lst.append(model_df8)\n",
    "\n",
    "    rng = 0.0115\n",
    "    val_df8_v2 = val_df8.set_index(['x','y']).join(data_val[['well','x','y']].set_index(['x','y'])).reset_index()\n",
    "    train_df8_v2 = train_df8.set_index(['x','y']).join(data_train[['well','x','y']].set_index(['x','y'])).reset_index()\n",
    "    def validation_qc(val, train, rng):\n",
    "        val['qc_up'] = val['phit_true']  + rng\n",
    "        val['qc_down'] = val['phit_true'] - rng\n",
    "        val['qc'] = 'norm'\n",
    "        val.loc[val['phit_pred'] >= val['qc_up'], 'qc'] = 'bigger'\n",
    "        val.loc[val['phit_pred'] <= val['qc_down'], 'qc'] = 'lower'\n",
    "        val['rng'] = rng\n",
    "        display(val.qc.value_counts(normalize=True))\n",
    "        display(val.qc.value_counts())\n",
    "\n",
    "        train['qc_up'] = train['phit_true']  + rng\n",
    "        train['qc_down'] = train['phit_true'] - rng\n",
    "        train['qc'] = 'norm'\n",
    "        train.loc[train['phit_pred'] >= train['qc_up'], 'qc'] = 'bigger'\n",
    "        train.loc[train['phit_pred'] <= train['qc_down'], 'qc'] = 'lower'\n",
    "        train['rng'] = rng\n",
    "\n",
    "        return val, train\n",
    "    val_df8_v2, train_df8_v2 = validation_qc(val_df8_v2, train_df8_v2, rng)\n",
    "\n",
    "    model = joblib.load(f'./report/models_cv/tregr_{num}.pkl')\n",
    "    model8 = pd.DataFrame({'num': num, 'model': model}, index=[0])\n",
    "    model_df_lst.append(model8)\n",
    "\n",
    "    val_df8_v2['num'] = num\n",
    "    val_df8_v2['type'] = 'val'\n",
    "    train_df8_v2['num'] = num\n",
    "    train_df8_v2['type'] = 'train'\n",
    "    train_val_df8 = pd.concat([train_df8_v2, val_df8_v2])\n",
    "    train_val_lst.append(train_val_df8)\n",
    "\n",
    "    def display_xplot_map(val_df, model_df, rng):\n",
    "        fig = plt.figure(figsize=(16, 4))\n",
    "        gs = GridSpec(1, 3, figure=fig)\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        sns.scatterplot(data=val_df, x='phit_true', y='phit_pred', c='#1190e6', s=30, alpha=0.5, ec='black', ax=ax1)\n",
    "        sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--', ax=ax1)\n",
    "        sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--', ax=ax1)\n",
    "        sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--', ax=ax1)\n",
    "        for idx, txt in enumerate(val_df.well):\n",
    "            ax1.annotate(txt, (val_df.phit_true.iloc[idx], val_df.phit_pred.iloc[idx]), fontsize=8)\n",
    "        ax1.grid()\n",
    "        ax2 = fig.add_subplot(gs[0, 1:])\n",
    "        cb1 = ax2.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', s=1)\n",
    "        ax2.scatter(val_df.x, val_df.y, c='green', s=10)\n",
    "        for idx, txt in enumerate(val_df.well):\n",
    "            ax1.annotate(txt, (val_df.x.iloc[idx], val_df.y.iloc[idx]), fontsize=8)\n",
    "        colorbar1 = plt.colorbar(cb1)\n",
    "        plt.show()\n",
    "    display_xplot_map(val_df8_v2, model_df8, rng)\n",
    "\n",
    "map_phit = pd.concat(map_phit_lst).reset_index(drop=True)\n",
    "map_phit.to_csv('./report/models_cv/map_phit.csv', index=False)\n",
    "\n",
    "def averaging_phit_map(map_phit_lst):\n",
    "    map_phit_v2 = pd.concat(map_phit_lst)\n",
    "    map_phit_df_lst =[]\n",
    "    for num in map_phit_v2.num.unique():\n",
    "        data = map_phit_v2[map_phit_v2.num == num]\n",
    "        data = data.rename(columns={'phit_pred':f'phit_pred_{num}',\n",
    "                                    'x':f'x_{num}',\n",
    "                                    'y':f'y_{num}',\n",
    "                                    'num':f'num_{num}'})\n",
    "        map_phit_df_lst.append(data)\n",
    "    map_phit_v3 = pd.concat(map_phit_df_lst, axis=1)\n",
    "    map_phit_v3 = map_phit_v3[['x_97', 'y_97', 'phit_pred_97', 'phit_pred_6','phit_pred_82', 'phit_pred_79', 'phit_pred_52', 'phit_pred_19']]\n",
    "    map_phit_v3['phit_pred_mean'] = map_phit_v3.iloc[:,2:].mean(axis=1)\n",
    "    map_phit_v3 = map_phit_v3.rename(columns={'x_97':'x', 'y_97':'y'})\n",
    "    return map_phit_v3\n",
    "map_phit_avg = averaging_phit_map(map_phit_lst)\n",
    "map_phit_avg.to_csv('./report/models_cv/map_phit_avg.csv', index=False)\n",
    "plt.scatter(map_phit_avg.x, map_phit_avg.y, c=map_phit_avg.phit_pred_mean, cmap='coolwarm', s=1)\n",
    "\n",
    "model_df = pd.concat(model_df_lst).reset_index(drop=True)\n",
    "train_val = pd.concat(train_val_lst).reset_index(drop=True)\n",
    "train_val_v2 = train_val.set_index('num').join(model_df.set_index('num'), on='num', how='left').reset_index()\n",
    "train_val_v2 = train_val_v2[['well', 'x', 'y', 'phit_pred', 'phit_true',  'qc_up', 'qc', 'qc_down', 'rng', 'model', 'num', 'type']]\n",
    "train_val_v2.to_csv('./report/models_cv/train_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_phit_avg vs v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_lst = [97, 6, 82, 79, 52, 19]\n",
    "model_print = joblib.load(f'./report/models_cv/tregr_{mdl_lst[1]}.pkl')\n",
    "model_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_phit_avg = pd.read_csv('./report/models_cv/map_phit_avg.csv')\n",
    "\n",
    "def seism_well_correl_v2(seism_map, wells_df, margin, value, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "    seism_map_short = seism_map[['x', 'y', value]]\n",
    "\n",
    "    df_lst = []\n",
    "    df_seism_map_zone_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        \n",
    "        mean = seism_map_zone[value].mean()\n",
    "        p50 = seism_map_zone[value].quantile(0.5)\n",
    "        p25 = seism_map_zone[value].quantile(0.25)\n",
    "        p75 = seism_map_zone[value].quantile(0.75)\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            value+'_avg': mean, \n",
    "                            value+'_p50': p50, \n",
    "                            value+'_p25': p25, \n",
    "                            value+'_p75': p75,\n",
    "                            'xmean':row['xmean'],\n",
    "                            'ymean':row['ymean'],\n",
    "                            'xmean_min':row['xmean_min'],\n",
    "                            'xmean_max':row['xmean_max'],\n",
    "                            'ymean_min':row['ymean_min'],\n",
    "                            'ymean_max':row['ymean_max'],\n",
    "                            'margin':margin,\n",
    "                            'field':row['field'],\n",
    "                            'seism_att':file}, index=[0])\n",
    "        \n",
    "        df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "        df_seism_map_zone['well'] = row['well']\n",
    "        df_lst.append(df)\n",
    "        df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "    result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "    seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "    seism_map_zone['seism_att'] = file\n",
    "    return result, seism_map_zone\n",
    "wells_df = df_attr_well_full[['well', 'phit_net_mean', 'xmean', 'ymean', 'margin', 'field']].drop_duplicates()\n",
    "phit_wells_init, phit_square = seism_well_correl_v2(map_phit_avg, wells_df, 300, 'phit_pred_mean', 'phit_pred_mean')\n",
    "phit_wells = phit_wells_init[['well',\t'phit_net_mean', 'phit_pred_mean_avg']]\n",
    "display(phit_wells.head(3))\n",
    "\n",
    "rng = 0.0115*1\n",
    "phit_wells['qc_up'] = phit_wells['phit_net_mean']  + rng\n",
    "phit_wells['qc_down'] = phit_wells['phit_net_mean'] - rng\n",
    "phit_wells['qc'] = 'norm'\n",
    "phit_wells.loc[phit_wells['phit_pred_mean_avg'] >= phit_wells['qc_up'], 'qc'] = 'bigger'\n",
    "phit_wells.loc[phit_wells['phit_pred_mean_avg'] <= phit_wells['qc_down'], 'qc'] = 'lower'\n",
    "phit_wells['rng'] = rng\n",
    "display(phit_wells.qc.value_counts(normalize=True).round(2))\n",
    "display(phit_wells.qc.value_counts())\n",
    "sns.scatterplot(data=phit_wells, x='phit_net_mean', y='phit_pred_mean_avg', hue='qc', s=30, alpha=0.75, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "plt.grid()\n",
    "plt.title('map_phit_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_phit_avg_v2 = pd.read_csv('./report/models_cv/map_phit_avg_v2.csv')\n",
    "\n",
    "def seism_well_correl_v2(seism_map, wells_df, margin, value, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "    seism_map_short = seism_map[['x', 'y', value]]\n",
    "\n",
    "    df_lst = []\n",
    "    df_seism_map_zone_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        \n",
    "        mean = seism_map_zone[value].mean()\n",
    "        p50 = seism_map_zone[value].quantile(0.5)\n",
    "        p25 = seism_map_zone[value].quantile(0.25)\n",
    "        p75 = seism_map_zone[value].quantile(0.75)\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            value+'_avg': mean, \n",
    "                            value+'_p50': p50, \n",
    "                            value+'_p25': p25, \n",
    "                            value+'_p75': p75,\n",
    "                            'xmean':row['xmean'],\n",
    "                            'ymean':row['ymean'],\n",
    "                            'xmean_min':row['xmean_min'],\n",
    "                            'xmean_max':row['xmean_max'],\n",
    "                            'ymean_min':row['ymean_min'],\n",
    "                            'ymean_max':row['ymean_max'],\n",
    "                            'margin':margin,\n",
    "                            'field':row['field'],\n",
    "                            'seism_att':file}, index=[0])\n",
    "        \n",
    "        df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "        df_seism_map_zone['well'] = row['well']\n",
    "        df_lst.append(df)\n",
    "        df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "    result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "    seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "    seism_map_zone['seism_att'] = file\n",
    "    return result, seism_map_zone\n",
    "wells_df = df_attr_well_full[['well', 'phit_net_mean', 'xmean', 'ymean', 'margin', 'field']].drop_duplicates()\n",
    "phit_wells_init_v2, phit_square_v2 = seism_well_correl_v2(map_phit_avg_v2, wells_df, 300, 'phit_pred_mean', 'phit_pred_mean')\n",
    "phit_wells_v2 = phit_wells_init_v2[['well',\t'phit_net_mean', 'phit_pred_mean_avg']]\n",
    "display(phit_wells_v2.head(3))\n",
    "\n",
    "rng = 0.0115*1.\n",
    "phit_wells_v2['qc_up'] = phit_wells_v2['phit_net_mean']  + rng\n",
    "phit_wells_v2['qc_down'] = phit_wells_v2['phit_net_mean'] - rng\n",
    "phit_wells_v2['qc'] = 'norm'\n",
    "phit_wells_v2.loc[phit_wells_v2['phit_pred_mean_avg'] >= phit_wells_v2['qc_up'], 'qc'] = 'bigger'\n",
    "phit_wells_v2.loc[phit_wells_v2['phit_pred_mean_avg'] <= phit_wells_v2['qc_down'], 'qc'] = 'lower'\n",
    "phit_wells_v2['rng'] = rng\n",
    "display(phit_wells_v2.qc.value_counts(normalize=True).round(2))\n",
    "display(phit_wells_v2.qc.value_counts())\n",
    "sns.scatterplot(data=phit_wells_v2, x='phit_net_mean', y='phit_pred_mean_avg', hue='qc', s=30, alpha=0.75, ec='black')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18, 0.28], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18+rng, 0.28+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.28], y=[0.18-rng, 0.28-rng], c='g', ls='--')\n",
    "plt.grid()\n",
    "plt.title('map_phit_avg_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train vs val ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_qcxplots(train_val_v2, rng, num):\n",
    "    data_type = train_val_v2[train_val_v2.num==num]\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    custom_pallete = {'norm':'#1190e6', 'bigger':'#ff7f0e', 'lower':'#2ca02c'}\n",
    "    sns.scatterplot(data=data_type[data_type.type == 'train'], x='phit_true', y='phit_pred', hue='qc', s=30, alpha=0.75, ec='black', ax=ax[0], palette=custom_pallete)\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15, 0.28], c='r', ls='--', ax=ax[0])\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15+rng, 0.28+rng], c='g', ls='--', ax=ax[0])\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15-rng, 0.28-rng], c='g', ls='--', ax=ax[0])\n",
    "    sns.scatterplot(data=data_type[data_type.type == 'val'], x='phit_true', y='phit_pred', hue='qc', s=30, alpha=0.75, ec='black', ax=ax[1], palette=custom_pallete)\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15, 0.28], c='r', ls='--', ax=ax[1])\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15+rng, 0.28+rng], c='g', ls='--', ax=ax[1])\n",
    "    sns.lineplot(x=[0.15, 0.28], y=[0.15-rng, 0.28-rng], c='g', ls='--', ax=ax[1])\n",
    "    ax[0].set_xlim(0.16, 0.28)\n",
    "    ax[0].set_ylim(0.16, 0.28)\n",
    "    ax[1].set_xlim(0.16, 0.28)\n",
    "    ax[1].set_ylim(0.16, 0.28)\n",
    "    ax[0].grid()\n",
    "    ax[1].grid()\n",
    "    plt.suptitle(f'Model {num}')\n",
    "    plt.show()\n",
    "\n",
    "for num in [97, 6, 82, 79, 52, 19]:\n",
    "    train_val_qcxplots(train_val_v2, rng, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_phit_map(map_phit_lst):\n",
    "    map_phit_v2 = pd.concat(map_phit_lst)\n",
    "    map_phit_df_lst =[]\n",
    "    for num in map_phit_v2.num.unique():\n",
    "        data = map_phit_v2[map_phit_v2.num == num]\n",
    "        data = data.rename(columns={'phit_pred':f'phit_pred_{num}',\n",
    "                                    'x':f'x_{num}',\n",
    "                                    'y':f'y_{num}',\n",
    "                                    'num':f'num_{num}'})\n",
    "        map_phit_df_lst.append(data)\n",
    "    map_phit_v3 = pd.concat(map_phit_df_lst, axis=1)\n",
    "    map_phit_v3 = map_phit_v3[['x_97', 'y_97', 'phit_pred_97', 'phit_pred_6','phit_pred_79', 'phit_pred_52', 'phit_pred_19']]\n",
    "    map_phit_v3['phit_pred_mean'] = map_phit_v3.iloc[:,2:].mean(axis=1)\n",
    "    map_phit_v3 = map_phit_v3.rename(columns={'x_97':'x', 'y_97':'y'})\n",
    "    return map_phit_v3\n",
    "map_phit_avg_v2 = averaging_phit_map(map_phit_lst)\n",
    "map_phit_avg_v2.to_csv('./report/models_cv/map_phit_avg_v2.csv', index=False)\n",
    "plt.scatter(map_phit_avg_v2.x, map_phit_avg_v2.y, c=map_phit_avg_v2.phit_pred_mean, cmap='coolwarm', s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perm calc base on phit_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_ds_us_calc(dataset, value):\n",
    "    def perm_ds_1(x):\n",
    "        return 10**(39139.46 * pow(x, 5) - 11140.04 * pow(x, 4) + 855.2176 * pow(x, 3) + 7.04505 * pow(x, 2) + 5.750233 * x - 1.997085)\n",
    "    def perm_us_1(x):\n",
    "        return 10**(1638286 * pow(x, 5) - 1396883 * pow(x, 4) + 468324.8 * pow(x, 3) - 76974.79 * pow(x, 2) + 6217.262 * x - 198.5042)\n",
    "    def perm_ds_2(x):\n",
    "        return 10**(+ 5675.143 * pow(x, 5) - 11106.91 * pow(x, 4) + 8608.366 * pow(x, 3) - 3318.893 * pow(x, 2) + 644.7713 * x - 48.16968)\n",
    "    def perm_us_2(x):\n",
    "        return 10**(+ 81.59968 * pow(x, 5) - 275.5442 * pow(x, 4) + 364.9522 * pow(x, 3) - 238.8838 * pow(x, 2) + 79.97139 * x - 7.15)\n",
    "    \n",
    "    def perm_20(x):\n",
    "        return (7.7925*((x*100)**2))-(29881.0*x)+2891.8\n",
    "    \n",
    "    def perm_16_20(x):\n",
    "        return 0.00000002*(np.exp(x*105.56))\n",
    "    \n",
    "    def perm_15_16(x):\n",
    "        return 0.0159*(np.exp(x*21.27))\n",
    "    \n",
    "    df = dataset.copy()\n",
    "    \n",
    "    df.loc[(df[value] >= 0.13) & (df[value] <=0.2), 'perm_us'] = df[value].apply(perm_us_1)\n",
    "    df.loc[(df[value] >= 0.2) & (df[value] <=1), 'perm_us'] = df[value].apply(perm_us_2)\n",
    "\n",
    "    df.loc[(df[value] >= 0.2) & (df[value] <=1), 'perm'] = df[value].apply(perm_20)\n",
    "    df.loc[(df[value] >= 0.16) & (df[value] <0.2), 'perm'] = df[value].apply(perm_16_20)\n",
    "    df.loc[(df[value] >= 0.15) & (df[value] <0.16), 'perm'] = df[value].apply(perm_15_16)\n",
    "\n",
    "    df.loc[(df[value] >= 0.13) & (df[value] <=0.2), 'perm_ds'] = df[value].apply(perm_ds_1)\n",
    "    df.loc[(df[value] >= 0.2) & (df[value] <=1), 'perm_ds'] = df[value].apply(perm_ds_2)\n",
    "    \n",
    "    df['perm_ds'] = df['perm_ds'].fillna(0)\n",
    "    df['perm_us'] = df['perm_us'].fillna(0)\n",
    "    return df\n",
    "htst_phit = df_bal8_v4_flag[df_bal8_v4_flag.net == 1].groupby('well')[['phit', \n",
    "                                                                       'xmean', 'ymean', \n",
    "                                                                       'net', \n",
    "                                                                       'khtst',\n",
    "                                                                       'field']].agg({  'phit':'mean', \n",
    "                                                                                        'net': lambda x: x.sum()*0.1,\n",
    "                                                                                        'khtst':'first',\n",
    "                                                                                        'xmean':'first', 'ymean':'first',\n",
    "                                                                                        'field':'first'}).reset_index()\n",
    "htst_phit = perm_ds_us_calc(htst_phit, 'phit')\n",
    "htst_phit = htst_phit.rename(columns={'perm':'perm_phit_avg', 'perm_ds':'perm_ds_phit_avg', 'perm_us':'perm_us_phit_avg'})\n",
    "htst_phit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if PHI >=0.20:\n",
    "# PERM = (7.7925*((PHI*100)**2))-(29881.0*PHI)+2891.8\n",
    "\n",
    "# elif PHI >= 0.16 and PHI < 0.20:\n",
    "# PERM = 0.00000002*(exp(PHI*105.56))\n",
    "\n",
    "# elif PHI >= 0.15 and PHI < 0.16:\n",
    "# PERM = 0.0159*(exp(PHI*21.27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_phit_avg = pd.read_csv('./report/models_cv/map_phit_avg.csv')\n",
    "perm_map = perm_ds_us_calc(map_phit_avg, 'phit_pred_mean')\n",
    "fig = plt.figure(figsize=(16, 7))\n",
    "cb = plt.scatter(perm_map.x, perm_map.y, c=perm_map.perm, cmap='coolwarm', s=1)\n",
    "plt.colorbar(cb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_correl_v3(seism_map, wells_df, margin, value, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "    seism_map_short = seism_map[['x', 'y', value]]\n",
    "\n",
    "    df_lst = []\n",
    "    df_seism_map_zone_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        \n",
    "        mean = seism_map_zone[value].mean()\n",
    "        p50 = seism_map_zone[value].quantile(0.5)\n",
    "        p25 = seism_map_zone[value].quantile(0.25)\n",
    "        p75 = seism_map_zone[value].quantile(0.75)\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit':row['phit'], \n",
    "                            value+'_avg': mean, \n",
    "                            value+'_p50': p50, \n",
    "                            value+'_p25': p25, \n",
    "                            value+'_p75': p75,\n",
    "                            'xmean':row['xmean'],\n",
    "                            'ymean':row['ymean'],\n",
    "                            'xmean_min':row['xmean_min'],\n",
    "                            'xmean_max':row['xmean_max'],\n",
    "                            'ymean_min':row['ymean_min'],\n",
    "                            'ymean_max':row['ymean_max'],\n",
    "                            'margin':margin,\n",
    "                            'field':row['field'],\n",
    "                            'htst': row['net'],\n",
    "                            'khtst': row['khtst'],\n",
    "                            'perm_us_phit_avg': row['perm_us_phit_avg'],\t\n",
    "                            'perm_phit_avg': row['perm_phit_avg'],\t\n",
    "                            'perm_ds_phit_avg': row['perm_ds_phit_avg'],\n",
    "                            'seism_att':file}, index=[0])\n",
    "        \n",
    "        df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "        df_seism_map_zone['well'] = row['well']\n",
    "        df_lst.append(df)\n",
    "        df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "    result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "    seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "    seism_map_zone['seism_att'] = file\n",
    "    return result, seism_map_zone\n",
    "perm_map_wells_init, perm_map_square = seism_well_correl_v3(perm_map, htst_phit, 300, 'perm', 'perm')\n",
    "perm_map_wells = perm_map_wells_init[['well', 'phit', 'perm_us_phit_avg', 'perm_phit_avg', 'perm_ds_phit_avg', 'htst', 'perm_avg', 'khtst', ]]\n",
    "perm_map_wells = perm_map_wells.rename(columns={'perm_avg':'perm_map_avg'})\n",
    "perm_map_wells['khtst_map'] = perm_map_wells['perm_map_avg'] * perm_map_wells['htst']\n",
    "perm_map_wells['khtst_log'] = perm_map_wells['perm_phit_avg'] * perm_map_wells['htst']\n",
    "perm_map_wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.scatterplot(data=perm_map_wells, x='khtst', y='khtst_log',  c='#32aa22', s=30, alpha=0.75, ec='black', ax=ax[0])\n",
    "sns.scatterplot(data=perm_map_wells, x='khtst_log', y='khtst_map',  c ='#eea506' ,s=30, alpha=0.75, ec='black', ax=ax[1])\n",
    "sns.lineplot(x=[0, 20000], y=[0, 20000], c='r', ls='--', ax=ax[1])\n",
    "sns.scatterplot(data=perm_map_wells, x='khtst_map', y='khtst',  s=30, alpha=0.75, ec='black', ax=ax[2])\n",
    "sns.lineplot(x=[0, 20000], y=[0, 20000], c='r', ls='--', ax=ax[2])\n",
    "sns.lineplot(x=[0, 8000], y=[0, 30000], c='r', ls=':', ax=ax[2])\n",
    "ax[2].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation distance between two dashed lines on 3d diagramn\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return round(((x2 - x1)**2 + (y2 - y1)**2)**(1/2),0)\n",
    "\n",
    "x1, y1 = 20000, 20000\n",
    "x2, y2 = 30000, 8000\n",
    "distance = calculate_distance(x1, y1, x2, y2)\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New wells blind test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wells = pd.read_csv(r'C:\\Petrel\\techlog_data\\k01k02d31c36x.csv')[1:].drop(['datasetName','TVDSS', 'BADPORLOG', 'FLANK', 'FLANK2', \n",
    "                                                                               'FLUIDCODE', 'Fluidcode', 'Fluidcode_mod', 'FLUIDCODE_PP',\n",
    "                                                                               'Labelling', 'AREA'], axis=1)\n",
    "new_wells = new_wells.rename(columns={'DEPT':'MD', 'wellName':'well'})\n",
    "new_wells8 = new_wells[new_wells.FORMATION.str.contains('Balakhany VIII')].reset_index(drop=True)\n",
    "new_wells8['FORMATION_up'] = 'Balakhany VIII'\n",
    "new_wells8.loc[new_wells8.well.str.startswith('K'), 'field'] = 'ACE'\n",
    "new_wells8.loc[new_wells8.well.str.startswith('D'), 'field'] = 'EAST AZERI'\n",
    "new_wells8.loc[new_wells8.well.str.startswith('C'), 'field'] = 'WEST AZERI'\n",
    "new_wells8 = new_wells8[new_wells8.TST != -9999.]\n",
    "new_wells8 = new_wells8[new_wells8.MD != -9999.]\n",
    "for col in  [   'MD', 'GR_N', 'GRMATRIX', 'GRSHALE',\n",
    "                'LPERM', 'LPERM_DS_Bal', 'LPERM_US_Bal', 'NET', 'NPSS', 'PHIT', 'RDEEP',\n",
    "                'RHOB', 'RHOF', 'RHOMA', 'TST', 'TVD_SCS', 'X', 'Y']:\n",
    "    new_wells8[col] = pd.to_numeric(new_wells8[col], errors='coerce')\n",
    "for col in  [ 'well', 'FORMATION', 'FORMATION_up', 'field']:\n",
    "    new_wells8[col] = new_wells8[col].astype('string')\n",
    "\n",
    "def interpolate_by_depth_fm_run_v3(df, step):\n",
    "    df_tst = df[df.TST.notna()].round({'MD':1})\n",
    "    \n",
    "    def interpolate_by_depth_fm_v2(one_well, step):\n",
    "        one_well = one_well.sort_values(by='TST')\n",
    "        well_name = one_well[\"well\"].iloc[0]\n",
    "        formation = one_well[\"FORMATION\"].iloc[0]\n",
    "        formation_up = one_well[\"FORMATION_up\"].iloc[0]\n",
    "        field = one_well[\"field\"].iloc[0]\n",
    "        data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "        starting_tst = one_well[\"TST\"].iloc[0]\n",
    "        new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "        col_lst = []\n",
    "        for col in one_well.columns:\n",
    "            if col not in ['well','FORMATION_up', 'FORMATION','field']:\n",
    "                interp = interp1d(one_well['TST'], one_well[col], kind='linear', fill_value=\"extrapolate\")\n",
    "                new_data = {col: interp(new_TST_values)}\n",
    "                new_df = pd.DataFrame(new_data)\n",
    "                col_lst.append(new_df)\n",
    "        new_df = pd.concat(col_lst, axis=1)\n",
    "        new_df['well'] = well_name\n",
    "        new_df['TST'] = new_TST_values\n",
    "        new_df['FORMATION'] = formation\n",
    "        new_df['FORMATION_up'] = formation_up\n",
    "        new_df['field'] = field #Index(['FORMATION', 'FORMATION_up', 'field'], dtype='object')\n",
    "        new_df = new_df[[   'well', 'MD', 'FORMATION', 'GR_N', 'GRMATRIX', 'GRSHALE', 'LPERM',\n",
    "                            'LPERM_DS_Bal', 'LPERM_US_Bal', 'NET', 'NPSS', 'PHIT', 'RDEEP', 'RHOB',\n",
    "                            'RHOF', 'RHOMA', 'TST', 'TVD_SCS', 'X', 'Y', 'FORMATION_up', 'field']]\n",
    "        return new_df\n",
    "    df_lst = []\n",
    "    for well in tqdm(df_tst.well.unique()):\n",
    "        well_data = df_tst[df_tst.well == well]\n",
    "        well_data_interp = interpolate_by_depth_fm_v2(well_data, 0.1)\n",
    "        df_lst.append(well_data_interp)\n",
    "    df_interp = pd.concat(df_lst)\n",
    "    df_interp = df_interp.round({'MD':1, 'TVD_SCS':1, 'TST':1})\n",
    "    print('Start joining')\n",
    "    def well_bal_interp_join(dataset):\n",
    "        df_tst = df[(df.TST.notna()) & (df.FORMATION_up.notna())].round({'MD':1})\n",
    "        data_fu = df_tst[['well','MD','FORMATION_up', 'FORMATION', 'field']]\n",
    "        well_join = dataset.set_index(['well','MD']).join(data_fu.set_index(['well','MD']), rsuffix='_r').reset_index()\n",
    "        well_join.insert(3, 'FORMATION_up', well_join.pop('FORMATION_up'))\n",
    "        well_join.insert(4, 'FORMATION', well_join.pop('FORMATION'))\n",
    "        # well_join.insert(5, 'tst_index', well_join.pop('tst_index'))\n",
    "        return well_join\n",
    "    well_interp_v2 = well_bal_interp_join(df_interp)\n",
    "    # well_interp_v2.loc[well_interp_v2.NET_VSH > 0, 'NET_VSH'] = 1\n",
    "    well_interp_v2.loc[well_interp_v2.NET > 0, 'NET'] = 1\n",
    "    \n",
    "    df_lst_2 = []\n",
    "    for well in well_interp_v2.well.unique():\n",
    "        field_data = well_interp_v2[well_interp_v2.well == well]\n",
    "        field_data.field = field_data.field.fillna(method = 'ffill')\n",
    "        field_data.field = field_data.field.fillna(method = 'bfill')\n",
    "        field_data.FORMATION_up = field_data.FORMATION_up.fillna(method = 'ffill')\n",
    "        field_data.FORMATION_up = field_data.FORMATION_up.fillna(method = 'bfill')\n",
    "        field_data.FORMATION = field_data.FORMATION.fillna(method = 'ffill')\n",
    "        field_data.FORMATION = field_data.FORMATION.fillna(method = 'bfill')\n",
    "        df_lst_2.append(field_data)\n",
    "    well_interp_v3 = pd.concat(df_lst_2)\n",
    "\n",
    "    return well_interp_v3\n",
    "new_wells8_v2 = interpolate_by_depth_fm_run_v3(new_wells8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wells8_v2.columns = new_wells8_v2.columns.str.lower()\n",
    "new_wells_phit = new_wells8_v2[new_wells8_v2.net==1].groupby('well')[['phit', 'x', 'y', 'field']].agg(\n",
    "    {'phit':'mean', 'x':'mean', 'y':'mean', 'field':'first'}).round({'x':0, 'y':0}).rename(\n",
    "        columns={'phit':'phit_net_mean', 'x':'xmean','y':'ymean'}).reset_index()\n",
    "new_wells_phit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 7))\n",
    "map_phit_avg = pd.read_csv('./report/models_cv/map_phit_avg.csv')\n",
    "cb = plt.scatter(map_phit_avg.x, map_phit_avg.y, c=map_phit_avg.phit_pred_mean, cmap='coolwarm', s=1)\n",
    "plt.colorbar(cb)\n",
    "plt.scatter(new_wells_phit.xmean, new_wells_phit.ymean, c='black', s=10)\n",
    "for idx, txt in enumerate(new_wells_phit.well):\n",
    "    plt.annotate(txt, (new_wells_phit.xmean.iloc[idx], new_wells_phit.ymean.iloc[idx]), fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_correl_new_wells(seism_map, wells_df, margin, value, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "    seism_map_short = seism_map[['x', 'y', value]]\n",
    "\n",
    "    df_lst = []\n",
    "    df_seism_map_zone_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        \n",
    "        mean = seism_map_zone[value].mean()\n",
    "        p50 = seism_map_zone[value].quantile(0.5)\n",
    "        p10 = seism_map_zone[value].quantile(0.1)\n",
    "        p90 = seism_map_zone[value].quantile(0.9)\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            value+'_avg': mean, \n",
    "                            value+'_p50': p50, \n",
    "                            value+'_p10': p10, \n",
    "                            value+'_p90': p90,\n",
    "                            'xmean':row['xmean'],\n",
    "                            'ymean':row['ymean'],\n",
    "                            'xmean_min':row['xmean_min'],\n",
    "                            'xmean_max':row['xmean_max'],\n",
    "                            'ymean_min':row['ymean_min'],\n",
    "                            'ymean_max':row['ymean_max'],\n",
    "                            'margin':margin,\n",
    "                            'field':row['field'],\n",
    "                            'seism_att':file}, index=[0])\n",
    "        \n",
    "        df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "        df_seism_map_zone['well'] = row['well']\n",
    "        df_lst.append(df)\n",
    "        df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "    result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "    seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "    seism_map_zone['seism_att'] = file\n",
    "    return result, seism_map_zone\n",
    "new_wells_phit, new_wells_square = seism_well_correl_new_wells(map_phit_avg, new_wells_phit, 300, 'phit_pred_mean', 'new_wells_phit')\n",
    "new_wells_phit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 0.0115*1\n",
    "sns.scatterplot(data=new_wells_phit, x='phit_net_mean', y='phit_pred_mean_avg', \n",
    "                s=30, alpha=0.5, ec='black', marker='o')\n",
    "sns.scatterplot(data=new_wells_phit, x='phit_net_mean', y='phit_pred_mean_p10', \n",
    "                s=30, alpha=0.5, ec='black', marker='v')\n",
    "sns.scatterplot(data=new_wells_phit, x='phit_net_mean', y='phit_pred_mean_p90', \n",
    "                s=30, alpha=0.5, ec='black', marker='^')\n",
    "sns.lineplot(x=[0.18, 0.26], y=[0.18, 0.26], c='r', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.26], y=[0.18+rng, 0.26+rng], c='g', ls='--')\n",
    "sns.lineplot(x=[0.18, 0.26], y=[0.18-rng, 0.26-rng], c='g', ls='--')\n",
    "plt.xlim(0.18, 0.26)\n",
    "plt.ylim(0.18, 0.26)\n",
    "plt.grid()\n",
    "for idx, txt in enumerate(new_wells_phit.well):\n",
    "    plt.annotate(txt, (new_wells_phit.phit_net_mean.iloc[idx], new_wells_phit.phit_pred_mean_avg.iloc[idx]), fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density_Bal8 uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'attr/Den8/'\n",
    "def list_files_by_mask(directory, mask, exclude_mask=None):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)   \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "    # Filter out files that match the exclude_mask\n",
    "    if exclude_mask:\n",
    "        exclude_pattern = os.path.join(directory, exclude_mask)\n",
    "        exclude_files = glob.glob(exclude_pattern)\n",
    "        files = [file for file in files if file not in exclude_files]\n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    return relative_paths\n",
    "files = list_files_by_mask(path, '*', '*.xml')\n",
    "full_files = list_files_by_mask(path, '* 0-80', '*.xml')\n",
    "full_files, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 300\n",
    "file = full_files[1]\n",
    "def seism_upload(file, delimiter):\n",
    "    seismic = pd.read_csv(file, delimiter=delimiter, skiprows=20, names=['x', 'y', 'value', 'column', 'row'])\n",
    "    seismic = seismic.round({'x':0, 'y':0})\n",
    "    return seismic\n",
    "seismic_map = seism_upload(path + file, ' ')\n",
    "seismic_map['path'] = path\n",
    "seismic_map['attr'] = file\n",
    "print(f\"seismic map <{path + file}> is uploaded\")\n",
    "\n",
    "def intersection_maps(map, wells_df, buffer):\n",
    "    geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "    gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "    geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "    gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "    convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "    intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "    return intersection\n",
    "seismic_map_intersect = intersection_maps(seismic_map, df_bal8_v4_flag, 1500)\n",
    "print(f'seismic map <{path + file}> is intersected with wells')\n",
    "\n",
    "def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "    seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "    df_lst = []\n",
    "    df_seism_map_zone_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        seism_map_zone['well'] = row['well']\n",
    "        mean = seism_map_zone.value.mean()\n",
    "        p50 = seism_map_zone.value.quantile(0.5)\n",
    "        p25 = seism_map_zone.value.quantile(0.25)\n",
    "        p75 = seism_map_zone.value.quantile(0.75)\n",
    "        df = pd.DataFrame({'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            'mean': mean, \n",
    "                            'p50': p50, \n",
    "                            'p25': p25, \n",
    "                            'p75': p75,\n",
    "                            'xmean':row['xmean'],\n",
    "                            'ymean':row['ymean'],\n",
    "                            'xmean_min':row['xmean_min'],\n",
    "                            'xmean_max':row['xmean_max'],\n",
    "                            'ymean_min':row['ymean_min'],\n",
    "                            'ymean_max':row['ymean_max'],\n",
    "                            'margin':margin,\n",
    "                            'seism_att':file}, index=[0])\n",
    "        df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "\n",
    "        df_lst.append(df)\n",
    "        df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "    result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "    seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "    \n",
    "    return result, seism_map_zone\n",
    "seismic_wells, seism_map_zone = seism_well_correl(seismic_map_intersect, xy8, margin, file)\n",
    "seismic_map_intersect.loc[seismic_map_intersect.value <= 1.65, 'value'] = np.nan\n",
    "print(f\"seismic map <{path + file}> to wells dataset is done\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "cb1 = plt.scatter(seismic_map_intersect['x'], seismic_map_intersect['y'], c=seismic_map_intersect['value'], cmap='coolwarm', s=1)\n",
    "plt.colorbar(cb1)\n",
    "plt.scatter(xy8['xmean'], xy8['ymean'], c='black', s=1)\n",
    "for idx, txt in enumerate(xy8['well']):\n",
    "    ax.annotate(txt, (xy8['xmean'].iloc[idx], xy8['ymean'].iloc[idx]), fontsize=8)\n",
    "for idx, row in seismic_wells.iterrows():\n",
    "    rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.title(path + file);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analize of rhob outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.05\n",
    "seismic_wells = seismic_wells.rename(columns={'mean':'rhob_avg_map', 'p50':'rhob_p50_map', 'p25':'rhob_p25_map', 'p75':'rhob_p75_map'})\n",
    "rhob_mean = df_bal8_v4_flag.groupby('well')[['rhob', 'field']].agg({'rhob':'mean', 'field':'first'}).reset_index()\n",
    "rhob_mean = rhob_mean.rename(columns={'rhob':'rhob_avg_well'})\n",
    "seismic_wells_v2 = seismic_wells.set_index('well').join(rhob_mean.set_index('well')).reset_index()\n",
    "seismic_wells_v2['up'] = seismic_wells_v2['rhob_avg_well'] + cutoff\n",
    "seismic_wells_v2['down'] = seismic_wells_v2['rhob_avg_well'] - cutoff\n",
    "seismic_wells_v2['qc_up'] = np.where((seismic_wells_v2['rhob_avg_map'] >= seismic_wells_v2['up']), 'bigger', 'norm')\n",
    "seismic_wells_v2['qc_down'] = np.where((seismic_wells_v2['rhob_avg_map'] <= seismic_wells_v2['down']), 'lower', 'norm')\n",
    "seismic_wells_v2['qc'] = np.where((seismic_wells_v2['qc_up'] == 'norm') & (seismic_wells_v2['qc_down'] == 'norm'), 'yes', 'no')\n",
    "print('up',seismic_wells_v2.qc_up.value_counts(),\n",
    "      '\\ndown',seismic_wells_v2.qc_down.value_counts(),\n",
    "      '\\ntotal qc', seismic_wells_v2.qc.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.scatterplot(data=seismic_wells_v2, x='rhob_avg_well', y='rhob_avg_map', hue='field')\n",
    "sns.lineplot(x = [1.65, 2.65], y = [1.65, 2.65], color='red', ls='--')\n",
    "sns.lineplot(x = [1.65, 2.65], y = [1.65+cutoff, 2.65+cutoff], color='green', ls='--')\n",
    "sns.lineplot(x = [1.65, 2.65], y = [1.65-cutoff, 2.65-cutoff], color='green', ls='--')\n",
    "down = seismic_wells_v2[seismic_wells_v2.qc_down==0]\n",
    "up = seismic_wells_v2[seismic_wells_v2.qc_up==0]\n",
    "for idx, txt in enumerate(down['well']):\n",
    "    plt.annotate(txt, (down['rhob_avg_well'].iloc[idx], down['rhob_avg_map'].iloc[idx]), fontsize=6, c='r')\n",
    "for idx, txt in enumerate(up['well']):\n",
    "    plt.annotate(txt, (up['rhob_avg_well'].iloc[idx], up['rhob_avg_map'].iloc[idx]), fontsize=6, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=seismic_wells_v2, x='xmean', y='ymean', c='green', label='norm')\n",
    "sns.scatterplot(data=seismic_wells_v2[seismic_wells_v2.qc_up == 'bigger'], x='xmean', y='ymean', c='b', label = 'bigger')\n",
    "sns.scatterplot(data=seismic_wells_v2[seismic_wells_v2.qc_down == 'lower'], x='xmean', y='ymean', c='r', label = 'lower')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density_Bal8 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    if ' 0-80' not in file and 'Mean amplitude' in file:\n",
    "        def seism_upload(file, delimiter):\n",
    "            seismic = pd.read_csv(file, delimiter=delimiter, skiprows=20, names=['x', 'y', 'value', 'column', 'row'])\n",
    "            seismic = seismic.round({'x':0, 'y':0})\n",
    "            return seismic\n",
    "        seismic_map = seism_upload(path + file, ' ')\n",
    "        seismic_map['path'] = path\n",
    "        seismic_map['attr'] = file\n",
    "        print(f\"seismic map <{path + file}> is uploaded\")\n",
    "        \n",
    "        def intersection_maps(map, wells_df, buffer):\n",
    "            geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "            gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "            geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "            gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "            convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "            intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "            return intersection\n",
    "        seismic_map_intersect = intersection_maps(seismic_map, df_bal8_v4_flag, 1500)\n",
    "        print(f'seismic map <{path + file}> is intersected with wells')\n",
    "\n",
    "        def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "            wells_df['xmean_min'] = wells_df['xmean'] - margin/2\n",
    "            wells_df['xmean_max'] = wells_df['xmean'] + margin/2\n",
    "            wells_df['ymean_min'] = wells_df['ymean'] - margin/2\n",
    "            wells_df['ymean_max'] = wells_df['ymean'] + margin/2\n",
    "            seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "            df_lst = []\n",
    "            df_seism_map_zone_lst = []\n",
    "            for idx, row in wells_df.iterrows():\n",
    "                seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                    (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                    (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                    (seism_map_short['y'] < row['ymean_max'])]\n",
    "                seism_map_zone['well'] = row['well']\n",
    "                mean = seism_map_zone.value.mean()\n",
    "                p50 = seism_map_zone.value.quantile(0.5)\n",
    "                p25 = seism_map_zone.value.quantile(0.25)\n",
    "                p75 = seism_map_zone.value.quantile(0.75)\n",
    "                df = pd.DataFrame({'well':row['well'], \n",
    "                                    'phit_net_mean':row['phit_net_mean'], \n",
    "                                    'mean': mean, \n",
    "                                    'p50': p50, \n",
    "                                    'p25': p25, \n",
    "                                    'p75': p75,\n",
    "                                    'xmean':row['xmean'],\n",
    "                                    'ymean':row['ymean'],\n",
    "                                    'xmean_min':row['xmean_min'],\n",
    "                                    'xmean_max':row['xmean_max'],\n",
    "                                    'ymean_min':row['ymean_min'],\n",
    "                                    'ymean_max':row['ymean_max'],\n",
    "                                    'margin':margin,\n",
    "                                    'seism_att':file}, index=[0])\n",
    "                df_seism_map_zone = pd.DataFrame(seism_map_zone)\n",
    "\n",
    "                df_lst.append(df)\n",
    "                df_seism_map_zone_lst.append(df_seism_map_zone)\n",
    "\n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['bottom_left_x'] = result['xmean'] - margin/2\n",
    "            result['bottom_left_y'] = result['ymean'] - margin/2\n",
    "            seism_map_zone = pd.concat(df_seism_map_zone_lst).reset_index(drop=True)\n",
    "            \n",
    "            return result, seism_map_zone\n",
    "        seismic_wells, seism_map_zone = seism_well_correl(seismic_map_intersect, xy8, margin, file)\n",
    "        seismic_map_intersect.loc[seismic_map_intersect.value <= 1.65, 'value'] = np.nan\n",
    "        print(f\"seismic map <{path + file}> to wells dataset is done\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        cb1 = plt.scatter(seismic_map_intersect['x'], seismic_map_intersect['y'], c=seismic_map_intersect['value'], cmap='coolwarm', s=1)\n",
    "        plt.colorbar(cb1)\n",
    "        plt.scatter(xy8['xmean'], xy8['ymean'], c='black', s=1)\n",
    "        for idx, txt in enumerate(xy8['well']):\n",
    "            ax.annotate(txt, (xy8['xmean'].iloc[idx], xy8['ymean'].iloc[idx]), fontsize=8)\n",
    "        for idx, row in seismic_wells.iterrows():\n",
    "            rect = plt.Rectangle((row['bottom_left_x'], row['bottom_left_y']), row['margin'], row['margin'], linewidth=1, edgecolor='b', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        plt.title(path + file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens8 = segyio.open(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\DEN_cube_comb_cut_trend_comp.sgy\")\n",
    "dens8.ilines, dens8.xlines, dens8.samples, len(dens8.ilines), len(dens8.xlines), len(dens8.samples)\n",
    "# df_dens_cube = segy_header_scrape(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\DEN_cube_comb_cut_trend_comp.sgy\", chunk=10000)\n",
    "# df_dens_cube.to_parquet(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\dens_cube8.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dens_cube = pd.read_parquet(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\dens_cube8.gzip\")\n",
    "df_xy_lines = df_dens_cube[['CDP_X', 'CDP_Y', 'INLINE_3D', 'CROSSLINE_3D']]\n",
    "df_xy_lines.columns = df_xy_lines.columns.str.lower()\n",
    "df_xy_lines = df_xy_lines.rename(columns={'cdp_x':'x', 'cdp_y':'y', 'inline_3d':'iline', 'crossline_3d':'xline'})\n",
    "df_xy_lines['x'] = df_xy_lines['x']/100\n",
    "df_xy_lines['y'] = df_xy_lines['y']/100\n",
    "df_xy_lines = df_xy_lines.round({'x':0, 'y':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b02 = df_bal8_v4_flag[df_bal8_v4_flag['well'] == 'B02']\n",
    "\n",
    "df_xy_lines_v2 = df_xy_lines[((df_xy_lines.iline >=3900) & (df_xy_lines.iline <= 6900)) & ((df_xy_lines.iline >= 3900) & (df_xy_lines.iline <= 6900))]\n",
    "# df_xy_lines_v2 = df_xy_lines\n",
    "margin = 100\n",
    "well_xmax = b02['xmean']+margin\n",
    "well_xmin = b02['xmean']-margin\n",
    "well_ymax = b02['ymean']+margin\n",
    "well_ymin = b02['ymean']-margin\n",
    "\n",
    "df_xy_lines_v3 = df_xy_lines_v2[((df_xy_lines_v2['x'] > well_xmin.values[0]) & (df_xy_lines_v2['x'] < well_xmax.values[0])) & \n",
    "                                ((df_xy_lines_v2['y'] > well_ymin.values[0]) & (df_xy_lines_v2['y'] < well_ymax.values[0]))]\n",
    "in_max, xn_max, in_min, xn_min = df_xy_lines_v3.iline.max(), df_xy_lines_v3.xline.max(), df_xy_lines_v3.iline.min(), df_xy_lines_v3.xline.min()\n",
    "\n",
    "tvd_max = round(b02['tvd_scs'].max(),0)\n",
    "tvd_min = round(b02['tvd_scs'].min(),0)\n",
    "tvd_max, tvd_min\n",
    "\n",
    "tvd_max_idx = np.where(dens8.samples.round(0) == tvd_max)[0][0]\n",
    "tvd_min_idx = np.where(dens8.samples.round(0) == tvd_min)[0][0]\n",
    "print(in_max, xn_max, in_min, xn_min, tvd_min_idx,  tvd_max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lexcube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iline_min = in_min\n",
    "iline_max = in_max\n",
    "xline_min = xn_min \n",
    "xline_max = xn_max\n",
    "sample_min = tvd_min_idx-350\n",
    "sample_max = tvd_max_idx\n",
    "\n",
    "offset_val = 0\n",
    "\n",
    "ils = np.arange(iline_min - offset_val, iline_max + offset_val)\n",
    "# xls = np.arange(xline_min - offset_val, xline_max + offset_val)\n",
    "xls = np.arange(xline_min - offset_val, xline_max + offset_val) - dens8.xlines.min()\n",
    "samples_dim = dens8.samples[sample_min:sample_max] # ignore out of bal8 values (manual adjust)\n",
    "\n",
    "three_d_array = np.empty((len(ils), len(xls), len(samples_dim)))\n",
    "# three_d_array = np.empty((ils, len(xls), len(samples_dim)))\n",
    "\n",
    "for il_idx, il in enumerate(ils):\n",
    "    for xl_idx, xl in enumerate(xls):\n",
    "        rhob = dens8.iline[il][xl][sample_min:sample_max] # ignore out of bal8 values (manual adjust)\n",
    "#         gr_adj = (gr - 43.948) / (69.331 - 43.948) * (70.384 - 36.241) + 36.241\n",
    "#         gr_adj = np.where(gr_adj < 0, 0, gr_adj)\n",
    "#         igr = (gr_adj - 33) / (86-33)\n",
    "#         vsh = 1.7 - (3.38-(igr+0.7)**2)**0.5\n",
    "        # rhob = np.where(gr == -1, -9999, gr)\n",
    "        # rhov = np.where(gr > 0.2, 1, gr)\n",
    "#         vsh = np.where(vsh < 0, 0, vsh)\n",
    "        three_d_array[il_idx, xl_idx, :] = rhob\n",
    "\n",
    "data_array = xr.DataArray(three_d_array, coords={\n",
    "    'iline': ils,\n",
    "    'xline': np.arange(xline_min - offset_val, xline_max + offset_val),\n",
    "    'z':samples_dim,\n",
    "})\n",
    "\n",
    "data_array = data_array.transpose('xline','z','iline')\n",
    "\n",
    "w = lexcube.Cube3DWidget(data_array,cmap=\"viridis_r\", vmin=1.95, vmax=2.95)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadir algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGY file\n",
    "v = segyio.open(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\DEN_cube_comb_cut_trend_comp.sgy\")\n",
    "\n",
    "# SEGY coordinates\n",
    "df_cube = pd.read_parquet(r\"C:\\Petrel\\seismic_data_wv\\dens_cube\\dens_cube8.gzip\")\n",
    "\n",
    "df_cube = df_cube[[\n",
    "    'CDP_X', \n",
    "    'CDP_Y', \n",
    "    'INLINE_3D', \n",
    "    'CROSSLINE_3D'\n",
    "]]\n",
    "\n",
    "df_cube['CDP_X'] /= 100\n",
    "df_cube['CDP_Y'] /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./support/well_traj\"\n",
    "\n",
    "def list_files_by_mask(directory, mask, exclude_mask=None):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "\n",
    "    # Filter out files that match the exclude_mask\n",
    "    if exclude_mask:\n",
    "        exclude_pattern = os.path.join(directory, exclude_mask)\n",
    "        exclude_files = glob.glob(exclude_pattern)\n",
    "        files = [file for file in files if file not in exclude_files]\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "files = list_files_by_mask(path, '*.las', '')\n",
    "\n",
    "df_lst = []\n",
    "for well_name in tqdm(files):\n",
    "    las = lasio.read(path + '/' +  well_name)\n",
    "    well_log = las.df().reset_index()[['X','Y','TVD_SCS','DEPTH']]\n",
    "    df = well_log.dropna()\n",
    "    df['WELL'] = well_name.split('.')[0]\n",
    "    df_lst.append(df)\n",
    "\n",
    "well_traj = pd.concat(df_lst).reset_index(drop=True)\n",
    "well_traj_v2 = well_traj[well_traj.WELL.isin(df_bal8_v4_flag.well.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_traj_v2.WELL.unique()\n",
    "df=well_traj[well_traj['WELL']=='C18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z interpolation\n",
    "new_TVD_SCS = np.arange(1380, df['TVD_SCS'].max() + 1)\n",
    "\n",
    "cs_x = CubicSpline(df['TVD_SCS'], df['X'])\n",
    "cs_y = CubicSpline(df['TVD_SCS'], df['Y'])\n",
    "cs_depth = CubicSpline(df['TVD_SCS'], df['DEPTH'])\n",
    "\n",
    "new_x = cs_x(new_TVD_SCS)\n",
    "new_y = cs_y(new_TVD_SCS)\n",
    "new_depth = cs_depth(new_TVD_SCS)\n",
    "\n",
    "interpolated_df = pd.DataFrame({'TVD_SCS': new_TVD_SCS, 'X': new_x, 'Y': new_y, 'DEPTH':new_depth})\n",
    "\n",
    "# Cleaning for extraction\n",
    "interpolated_df = interpolated_df[interpolated_df['TVD_SCS'] >= 1380][interpolated_df['TVD_SCS'] <= 4250]\n",
    "\n",
    "interpolated_df.rename(columns={\n",
    "    'X':'CDP_X',\n",
    "    'Y':'CDP_Y'\n",
    "}, inplace=True)\n",
    "\n",
    "# Closest 4 points\n",
    "tree = cKDTree(df_cube[['CDP_X', 'CDP_Y']])\n",
    "\n",
    "k = 4\n",
    "distances, indices = tree.query(interpolated_df[['CDP_X', 'CDP_Y']], k=k)\n",
    "\n",
    "closest_points = pd.concat([df_cube.iloc[indices[:, i]].reset_index(drop=True) for i in range(k)], axis=1)\n",
    "distances_df = pd.DataFrame(distances, columns=[f'distance_{i+1}' for i in range(k)])\n",
    "\n",
    "closest_points.columns = [f'{col}_{i+1}' for i in range(k) for col in df_cube.columns]\n",
    "\n",
    "result = pd.concat([interpolated_df.reset_index(drop=True), closest_points, distances_df], axis=1)\n",
    "\n",
    "# GR extract\n",
    "def GR_extract(iline, xline, sample):\n",
    "    iline = iline\n",
    "    xline = xline - v.xlines.min()\n",
    "    sample = sample - int(v.samples.min())\n",
    "\n",
    "    return v.iline[iline][xline][sample]\n",
    "\n",
    "def FourPointAvg(row):\n",
    "    nom = (row['RHOB1'] / row['distance_1']) + (row['RHOB2'] / row['distance_2']) + (row['RHOB3'] / row['distance_3']) + (row['RHOB4'] / row['distance_4'])\n",
    "    de = (1 / row['distance_1']) + (1 / row['distance_2']) + (1 / row['distance_3']) + (1 / row['distance_4'])\n",
    "\n",
    "    return nom / de\n",
    "\n",
    "for i in range(4):\n",
    "    result[f'RHOB{i+1}'] = result.apply(lambda row: GR_extract(row[f'INLINE_3D_{i+1}'].astype(int), \n",
    "                                                               row[f'CROSSLINE_3D_{i+1}'].astype(int), \n",
    "                                                               row['TVD_SCS'].astype(int)), axis=1)\n",
    "\n",
    "# GR 4 point average\n",
    "result['RHOB_avg'] = result.apply(lambda row: FourPointAvg(row), axis=1)\n",
    "\n",
    "result_mod = result[[\n",
    "    'DEPTH',\n",
    "    'TVD_SCS',\n",
    "    'RHOB_avg'\n",
    "]]\n",
    "\n",
    "# MD interpolation\n",
    "new_md = np.arange(round(result_mod['DEPTH'].min()), result_mod['DEPTH'].max() + 0.1, 0.1)\n",
    "\n",
    "cs_gravg = CubicSpline(result_mod['DEPTH'], result_mod['RHOB_avg'])\n",
    "cs_tvd = CubicSpline(result_mod['DEPTH'], result_mod['TVD_SCS'])\n",
    "\n",
    "new_gravg = cs_gravg(new_md)\n",
    "new_tvd = cs_tvd(new_md)\n",
    "\n",
    "res_interp = pd.DataFrame({\n",
    "    'DEPTH':new_md, \n",
    "    'TVD_SCS': new_tvd, \n",
    "    'RHOB_avg':new_gravg\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = df_bal8_v4_flag[df_bal8_v4_flag.well == 'C18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3, 7))\n",
    "ax.plot(res_interp['RHOB_avg'], res_interp['TVD_SCS'], label='cube')\n",
    "ax.plot(logs['rhob'], logs['tvd_scs'], label='log')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(1.95, 2.95)\n",
    "# ax.set_ylim(2450, 1900)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

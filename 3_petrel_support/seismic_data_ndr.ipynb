{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import tpot\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.float_format = lambda x: '%.5f' % x\n",
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_rows = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = df_bal8_v4_flag[df_bal8_v4_flag.net == 1].groupby('well')['tst'].count().reset_index()\n",
    "# total = df_bal8_v4_flag.groupby('well')['tst'].count().reset_index()\n",
    "# final = net.merge(total, left_index=True, right_index=True, suffixes=('_net', '_total'))\n",
    "# final['ntg'] = final['tst_net'] / final['tst_total']\n",
    "# final = final.drop(['tst_net', 'tst_total', 'well_total'], axis=1).rename(columns={'well_net': 'well'})\n",
    "# final['fm'] = 'bal8'\n",
    "# final.to_csv('ntg_bal8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal8_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal8_azr_v4.csv')\n",
    "df_bal8_v4.columns = df_bal8_v4.columns.str.lower()\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII sand','formation'] = '1_bal8_sand'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 25','formation'] = '2_bal8_25'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 20','formation'] = '3_bal8_20'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 15','formation'] = '4_bal8_15'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 10','formation'] = '5_bal8_10'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 5','formation'] = '6_bal8_5'\n",
    "well_phit_flag8 = df_bal8_v4[df_bal8_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal8_v4_flag = df_bal8_v4[df_bal8_v4.well.isin(well_phit_flag8)]\n",
    "\n",
    "ntd_top_phi_bot8_bp_v4 = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\layers\\ntd_top_phi_bot8_bp_v4.csv').drop('Unnamed: 0', axis=1)\n",
    "ntd_top_phi_bot8_bp_v4.columns = ntd_top_phi_bot8_bp_v4.columns.str.lower()\n",
    "\n",
    "df_bal10_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal10_vshclp2_v4.csv')\n",
    "df_bal10_v4.columns = df_bal10_v4.columns.str.lower()\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X sand','formation'] = '1_bal10_sand'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 50','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 40','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 20','formation'] = '3_bal10_20'\n",
    "well_phit_flag10 = df_bal10_v4[df_bal10_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal10_v4_flag = df_bal10_v4[df_bal10_v4.well.isin(well_phit_flag10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy8 = df_bal8_v4_flag.groupby('well')[['xmean','ymean','field']].first().reset_index()\n",
    "xy8 = xy8.round({'xmean':0, 'ymean':0})\n",
    "phit8 = df_bal8_v4_flag[df_bal8_v4_flag.net == 1].groupby('well')['phit'].mean().reset_index()\n",
    "xy8_phit = pd.merge(xy8, phit8, left_on='well', right_on='well', how='left')\n",
    "xy8_phit = xy8_phit.rename(columns={'phit':'phit_net_mean'})\n",
    "\n",
    "xy10 = df_bal10_v4_flag.groupby('well')[['xmean','ymean','field']].first().reset_index()\n",
    "xy10 = xy10.round({'xmean':0, 'ymean':0})\n",
    "phit10 = df_bal10_v4_flag[df_bal10_v4_flag.net == 1].groupby('well')['phit'].mean().reset_index()\n",
    "xy10_phit = pd.merge(xy10, phit10, left_on='well', right_on='well', how='left')\n",
    "xy10_phit = xy10_phit.rename(columns={'phit':'phit_net_mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seism data analize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_mask(directory, mask):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "files = list_files_by_mask('input/', 'Bal8*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seis_well_run(file, wells_df, buffer, margin, disp_map=1, disp_xplots=1):\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "        seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seism = seism_upload(file, ' ')\n",
    "    print(f\"seismic map {file} is uploaded\")\n",
    "    \n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seism_intersect = intersection_maps(seism, wells_df, buffer)\n",
    "    print('seismic map is intersected with wells')\n",
    "\n",
    "    def display_map(seism_map, wells_df, file):\n",
    "        plt.subplots(figsize=(14, 6))\n",
    "        plt.scatter(seism_map['x'], seism_map['y'], c=seism_map['value'], cmap='coolwarm')\n",
    "        sc = plt.scatter(seism_map['x'], seism_map['y'], c=seism_map['value'], cmap='coolwarm', alpha=0.5)\n",
    "        plt.colorbar(sc)\n",
    "        plt.scatter(wells_df['xmean'], wells_df['ymean'], c=wells_df['phit_net_mean'], s=50, ec='black', lw=0.5, alpha=0.5)\n",
    "        for i, txt in enumerate(wells_df['well']):\n",
    "            plt.annotate(txt, (wells_df['xmean'].iloc[i], wells_df['ymean'].iloc[i]), fontsize=6)\n",
    "        plt.show()\n",
    "        plt.title(f'Seismic {file} map with wells')\n",
    "    if disp_map == 1:\n",
    "        display_map(seism_intersect, wells_df, file)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    def seism_well_correl(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "    seism_wells = seism_well_correl(seism_intersect, wells_df, margin, file)\n",
    "    print(f\"map {file} to wells dataset is done\")\n",
    "\n",
    "    def seism_well_xplots(seism_well):\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "        sns.scatterplot(data=seism_well, x='phit_net_mean', y='mean', ax=ax[0])\n",
    "        sns.scatterplot(data=seism_well, x='phit_net_mean', y='p25', ax=ax[2])\n",
    "        sns.scatterplot(data=seism_well, x='phit_net_mean', y='p50', ax=ax[1])\n",
    "        sns.scatterplot(data=seism_well, x='phit_net_mean', y='p75', ax=ax[3])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.suptitle(f'Seismic {file} vs wells')\n",
    "    if disp_xplots == 1:\n",
    "        seism_well_xplots(seism_wells)\n",
    "    \n",
    "    resulting_dict = {'seism_map':seism_intersect, 'seism_wells':seism_wells}\n",
    "    \n",
    "    return resulting_dict\n",
    "\n",
    "seism_lst = []\n",
    "for file in files:\n",
    "    seism_lst.append(seis_well_run('input/'+file, xy8_phit, buffer=1500, margin=100, disp_map=0, disp_xplots=0)['seism_wells'])\n",
    "\n",
    "final = pd.concat(seism_lst).reset_index(drop=True)\n",
    "final.to_csv('io/seism_wells_bal8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('io/seism_wells_bal8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for att in final.seism_att.unique():\n",
    "    data = final[final.seism_att == att]\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "    sns.scatterplot(data=data, x='phit_net_mean', y='mean', hue='field', ax=ax[0])\n",
    "    sns.scatterplot(data=data, x='phit_net_mean', y='p25', hue='field', ax=ax[2])\n",
    "    sns.scatterplot(data=data, x='phit_net_mean', y='p50', hue='field', ax=ax[1])\n",
    "    sns.scatterplot(data=data, x='phit_net_mean', y='p75', hue='field', ax=ax[3])\n",
    "    plt.suptitle(f'Seismic {att} vs wells')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seism in final.seism_att.unique():\n",
    "    ref = final.seism_att.unique()[0]\n",
    "    data1 = final[final.seism_att == ref]\n",
    "    data2 = final[final.seism_att == seism]\n",
    "    siesm_name = data2.seism_att.unique()[0]\n",
    "    data_join = data1.merge(data2, on='well', suffixes=('_ref', '_seism'))\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(data=data_join, x='mean_ref', y='mean_seism', hue='field_ref')\n",
    "    plt.title(f'{ref} vs {siesm_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porosity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_upload(file, delimiter):\n",
    "    seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "    seismic = seismic.round({'x':0, 'y':0})\n",
    "    return seismic\n",
    "seism = seism_upload('Bal8_AV', ' ')\n",
    "\n",
    "def intersection_maps(map, wells_df, buffer):\n",
    "    geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "    gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "    geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "    gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "    convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "    intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "    return intersection\n",
    "seism_intersect = intersection_maps(seism, xy8_phit, 1500)\n",
    "print('seismic map is intersected with wells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_av = final[final.seism_att == 'Bal8_AV']\n",
    "# df_av = df_av.rename(columns={'mean':'mean_av', 'p25':'p25_av', 'p50':'p50_av', 'p75':'p75_av'})\n",
    "sns.scatterplot(data=df_av, x='phit_net_mean', y='mean', hue='field')\n",
    "plt.legend(loc='upper right')\n",
    "for idx, txt in enumerate(df_av['well']):\n",
    "    plt.annotate(txt, (df_av['phit_net_mean'].iloc[idx], df_av['mean'].iloc[idx]), fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_av_v2 = df_av[~df_av.well.isin(['B39', 'D02Y', 'D34', 'B31', 'B20'])]\n",
    "xy = df_bal8_v4_flag.groupby('well')[['xmean','ymean']].first().reset_index()\n",
    "df_av_v2 = df_av_v2.merge(xy, on='well')\n",
    "df_av_v2 = df_av_v2.rename(columns = {'xmean':'x', 'ymean':'y'})\n",
    "df_av_v2 = df_av_v2[~df_av_v2.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])]\n",
    "sns.scatterplot(data=df_av_v2, x='phit_net_mean', y='mean', hue='field')\n",
    "plt.legend(loc='upper right')\n",
    "for idx, txt in enumerate(df_av_v2['well']):\n",
    "    plt.annotate(txt, (df_av_v2['phit_net_mean'].iloc[idx], df_av_v2['mean'].iloc[idx]), fontsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_av_v2[['x', 'y', 'mean']].rename(columns={'mean':'value'})\n",
    "y = df_av_v2['phit_net_mean']\n",
    "\n",
    "X_train, y_train = X, y\n",
    "X_test = seism_intersect[['x', 'y', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr = tpot.TPOTRegressor(n_jobs=7, verbosity=2, generations=20, \n",
    "                           warm_start=True, random_state=42, memory='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tregr.fit(X_train, y_train)\n",
    "tregr.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tregr.fitted_pipeline_, 'tregr_v6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descr = tregr.fitted_pipeline_\n",
    "model_descr.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load('tregr_v1.pkl')\n",
    "model = joblib.load('tregr_v2.pkl')\n",
    "X_test = X_test.rename(columns={'value':'mean_av'})\n",
    "y_pred = model.predict(X_test)\n",
    "model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],\n",
    "                          'phit_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "cb1 = plt.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm')\n",
    "plt.colorbar(cb1)\n",
    "cb2 = plt.scatter(df_av_v2['x'], df_av_v2['y'], c=df_av_v2['phit_net_mean'], s=50, ec='black', lw=0.5, alpha=0.5, cmap='coolwarm')\n",
    "plt.colorbar(cb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_correl_pred(seism_map, wells_df, margin, file):\n",
    "    wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "    wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "    wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "    wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "    seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "    df_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        mean = seism_map_zone.value.mean()\n",
    "        df = pd.DataFrame({'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            'field':row['field'],\n",
    "                            'mean': mean, \n",
    "                            'margin':margin,\n",
    "                            'seism_att':file}, index=[0])\n",
    "        df_lst.append(df)\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "model_df = model_df.rename(columns={'phit_pred':'value'})\n",
    "wells_pred = seism_well_correl_pred(model_df, xy8_phit, 100, 'Bal8_AV')\n",
    "wells_pred = wells_pred[['well', 'mean']].rename(columns={'mean':'phit_pred'})\n",
    "\n",
    "wells_true = df_av_v2[['well','phit_net_mean','field']]\n",
    "wells_pred_true = wells_pred.set_index('well').join(wells_true.set_index('well'), how='inner').reset_index()\n",
    "wells_pred_true['up_1.15pu'] = wells_pred_true.phit_net_mean+0.0115\n",
    "wells_pred_true['down_1.15pu'] = wells_pred_true.phit_net_mean-0.0115\n",
    "wells_pred_true['qc'] = np.where((wells_pred_true.phit_pred >= wells_pred_true['down_1.15pu']) \n",
    "& (wells_pred_true.phit_pred <= wells_pred_true['up_1.15pu']), 1, 0)\n",
    "display(wells_pred_true.qc.value_counts(normalize=True))\n",
    "\n",
    "sns.scatterplot(data=wells_pred_true, x='phit_net_mean', y='phit_pred', hue='field')\n",
    "sns.lineplot(x=[0.13, 0.29], y=[0.13, 0.29], color='red', ls='--')\n",
    "sns.lineplot(x=[0.13, 0.29], y=[0.13+0.0115, 0.29+0.0115], color='black', ls='--')\n",
    "sns.lineplot(x=[0.13, 0.29], y=[0.13-0.0115, 0.29-0.0115], color='black', ls='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final script Bal8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_mask(directory, mask):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "files8 = list_files_by_mask('', 'Bal8*')\n",
    "files8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst8 = []\n",
    "for file in tqdm(files8[:1]):\n",
    "    def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "        def seism_upload(file, delimiter):\n",
    "            seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "            seismic = seismic.round({'x':0, 'y':0})\n",
    "            return seismic\n",
    "        seismic_map = seism_upload(file, ' ')\n",
    "        print(f\"seismic map {file} is uploaded\")\n",
    "        \n",
    "        def intersection_maps(map, wells_df, buffer):\n",
    "            geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "            gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "            geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "            gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "            convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "            intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "            return intersection\n",
    "        seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "        print('seismic map is intersected with wells')\n",
    "    \n",
    "        def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "            wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "            wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "            wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "            wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "            seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "            df_lst = []\n",
    "            for idx, row in wells_df.iterrows():\n",
    "                seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                    (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                    (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                    (seism_map_short['y'] < row['ymean_max'])]\n",
    "                mean = seism_map_zone.value.mean()\n",
    "                p50 = seism_map_zone.value.quantile(0.5)\n",
    "                p25 = seism_map_zone.value.quantile(0.25)\n",
    "                p75 = seism_map_zone.value.quantile(0.75)\n",
    "                df = pd.DataFrame({'well':row['well'], \n",
    "                                    'phit_net_mean':row['phit_net_mean'], \n",
    "                                    'field':row['field'],\n",
    "                                    'mean': mean, \n",
    "                                    'p50': p50, \n",
    "                                    'p25': p25, \n",
    "                                    'p75': p75,\n",
    "                                    'x':row['xmean'],\n",
    "                                    'y':row['ymean'],\n",
    "                                    'xmean_min':row['xmean_min'],\n",
    "                                    'xmean_max':row['xmean_max'],\n",
    "                                    'ymean_min':row['ymean_min'],\n",
    "                                    'ymean_max':row['ymean_max'],\n",
    "                                    'margin_init':margin,\n",
    "                                    'seism_att':file}, index=[0])\n",
    "                df_lst.append(df)\n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            return result\n",
    "        well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "        print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "        dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "        \n",
    "        return dict_with_results\n",
    "    print(f'siesmic maps {file} and well data preparation is started')\n",
    "    data_bal8 = seism_well_run_v2(file, xy8_phit, buffer=1500, margin=100)\n",
    "    seismic_map8 = data_bal8['seismic_map_intersect']\n",
    "    well_data8 = data_bal8['well_data_from_seismic_map']\n",
    "\n",
    "    def preprocessing_data(seismic_map, well_data):\n",
    "        well_data_v2 = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'B31', 'B20'])] #outliers\n",
    "        well_data_v3 = well_data_v2[~well_data_v2.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "\n",
    "        X = well_data_v3[['x', 'y', 'mean']].rename(columns={'mean':'value'})\n",
    "        y = well_data_v3['phit_net_mean']\n",
    "        X_train, y_train = X, y\n",
    "        X_test = seismic_map[['x', 'y', 'value']]\n",
    "        return X_train, y_train, X_test, well_data_v3\n",
    "    print('data is preprocessed')\n",
    "    X_train8, y_train8, X_test8, well_data8_v3 = preprocessing_data(seismic_map8, well_data8)\n",
    "\n",
    "    tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=1, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "    tregr8.fit(X_train8, y_train8)\n",
    "    tregr8.fitted_pipeline_\n",
    "    joblib.dump(tregr8.fitted_pipeline_, f'tregr_{file}.pkl')\n",
    "    print('model is trained')\n",
    "\n",
    "    model8 = joblib.load(f'tregr_{file}.pkl')\n",
    "    y_pred8 = model8.predict(X_test8)\n",
    "    model_df8 = pd.DataFrame({'x': X_test8.iloc[:,0], 'y': X_test8.iloc[:,1],'phit_pred': y_pred8})\n",
    "\n",
    "    def model_postprocessing8(model_df, well_data_v3, file, margin):\n",
    "        def seism_well_correl_pred(seism_map, wells_df, margin, file):\n",
    "            wells_df['xmean_min'] = wells_df['x'] - margin\n",
    "            wells_df['xmean_max'] = wells_df['x'] + margin\n",
    "            wells_df['ymean_min'] = wells_df['y'] - margin\n",
    "            wells_df['ymean_max'] = wells_df['y'] + margin\n",
    "            seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "            df_lst = []\n",
    "            for idx, row in wells_df.iterrows():\n",
    "                seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                    (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                    (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                    (seism_map_short['y'] < row['ymean_max'])]\n",
    "                mean = seism_map_zone.value.mean()\n",
    "                df = pd.DataFrame({'well':row['well'], \n",
    "                                    'phit_net_mean':row['phit_net_mean'], \n",
    "                                    'field':row['field'],\n",
    "                                    'mean': mean, \n",
    "                                    'margin_pred':margin,\n",
    "                                    'seism_att':file}, index=[0])\n",
    "                df_lst.append(df)\n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            return result\n",
    "\n",
    "        model_df = model_df.rename(columns={'phit_pred':'value'})\n",
    "        wells_pred = seism_well_correl_pred(model_df, well_data_v3, margin, 'Bal8_AV')\n",
    "        wells_pred = wells_pred[['well', 'mean']].rename(columns={'mean':'phit_pred'})\n",
    "\n",
    "        wells_pred_true = well_data_v3.set_index('well').join(wells_pred.set_index('well'), how='inner').reset_index()\n",
    "\n",
    "        wells_pred_true['algorithm'] = tregr8.fitted_pipeline_\n",
    "        wells_pred_true['up_1.15pu'] = wells_pred_true.phit_net_mean+0.0115\n",
    "        wells_pred_true['down_1.15pu'] = wells_pred_true.phit_net_mean-0.0115\n",
    "\n",
    "        wells_pred_true['qc'] = np.where((wells_pred_true.phit_pred >= wells_pred_true['down_1.15pu']) \n",
    "        & (wells_pred_true.phit_pred <= wells_pred_true['up_1.15pu']), 1, 0)\n",
    "\n",
    "        dict_qc = {'1':wells_pred_true.qc.value_counts(normalize=True)[1], '0':wells_pred_true.qc.value_counts(normalize=True)[0]}\n",
    "\n",
    "        wells_pred_true['qc_result'] = [dict_qc] * len(wells_pred_true)\n",
    "        wells_pred_true.qc_result.iloc[0]\n",
    "        return wells_pred_true\n",
    "    print('model is postprocessed')\n",
    "    wells_pred_true8 = model_postprocessing8(model_df8, well_data8_v3, file, margin=100)\n",
    "    wells_pred_true8['scoring'] = 'r2'\n",
    "    print(f'model based on {file} is ready:', wells_pred_true8.qc_result.iloc[0])\n",
    "    df_lst8.append(wells_pred_true)\n",
    "\n",
    "final_pred8 = pd.concat(df_lst8).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred8.to_csv('final_pred_bal8_scoring_r2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization best result bal8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k01 = pd.read_csv(r'C:\\jupyter\\SPP\\input\\ACG_k01.csv')[1:].drop('datasetName', axis=1)\n",
    "k01 = k01.rename(columns={'wellName':'well'})\n",
    "k01 = k01[k01.FORMATION.isin(['Balakhany VIII sand', 'Balakhany VIII 20','Balakhany VIII 15', 'Balakhany VIII 10', 'Balakhany VIII 5'])]\n",
    "k01['FORMATION_up'] = 'Balakhany VIII'\n",
    "k01['field'] = 'ACE'\n",
    "for col in [    'MD', 'AREA', 'BADPORLOG', 'FLANK', 'Fluidcode',\n",
    "                'FLUIDCODE_PP', 'GR_N', 'GRMATRIX', 'GRSHALE', 'LPERM',\n",
    "                'LPERM_DS_Bal', 'LPERM_US_Bal', 'NET', 'NPSS', 'PHIT', 'RDEEP', 'RHOB',\n",
    "                'RHOF', 'RHOMA', 'TST', 'TVD_SCS', 'X', 'Y']:\n",
    "    k01[col] = pd.to_numeric(k01[col], errors='coerce')\n",
    "k01 = k01[(k01.PHIT > 0)]\n",
    "k01 = k01.round({'MD':1, 'TVD_SCS':1, 'TST':1, 'X':0, 'Y':0})\n",
    "for col in ['well', 'FORMATION', 'FORMATION_up', 'field']:\n",
    "    k01[col] = k01[col].astype('string')\n",
    "\n",
    "def interpolate_by_depth_fm_run_k01(df, step):\n",
    "    df_tst = df[df.TST.notna()].round({'MD':1})\n",
    "    \n",
    "    def interpolate_by_depth_fm_v2(one_well, step):\n",
    "        one_well = one_well.sort_values(by='TST')\n",
    "        well_name = one_well[\"well\"].iloc[0]\n",
    "        formation = one_well[\"FORMATION\"].iloc[0]\n",
    "        formation_up = one_well[\"FORMATION_up\"].iloc[0]\n",
    "        field = one_well[\"field\"].iloc[0]\n",
    "        data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "        starting_tst = one_well[\"TST\"].iloc[0]\n",
    "        new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "        col_lst = []\n",
    "        for col in one_well.columns:\n",
    "            if col not in ['well','FORMATION_up', 'FORMATION','field']:\n",
    "                interp = interp1d(one_well['TST'], one_well[col], kind='linear', fill_value=\"extrapolate\")\n",
    "                new_data = {col: interp(new_TST_values)}\n",
    "                new_df = pd.DataFrame(new_data)\n",
    "                col_lst.append(new_df)\n",
    "        new_df = pd.concat(col_lst, axis=1)\n",
    "        new_df['well'] = well_name\n",
    "        new_df['TST'] = new_TST_values\n",
    "        # new_df['FORMATION'] = formation\n",
    "        # new_df['FORMATION_up'] = formation_up\n",
    "        # new_df['field'] = field #Index(['FORMATION', 'FORMATION_up', 'field'], dtype='object')\n",
    "        # new_df = new_df[[   'well', \n",
    "        #                     'TST', 'tst_index', 'MD',  'DEVI', 'HAZI', 'NET', 'NET_VSH', 'LPERM',\n",
    "        #                     'PHIT', 'GR_N', 'VSH', 'NPSS', 'RHOB', 'RDEEP', 'SON', 'SONSH',\n",
    "        #                     'TVD_SCS', 'X_traj', 'Y_traj', 'Xmean', 'Ymean', 'RHOF', 'RHOMA',\n",
    "        #                     'tst_sample', 'NET_clp', 'NET_clp2', 'phit_flag', 'PERM_DS', 'PERM_US',\n",
    "        #                     'k_htst', 'KHtst', 'VSH_smooth', 'NET_smooth', 'NET_orig',\n",
    "        #                     'NET_VSH_orig', 'TST_interv', 'TST_interv_fu', 'fluid_code', 'calc',\n",
    "        #                     'calc_net', 'phitd_npss']]\n",
    "        return new_df\n",
    "    df_lst = []\n",
    "    for well in tqdm(df_tst.well.unique()):\n",
    "        well_data = df_tst[df_tst.well == well]\n",
    "        well_data_interp = interpolate_by_depth_fm_v2(well_data, 0.1)\n",
    "        df_lst.append(well_data_interp)\n",
    "    df_interp = pd.concat(df_lst)\n",
    "    df_interp = df_interp.round({'MD':1, 'TVD_SCS':1, 'TST':1})\n",
    "    print('Start joining')\n",
    "    def well_bal_interp_join(dataset):\n",
    "        df_tst = df[(df.TST.notna()) & (df.FORMATION_up.notna())].round({'MD':1})\n",
    "        data_fu = df_tst[['well','MD','FORMATION_up', 'FORMATION', 'field']]\n",
    "        well_join = dataset.set_index(['well','MD']).join(data_fu.set_index(['well','MD'])).reset_index()\n",
    "        well_join.insert(3, 'FORMATION_up', well_join.pop('FORMATION_up'))\n",
    "        well_join.insert(4, 'FORMATION', well_join.pop('FORMATION'))\n",
    "        # well_join.insert(5, 'tst_index', well_join.pop('tst_index'))\n",
    "        return well_join\n",
    "    well_interp_v2 = well_bal_interp_join(df_interp)\n",
    "    # well_interp_v2.loc[well_interp_v2.NET_VSH > 0, 'NET_VSH'] = 1\n",
    "    # well_interp_v2.loc[well_interp_v2.NET > 0, 'NET'] = 1\n",
    "    \n",
    "    df_lst_2 = []\n",
    "    for well in well_interp_v2.well.unique():\n",
    "        field_data = well_interp_v2[well_interp_v2.well == well]\n",
    "        field_data.field = field_data.field.fillna(method = 'ffill')\n",
    "        field_data.field = field_data.field.fillna(method = 'bfill')\n",
    "        field_data.FORMATION_up = field_data.FORMATION_up.fillna(method = 'ffill')\n",
    "        field_data.FORMATION_up = field_data.FORMATION_up.fillna(method = 'bfill')\n",
    "        field_data.FORMATION = field_data.FORMATION.fillna(method = 'ffill')\n",
    "        field_data.FORMATION = field_data.FORMATION.fillna(method = 'bfill')\n",
    "        df_lst_2.append(field_data)\n",
    "    well_interp_v3 = pd.concat(df_lst_2)\n",
    "\n",
    "    return well_interp_v3\n",
    "\n",
    "k01_intepr = interpolate_by_depth_fm_run_k01(k01, 0.1)\n",
    "k01_intepr.columns = k01_intepr.columns.str.lower()\n",
    "k01_intepr['son'] = 0\n",
    "k01_intepr['sonsh'] = 0\n",
    "k01_intepr['xmean'] = k01_intepr.x.mean()\n",
    "k01_intepr['ymean'] = k01_intepr.y.mean()\n",
    "k01_gb = k01_intepr[k01_intepr.net==1].groupby('well')[['phit', 'xmean', 'ymean']].mean().reset_index()\n",
    "k01_gb = k01_gb.rename(columns={'phit':'phit_w_avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Bal8_SNA'\n",
    "def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "        seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seismic_map = seism_upload(file, ' ')\n",
    "    print(f\"seismic map {file} is uploaded\")\n",
    "    \n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "    print('seismic map is intersected with wells')\n",
    "\n",
    "    def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'x':row['xmean'],\n",
    "                                'y':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin_init':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "    well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "    print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "    dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "    \n",
    "    return dict_with_results\n",
    "print(f'siesmic maps {file} and well data preparation is started')\n",
    "data_bal8 = seism_well_run_v2(file, xy8_phit, buffer=1500, margin=100)\n",
    "seismic_map = data_bal8['seismic_map_intersect']\n",
    "well_data = data_bal8['well_data_from_seismic_map']\n",
    "X_test = seismic_map[['x', 'y', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.read_csv('final_pred_bal8_scoring_r2.csv')\n",
    "model = joblib.load(f'tregr_{file}.pkl')\n",
    "X_test = X_test.rename(columns={'mean':'value'})\n",
    "y_pred = model.predict(X_test)\n",
    "model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1],\n",
    "                          'phit_pred': y_pred})\n",
    "final_pred[final_pred.seism_att == file].qc_result.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "xy8_phit_preproc = xy8_phit[~xy8_phit.well.isin(['B39', 'D02Y', 'D34', 'B31', 'B20',\n",
    "                                                 'B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])]\n",
    "all_values = pd.concat([xy8_phit_preproc.phit_net_mean, model_df.phit_pred, k01_gb.phit_w_avg]).reset_index(drop=True)\n",
    "norm = plt.Normalize(all_values.min(), all_values.max())\n",
    "cb1 = plt.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', norm=norm, s=1)\n",
    "# colorbar1 = plt.colorbar(cb1)\n",
    "# colorbar1.set_label('phit_model')\n",
    "cb2 = plt.scatter(  xy8_phit_preproc['xmean'], \n",
    "                    xy8_phit_preproc['ymean'], \n",
    "                    c=xy8_phit_preproc['phit_net_mean'], \n",
    "                    s=50, ec='black', lw=0.5, alpha=1, norm=norm, cmap='coolwarm')\n",
    "# colorbar2 = plt.colorbar(cb2)\n",
    "# colorbar2.set_label('phit_wells')\n",
    "plt.scatter(k01_gb['xmean'], k01_gb['ymean'], c=k01_gb['phit_w_avg'], norm=norm, \n",
    "            s=50, ec='black', lw=0.5, alpha=0.75, cmap='coolwarm')\n",
    "plt.title(f'phit prediction based on {file}');\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phit_pred_sna = final_pred8[final_pred8.seism_att == file].sort_values('phit_net_mean')\n",
    "dict_obj = ast.literal_eval(phit_pred_sna.qc_result.iloc[0])\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "sns.lineplot(data=phit_pred_sna, x='well', y='phit_net_mean', ax=ax, label = 'phit_net_mean')\n",
    "sns.lineplot(data=phit_pred_sna, x='well', y='phit_pred', ax=ax, label = 'phit_pred')\n",
    "ax.fill_between( phit_pred_sna['well'], \n",
    "                    phit_pred_sna['phit_net_mean'] - 0.0115, \n",
    "                    phit_pred_sna['phit_net_mean'] + 0.0115, \n",
    "                    color='b', alpha=0.2) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=6)\n",
    "plt.title(f\"phit_net_mean vs phit_pred based on {phit_pred_sna.seism_att.iloc[0]} with 1:{dict_obj['1']:.3f}\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test K01 bal8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_correl_test(seism_map, wells_df, margin, file):\n",
    "    \"\"\"\n",
    "    well_df.columns = ['well', 'phit_net_mean', 'x', 'y']\n",
    "    seism_map.columns = ['x', 'y', 'phit_pred']\n",
    "    \"\"\" \n",
    "    wells_df['xmean_min'] = wells_df['x'] - margin\n",
    "    wells_df['xmean_max'] = wells_df['x'] + margin\n",
    "    wells_df['ymean_min'] = wells_df['y'] - margin\n",
    "    wells_df['ymean_max'] = wells_df['y'] + margin\n",
    "    seism_map_short = seism_map[['x', 'y', 'phit_pred']]\n",
    "\n",
    "    df_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        mean = seism_map_zone.phit_pred.mean()\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            # 'field':row['field'],\n",
    "                            'mean': mean, \n",
    "                            'margin_pred':margin,\n",
    "                            'seism_att':file}, index=[0])\n",
    "        df_lst.append(df)\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    return result\n",
    "k01_gb = k01_gb.rename(columns = {'xmean':'x', 'ymean':'y', 'phit_w_avg':'phit_net_mean'})\n",
    "test_k01 = seism_well_correl_test(model_df, k01_gb, 30, 'Bal8_SNA')\n",
    "test_k01['diff'] = test_k01.phit_net_mean - test_k01['mean']\n",
    "test_k01['up_1.15pu'] = test_k01.phit_net_mean+0.0115\n",
    "test_k01['down_1.15pu'] = test_k01.phit_net_mean-0.0115\n",
    "test_k01['qc'] = np.where((test_k01['mean'] >= test_k01['down_1.15pu']) & (test_k01['mean'] <= test['up_1.15pu']), 1, 0)\n",
    "test_k01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaing phit_pred maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_mask(directory, mask):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "tregr = list_files_by_mask('', 'tregr_*')\n",
    "files = list_files_by_mask('', 'Bal8_*')\n",
    "df_files_tregr = pd.DataFrame(zip(tregr,files), columns=['model','seismic'])\n",
    "df_files_tregr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "        seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seismic_map = seism_upload(file, ' ')\n",
    "    print(f\"seismic map {file} is uploaded\")\n",
    "    \n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "    print('seismic map is intersected with wells')\n",
    "\n",
    "    def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'x':row['xmean'],\n",
    "                                'y':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin_init':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "    well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "    print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "    dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "    \n",
    "    return dict_with_results\n",
    "\n",
    "for idx, row in df_files_tregr.iterrows():\n",
    "    print(f\"siesmic maps {row['seismic']} and model {row['model']} are started\")\n",
    "    data_bal8 = seism_well_run_v2(row['seismic'], xy8_phit, buffer=1500, margin=100)\n",
    "    seismic_map = data_bal8['seismic_map_intersect']\n",
    "    X_test = seismic_map[['x', 'y', 'value']]\n",
    "\n",
    "    model = joblib.load(row['model'])\n",
    "    X_test = X_test.rename(columns={'mean':'value'})\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_df = pd.DataFrame({'x': X_test.iloc[:,0], 'y': X_test.iloc[:,1], 'phit_pred': y_pred})\n",
    "\n",
    "    phit_pred_sna = final_pred[final_pred.seism_att == row['seismic']]\n",
    "    dict_obj = ast.literal_eval(phit_pred_sna.qc_result.iloc[0])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    cb1 = plt.scatter(model_df['x'], model_df['y'], c=model_df['phit_pred'], cmap='coolwarm', norm=norm, s=1)\n",
    "    colorbar1 = plt.colorbar(cb1)\n",
    "    plt.title(f\"phit prediction based on {row['seismic']} and model {row['model']} and score {dict_obj['1']:.3f}\")\n",
    "    plt.show();\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Bal8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(well_data8.drop('phit_net_mean', axis=1), well_data8['phit_net_mean'], test_size=0.3, random_state=42)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Bal8_SNA'\n",
    "\n",
    "def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "        seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seismic_map = seism_upload(file, ' ')\n",
    "    print(f\"seismic map {file} is uploaded\")\n",
    "    \n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "    print('seismic map is intersected with wells')\n",
    "\n",
    "    def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'x':row['xmean'],\n",
    "                                'y':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin_init':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "    well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "    print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "    dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "    \n",
    "    return dict_with_results\n",
    "print(f'siesmic maps {file} and well data preparation is started')\n",
    "data_bal8 = seism_well_run_v2(file, xy8_phit, buffer=1500, margin=100)\n",
    "seismic_map8 = data_bal8['seismic_map_intersect']\n",
    "well_data8 = data_bal8['well_data_from_seismic_map']\n",
    "\n",
    "def preprocessing_data(seismic_map, well_data):\n",
    "    well_data_v2 = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'B31', 'B20'])] #outliers\n",
    "    well_data_v3 = well_data_v2[~well_data_v2.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(well_data_v3.drop(['phit_net_mean']), well_data_v3['phit_net_mean'], test_size=0.3, random_state=42)\n",
    "\n",
    "    X = well_data_v3[['x', 'y', 'mean']].rename(columns={'mean':'value'})\n",
    "    y = well_data_v3['phit_net_mean']\n",
    "\n",
    "    \n",
    "\n",
    "    X_test = seismic_map[['x', 'y', 'value']]\n",
    "    return X_train, y_train, X_val, y_val, X_test, well_data_v3\n",
    "print('data is preprocessed')\n",
    "X_train8, y_train8, X_val8, y_val8, X_test8, well_data8_v3 = preprocessing_data(seismic_map8, well_data8)\n",
    "\n",
    "tregr8 = tpot.TPOTRegressor(n_jobs=7, verbosity=1, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "tregr8.fit(X_train8, y_train8)\n",
    "tregr8.fitted_pipeline_\n",
    "joblib.dump(tregr8.fitted_pipeline_, f'tregr_test_{file}.pkl')\n",
    "print('model is trained')\n",
    "\n",
    "model8 = joblib.load(f'tregr_test_{file}.pkl')\n",
    "y_pred8 = model8.predict(X_test8)\n",
    "model_df8 = pd.DataFrame({'x': X_test8.iloc[:,0], 'y': X_test8.iloc[:,1],'phit_pred': y_pred8})\n",
    "\n",
    "def model_postprocessing8(model_df, well_data_v3, file, margin):\n",
    "    def seism_well_correl_pred(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['x'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['x'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['y'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['y'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'margin_pred':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "\n",
    "    model_df = model_df.rename(columns={'phit_pred':'value'})\n",
    "    wells_pred = seism_well_correl_pred(model_df, well_data_v3, margin, 'Bal8_AV')\n",
    "    wells_pred = wells_pred[['well', 'mean']].rename(columns={'mean':'phit_pred'})\n",
    "\n",
    "    wells_pred_true = well_data_v3.set_index('well').join(wells_pred.set_index('well'), how='inner').reset_index()\n",
    "\n",
    "    wells_pred_true['algorithm'] = tregr8.fitted_pipeline_\n",
    "    wells_pred_true['up_1.15pu'] = wells_pred_true.phit_net_mean+0.0115\n",
    "    wells_pred_true['down_1.15pu'] = wells_pred_true.phit_net_mean-0.0115\n",
    "\n",
    "    wells_pred_true['qc'] = np.where((wells_pred_true.phit_pred >= wells_pred_true['down_1.15pu']) \n",
    "    & (wells_pred_true.phit_pred <= wells_pred_true['up_1.15pu']), 1, 0)\n",
    "\n",
    "    dict_qc = {'1':wells_pred_true.qc.value_counts(normalize=True)[1], '0':wells_pred_true.qc.value_counts(normalize=True)[0]}\n",
    "\n",
    "    wells_pred_true['qc_result'] = [dict_qc] * len(wells_pred_true)\n",
    "    wells_pred_true.qc_result.iloc[0]\n",
    "    return wells_pred_true\n",
    "print('model is postprocessed')\n",
    "wells_pred_true8 = model_postprocessing8(model_df8, well_data8_v3, file, margin=100)\n",
    "wells_pred_true8['scoring'] = 'r2'\n",
    "print(f'model based on {file} is ready:', wells_pred_true8.qc_result.iloc[0])\n",
    "\n",
    "final_pred8_test1 = wells_pred_true8\n",
    "val_test1 = X_val8\n",
    "val_test1['phit_net_mean'] = y_val8\n",
    "val_test1_v2 = val_test1.join(xy8_phit['well'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seism_well_correl_test(seism_map, wells_df, margin, file):\n",
    "    \"\"\"\n",
    "    well_df.columns = ['well', 'phit_net_mean', 'x', 'y']\n",
    "    seism_map.columns = ['x', 'y', 'phit_pred']\n",
    "    \"\"\" \n",
    "    wells_df['xmean_min'] = wells_df['x'] - margin\n",
    "    wells_df['xmean_max'] = wells_df['x'] + margin\n",
    "    wells_df['ymean_min'] = wells_df['y'] - margin\n",
    "    wells_df['ymean_max'] = wells_df['y'] + margin\n",
    "    seism_map_short = seism_map[['x', 'y', 'phit_pred']]\n",
    "\n",
    "    df_lst = []\n",
    "    for idx, row in wells_df.iterrows():\n",
    "        seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                            (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                            (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                            (seism_map_short['y'] < row['ymean_max'])]\n",
    "        mean = seism_map_zone.phit_pred.mean()\n",
    "        df = pd.DataFrame({ 'well':row['well'], \n",
    "                            'phit_net_mean':row['phit_net_mean'], \n",
    "                            # 'field':row['field'],\n",
    "                            'mean': mean, \n",
    "                            'margin_pred':margin,\n",
    "                            'seism_att':file}, index=[0])\n",
    "        df_lst.append(df)\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    return result\n",
    "val_test1_v2 = val_test1_v2.rename(columns={'phit_val':'phit_net_mean'})\n",
    "test_val = seism_well_correl_test(model_df8, val_test1_v2, 100, 'Bal8_SNA')\n",
    "test_val['diff'] = test_val.phit_net_mean - test_val['mean']\n",
    "test_val['up_1.15pu'] = test_val.phit_net_mean+0.0115\n",
    "test_val['down_1.15pu'] = test_val.phit_net_mean-0.0115\n",
    "test_val['qc'] = np.where((test_val['mean'] >= test_val['down_1.15pu']) & (test_val['mean'] <= test_val['up_1.15pu']), 1, 0)\n",
    "test_val.qc.value_counts(normalize=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val = test_val.rename(columns={'mean':'phit_pred'})\n",
    "test_val = test_val.sort_values('phit_net_mean')\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "sns.lineplot(data=test_val, x='well', y='phit_net_mean', ax=ax, label = 'phit_net_mean')\n",
    "sns.lineplot(data=test_val, x='well', y='phit_pred', ax=ax, label = 'phit_pred')\n",
    "ax.fill_between( test_val['well'], \n",
    "                    test_val['phit_net_mean'] - 0.0115, \n",
    "                    test_val['phit_net_mean'] + 0.0115, \n",
    "                    color='b', alpha=0.2) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=6)\n",
    "plt.title(f\"phit_net_mean vs phit_pred based on {test_val.seism_att.iloc[0]} with 1:{test_val.qc.value_counts(normalize=True)[1]:.3f}\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final script Bal10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_by_mask(directory, mask):\n",
    "    # Construct the full pattern\n",
    "    pattern = os.path.join(directory, mask)\n",
    "    \n",
    "    # Use glob to get the list of files\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    # Extract the relative path of each file\n",
    "    relative_paths = [os.path.relpath(file, directory) for file in files]\n",
    "    \n",
    "    return relative_paths\n",
    "files10 = list_files_by_mask('', 'Bal10*')\n",
    "files10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst10 = []\n",
    "for file in tqdm(files10):\n",
    "    def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "        def seism_upload(file, delimiter):\n",
    "            seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "            seismic = seismic.round({'x':0, 'y':0})\n",
    "            return seismic\n",
    "        seismic_map = seism_upload(file, ' ')\n",
    "        print(f\"seismic map {file} is uploaded\")\n",
    "        \n",
    "        def intersection_maps(map, wells_df, buffer):\n",
    "            geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "            gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "            geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "            gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "            convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "            intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "            return intersection\n",
    "        seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "        print('seismic map is intersected with wells')\n",
    "    \n",
    "        def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "            wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "            wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "            wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "            wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "            seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "            df_lst = []\n",
    "            for idx, row in wells_df.iterrows():\n",
    "                seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                    (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                    (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                    (seism_map_short['y'] < row['ymean_max'])]\n",
    "                mean = seism_map_zone.value.mean()\n",
    "                p50 = seism_map_zone.value.quantile(0.5)\n",
    "                p25 = seism_map_zone.value.quantile(0.25)\n",
    "                p75 = seism_map_zone.value.quantile(0.75)\n",
    "                df = pd.DataFrame({'well':row['well'], \n",
    "                                    'phit_net_mean':row['phit_net_mean'], \n",
    "                                    'field':row['field'],\n",
    "                                    'mean': mean, \n",
    "                                    'p50': p50, \n",
    "                                    'p25': p25, \n",
    "                                    'p75': p75,\n",
    "                                    'x':row['xmean'],\n",
    "                                    'y':row['ymean'],\n",
    "                                    'xmean_min':row['xmean_min'],\n",
    "                                    'xmean_max':row['xmean_max'],\n",
    "                                    'ymean_min':row['ymean_min'],\n",
    "                                    'ymean_max':row['ymean_max'],\n",
    "                                    'margin_init':margin,\n",
    "                                    'seism_att':file}, index=[0])\n",
    "                df_lst.append(df)\n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            return result\n",
    "        well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "        print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "        dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "        \n",
    "        return dict_with_results\n",
    "    print(f'siesmic maps {file} and well data preparation is started')\n",
    "    data_bal10 = seism_well_run_v2(file, xy10_phit, buffer=1500, margin=100)\n",
    "    seismic_map10 = data_bal10['seismic_map_intersect']\n",
    "    well_data10 = data_bal10['well_data_from_seismic_map']\n",
    "\n",
    "    def preprocessing_data(seismic_map, well_data):\n",
    "        well_data_v2 = well_data[~well_data.well.isin(['B39', 'D02Y', 'D34', 'B31', 'B20'])] #outliers\n",
    "        well_data_v3 = well_data_v2[~well_data_v2.well.isin(['B01ST1', 'D01', 'C14', 'C01A', 'B06', 'C13Z', 'C06', 'D01Z','C07'])] #very close to each other wells\n",
    "\n",
    "        X = well_data_v3[['x', 'y', 'mean']].rename(columns={'mean':'value'})\n",
    "        y = well_data_v3['phit_net_mean']\n",
    "        X_train, y_train = X, y\n",
    "        X_test = seismic_map[['x', 'y', 'value']]\n",
    "        return X_train, y_train, X_test, well_data_v3\n",
    "    print('data is preprocessed')\n",
    "    X_train10, y_train10, X_test10, well_data10_v3 = preprocessing_data(seismic_map10, well_data10)\n",
    "\n",
    "    tregr10 = tpot.TPOTRegressor(n_jobs=7, verbosity=1, generations=20, random_state=42, scoring='r2', early_stop=5)\n",
    "    tregr10.fit(X_train10, y_train10)\n",
    "    tregr10.fitted_pipeline_\n",
    "    joblib.dump(tregr10.fitted_pipeline_, f'tregr_{file}.pkl')\n",
    "    print('model is trained')\n",
    "\n",
    "    model10 = joblib.load(f'tregr_{file}.pkl')\n",
    "    y_pred10 = model10.predict(X_test10)\n",
    "    model_df10 = pd.DataFrame({'x': X_test10.iloc[:,0], 'y': X_test10.iloc[:,1],'phit_pred': y_pred10})\n",
    "\n",
    "    def model_postprocessing(model_df, well_data_v3, file, margin):\n",
    "        def seism_well_correl_pred(seism_map, wells_df, margin, file):\n",
    "            wells_df['xmean_min'] = wells_df['x'] - margin\n",
    "            wells_df['xmean_max'] = wells_df['x'] + margin\n",
    "            wells_df['ymean_min'] = wells_df['y'] - margin\n",
    "            wells_df['ymean_max'] = wells_df['y'] + margin\n",
    "            seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "            df_lst = []\n",
    "            for idx, row in wells_df.iterrows():\n",
    "                seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                    (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                    (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                    (seism_map_short['y'] < row['ymean_max'])]\n",
    "                mean = seism_map_zone.value.mean()\n",
    "                df = pd.DataFrame({'well':row['well'], \n",
    "                                    'phit_net_mean':row['phit_net_mean'], \n",
    "                                    'field':row['field'],\n",
    "                                    'mean': mean, \n",
    "                                    'margin_pred':margin,\n",
    "                                    'seism_att':file}, index=[0])\n",
    "                df_lst.append(df)\n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            return result\n",
    "\n",
    "        model_df = model_df.rename(columns={'phit_pred':'value'})\n",
    "        wells_pred = seism_well_correl_pred(model_df, well_data_v3, margin, 'Bal8_AV')\n",
    "        wells_pred = wells_pred[['well', 'mean']].rename(columns={'mean':'phit_pred'})\n",
    "\n",
    "        wells_pred_true = well_data_v3.set_index('well').join(wells_pred.set_index('well'), how='inner').reset_index()\n",
    "\n",
    "        wells_pred_true['algorithm'] = tregr10.fitted_pipeline_\n",
    "        wells_pred_true['up_1.15pu'] = wells_pred_true.phit_net_mean+0.0115\n",
    "        wells_pred_true['down_1.15pu'] = wells_pred_true.phit_net_mean-0.0115\n",
    "\n",
    "        wells_pred_true['qc'] = np.where((wells_pred_true.phit_pred >= wells_pred_true['down_1.15pu']) \n",
    "        & (wells_pred_true.phit_pred <= wells_pred_true['up_1.15pu']), 1, 0)\n",
    "\n",
    "        dict_qc = {'1':wells_pred_true.qc.value_counts(normalize=True)[1], '0':wells_pred_true.qc.value_counts(normalize=True)[0]}\n",
    "\n",
    "        wells_pred_true['qc_result'] = [dict_qc] * len(wells_pred_true)\n",
    "\n",
    "        return wells_pred_true\n",
    "    print('model is postprocessed')\n",
    "    wells_pred_true10 = model_postprocessing(model_df10, well_data10_v3, file, margin=100)\n",
    "    wells_pred_true10['scoring'] = 'r2'\n",
    "    print(f'model based on {file} is ready:', wells_pred_true10.qc_result.iloc[0])\n",
    "    df_lst10.append(wells_pred_true10)\n",
    "\n",
    "final_pred10 = pd.concat(df_lst10).reset_index(drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred10.to_csv('final_pred_bal10_scoring_r2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization result bal10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Bal10_AV'\n",
    "def seism_well_run_v2(file, wells_df, buffer, margin):\n",
    "    def seism_upload(file, delimiter):\n",
    "        seismic = pd.read_csv(file, delimiter=delimiter)\n",
    "        seismic = seismic.round({'x':0, 'y':0})\n",
    "        return seismic\n",
    "    seismic_map = seism_upload(file, ' ')\n",
    "    print(f\"seismic map {file} is uploaded\")\n",
    "    \n",
    "    def intersection_maps(map, wells_df, buffer):\n",
    "        geometry_map = [Point(xy) for xy in zip(map['x'], map['y'])]\n",
    "        gdf_map = gpd.GeoDataFrame(map, geometry=geometry_map)\n",
    "\n",
    "        geometry_points = [Point(xy) for xy in zip(wells_df['xmean'], wells_df['ymean'])]\n",
    "        gdf_points = gpd.GeoDataFrame(wells_df, geometry=geometry_points)\n",
    "        convex_hull = gdf_points.unary_union.convex_hull.buffer(buffer)\n",
    "        intersection = gdf_map[gdf_map.intersects(convex_hull)]\n",
    "        return intersection\n",
    "    seismic_map_intersect = intersection_maps(seismic_map, wells_df, buffer)\n",
    "    print('seismic map is intersected with wells')\n",
    "\n",
    "    def seism_well_correl_init(seism_map, wells_df, margin, file):\n",
    "        wells_df['xmean_min'] = wells_df['xmean'] - margin\n",
    "        wells_df['xmean_max'] = wells_df['xmean'] + margin\n",
    "        wells_df['ymean_min'] = wells_df['ymean'] - margin\n",
    "        wells_df['ymean_max'] = wells_df['ymean'] + margin\n",
    "        seism_map_short = seism_map[['x', 'y', 'value']]\n",
    "\n",
    "        df_lst = []\n",
    "        for idx, row in wells_df.iterrows():\n",
    "            seism_map_zone = seism_map_short[   (seism_map_short['x'] > row['xmean_min']) &\n",
    "                                                (seism_map_short['x'] < row['xmean_max']) & \n",
    "                                                (seism_map_short['y'] > row['ymean_min']) &\n",
    "                                                (seism_map_short['y'] < row['ymean_max'])]\n",
    "            mean = seism_map_zone.value.mean()\n",
    "            p50 = seism_map_zone.value.quantile(0.5)\n",
    "            p25 = seism_map_zone.value.quantile(0.25)\n",
    "            p75 = seism_map_zone.value.quantile(0.75)\n",
    "            df = pd.DataFrame({'well':row['well'], \n",
    "                                'phit_net_mean':row['phit_net_mean'], \n",
    "                                'field':row['field'],\n",
    "                                'mean': mean, \n",
    "                                'p50': p50, \n",
    "                                'p25': p25, \n",
    "                                'p75': p75,\n",
    "                                'x':row['xmean'],\n",
    "                                'y':row['ymean'],\n",
    "                                'xmean_min':row['xmean_min'],\n",
    "                                'xmean_max':row['xmean_max'],\n",
    "                                'ymean_min':row['ymean_min'],\n",
    "                                'ymean_max':row['ymean_max'],\n",
    "                                'margin_init':margin,\n",
    "                                'seism_att':file}, index=[0])\n",
    "            df_lst.append(df)\n",
    "        result = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return result\n",
    "    well_data_from_seismic_map = seism_well_correl_init(seismic_map_intersect, wells_df, margin, file)\n",
    "    print(f\"map {file} to wells dataset is recalculated\")\n",
    "\n",
    "    dict_with_results = {'seismic_map_intersect':seismic_map_intersect, 'well_data_from_seismic_map':well_data_from_seismic_map}\n",
    "    \n",
    "    return dict_with_results\n",
    "print(f'siesmic maps {file} and well data preparation is started')\n",
    "data_bal10 = seism_well_run_v2(file, xy10_phit, buffer=1500, margin=100)\n",
    "seismic_map10 = data_bal10['seismic_map_intersect']\n",
    "well_data10 = data_bal10['well_data_from_seismic_map']\n",
    "X_test10 = seismic_map10[['x', 'y', 'value']]\n",
    "\n",
    "final_pred10 = pd.read_csv('final_pred_bal10_scoring_r2.csv')\n",
    "model10 = joblib.load(f'tregr_{file}.pkl')\n",
    "X_test10 = X_test10.rename(columns={'mean':'value'})\n",
    "y_pred10 = model10.predict(X_test10)\n",
    "model_df10 = pd.DataFrame({'x': X_test10.iloc[:,0], 'y': X_test10.iloc[:,1], 'phit_pred': y_pred10})\n",
    "display(final_pred10[final_pred10.seism_att == file].qc_result.iloc[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "xy10_phit_preproc = xy10_phit[~xy10_phit.well.isin(['A13Z', 'H01Y', 'A01X', 'A12X', 'D01', 'E31', 'G01Y', 'A09Y', \n",
    "                                                                 'E01X', 'A07Y', 'A01W', 'C27Y', 'C03ST1', 'H01', 'D07'])]\n",
    "all_values10 = pd.concat([xy10_phit_preproc.phit_net_mean, model_df10.phit_pred]).reset_index(drop=True)\n",
    "norm10 = plt.Normalize(all_values10.min(), all_values10.max())\n",
    "cb1 = plt.scatter(model_df10['x'], model_df10['y'], c=model_df10['phit_pred'], cmap='coolwarm', norm=norm10, s=1)\n",
    "# colorbar1 = plt.colorbar(cb1)\n",
    "# colorbar1.set_label('phit_model')\n",
    "cb2 = plt.scatter(  xy10_phit_preproc['xmean'], \n",
    "                    xy10_phit_preproc['ymean'], \n",
    "                    c=xy10_phit_preproc['phit_net_mean'], \n",
    "                    s=50, ec='black', lw=0.5, alpha=1, norm=norm10, cmap='coolwarm')\n",
    "# colorbar2 = plt.colorbar(cb2)\n",
    "# colorbar2.set_label('phit_wells')\n",
    "# plt.scatter(k01_gb['xmean'], k01_gb['ymean'], c=k01_gb['phit_w_avg'], norm=norm, \n",
    "#             s=50, ec='black', lw=0.5, alpha=0.75, cmap='coolwarm')\n",
    "plt.title(f'phit prediction based on {file}');\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phit_pred10 = final_pred10[final_pred10.seism_att == file].sort_values('phit_net_mean')\n",
    "dict_obj = ast.literal_eval(phit_pred10.qc_result.iloc[0])\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "sns.lineplot(data=phit_pred10, x='well', y='phit_net_mean', ax=ax, label = 'phit_net_mean')\n",
    "sns.lineplot(data=phit_pred10, x='well', y='phit_pred', ax=ax, label = 'phit_pred')\n",
    "ax.fill_between(    phit_pred10['well'], \n",
    "                    phit_pred10['phit_net_mean'] - 0.0115, \n",
    "                    phit_pred10['phit_net_mean'] + 0.0115, \n",
    "                    color='b', alpha=0.2) \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=6)\n",
    "plt.title(f\"phit_net_mean vs phit_pred based on {phit_pred10.seism_att.iloc[0]} with 1:{dict_obj['1']:.3f}\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

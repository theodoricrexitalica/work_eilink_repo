{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statistics as st\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import geopandas as gpd\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\jupyter\\SPP\\input\\sensitivity_MC_TL_bal8sand.xlsx\", sheet_name='Sheet1')\n",
    "unique_column_values_raw = df['well_name'].unique()\n",
    "unique_column_values = [x for x in unique_column_values_raw[~pd.isnull(unique_column_values_raw)] if x!= 'well_name']\n",
    "tables = {}\n",
    "for value in unique_column_values:\n",
    "    table_name = value\n",
    "    table_df = df[df['well_name'] == value].reset_index(drop=True)\n",
    "    tables[table_name] = table_df\n",
    "\n",
    "p10 = pd.DataFrame()\n",
    "p50 = pd.DataFrame()\n",
    "p90 = pd.DataFrame()\n",
    "for table in tables.values():\n",
    "    if len(table):\n",
    "        p10 = pd.concat([p10, table[table['Flag Name']=='RES'][table['Stat Name']=='P 10']])\n",
    "        p50 = pd.concat([p50, table[table['Flag Name']=='RES'][table['Stat Name']=='P 50']])\n",
    "        p90 = pd.concat([p90, table[table['Flag Name']=='RES'][table['Stat Name']=='P 90']])\n",
    "p10.reset_index(drop=True, inplace=True)\n",
    "p50.reset_index(drop=True, inplace=True)\n",
    "p90.reset_index(drop=True, inplace=True)\n",
    "p10.iloc[:,3:-1] = p10.iloc[:,3:-1].astype('float')\n",
    "p50.iloc[:,3:-1] = p50.iloc[:,3:-1].astype('float')\n",
    "p90.iloc[:,3:-1] = p90.iloc[:,3:-1].astype('float')\n",
    "p10.replace(-9999, np.nan, inplace=True)\n",
    "p50.replace(-9999, np.nan, inplace=True)\n",
    "p90.replace(-9999, np.nan, inplace=True)\n",
    "df_uncert = pd.concat([p10,p50,p90], ignore_index=True)\n",
    "df_uncert = df_uncert[[ 'well_name', 'Zone Name', 'Flag Name', 'Stat Name', 'Top (M)', 'Bottom (M)',\n",
    "                        'Gross (M)', 'Net(M)', 'Net to gross', 'POR avg', 'VSH avg',\n",
    "                        'SW avg', 'PORV(M)', 'HCPV(M)', 'LPERM arithmetic avg',\n",
    "                        'LPERM geometric avg', 'LPERM Hamonic avg']]\n",
    "df_uncert.sort_values(by='well_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading metadata, distribution wells per Platforms and all the that.\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "metadata = metadata_init.copy()\n",
    "metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "metadata.Status = metadata.Status.str.strip()\n",
    "metadata.Status = metadata.Status.str.lower()\n",
    "metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "#Read data from parquet\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v6.parquet.gzip')\n",
    "df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "# print('wells in df totally:', len(df_prq.well.unique()))\n",
    "# Filter data with bad_well_list \n",
    "bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP']\n",
    "df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "#Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "df_prq.loc[df_prq.Fluidcode_mod>0, 'gross_pay'] = 1\n",
    "df_prq.loc[df_prq.Fluidcode_mod<=0, 'gross_pay'] = 0\n",
    "df_prq.gross_pay = df_prq.gross_pay.astype('int')\n",
    "#Getting XY coords of Balakhany formation tops\n",
    "xy_coord = df_prq[['well', 'FORMATION', 'X', 'Y']]\n",
    "xy_coord = xy_coord.groupby(['well', 'FORMATION']).apply(lambda x: x.iloc[0]).drop(columns=['well', 'FORMATION']).reset_index()\n",
    "xy_coord = xy_coord[xy_coord.FORMATION.str.contains('Balakhany') & (xy_coord.X>0) & (xy_coord.Y>0)]\n",
    "#Find top TVD_SCS for each formation\n",
    "df_prq_tvdss = df_prq[['well','DEPTH','FORMATION','TVD_SCS']].groupby(['well','FORMATION']).apply(lambda x: x.iloc[0])\n",
    "df_prq_tvdss = df_prq_tvdss.drop(['well','FORMATION'], axis=1).reset_index()\n",
    "df_prq_tvdss = df_prq_tvdss[df_prq_tvdss.TVD_SCS>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of TST-thickness for ALL Balakhany FU\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fu_tst_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms tst_interv and md_gross_uncert\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "              x=df_fu_tst_final.TST_interv, \n",
    "              xbins=dict(start=0, end=150, size=3), marker_color='blue', name='tst_interv'))\n",
    "fig.add_trace(go.Histogram(\n",
    "              x=df_uncert['Gross (M)'], \n",
    "              xbins=dict(start=0, end=150, size=3), marker_color='yellow', name='md_uncert'))\n",
    "fig.update_traces(opacity=0.66)\n",
    "fig.update_layout(title_text='Histograms tst_interv and md_gross_uncert',\n",
    "                  xaxis_title_text='tst_thickness', yaxis_title_text='Count',\n",
    "                  autosize=True, width=1000, height=300, margin=dict(l=10,r=10,b=10,t=40))\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_xaxes(nticks=40, showgrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel = df_uncert[(df_uncert['Gross (M)'] < 45) & (df_uncert['Net(M)'] > 0)]\n",
    "df_fu_tst_final_sel = df_fu_tst_final[df_fu_tst_final.TST_interv < 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms tst_interv and md_gross_uncert\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "              x=df_fu_tst_final_sel.TST_interv, \n",
    "              xbins=dict(start=0, end=100, size=1), marker_color='blue', name='tst_interv'))\n",
    "fig.add_trace(go.Histogram(\n",
    "              x=df_uncert_sel['Gross (M)'], \n",
    "              xbins=dict(start=0, end=100, size=1), marker_color='yellow', name='md_uncert'))\n",
    "fig.update_traces(opacity=0.66)\n",
    "fig.update_layout(title_text='Histograms tst_interv and md_gross_uncert',\n",
    "                  xaxis_title_text='tst_thickness', yaxis_title_text='Count',\n",
    "                  autosize=True, width=700, height=400, margin=dict(l=10,r=10,b=10,t=40))\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_xaxes(nticks=40, showgrid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel['Kavg_ar_Net'] = (df_uncert_sel['Net(M)'] * df_uncert_sel['LPERM arithmetic avg']).round(0)\n",
    "df_uncert_sel.loc[df_uncert_sel['Stat Name'] == 'P 10', 'NewProb'] = 'P90'\n",
    "df_uncert_sel.loc[df_uncert_sel['Stat Name'] == 'P 50', 'NewProb'] = 'P50'\n",
    "df_uncert_sel.loc[df_uncert_sel['Stat Name'] == 'P 90', 'NewProb'] = 'P10'\n",
    "df_uncert_sel.sort_values(by=['well_name', 'NewProb'], inplace=True)\n",
    "df_uncert_sel.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel_p10 = df_uncert_sel[(df_uncert_sel.NewProb=='P10') & (df_uncert_sel.Kavg_ar_Net>100)]\n",
    "df_uncert_sel_p10.Kavg_ar_Net.quantile(0.5, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel_p10.sort_values(by=['Kavg_ar_Net'], inplace=True, ascending=False)\n",
    "fig = px.bar(df_uncert_sel_p10, x=\"well_name\", y=\"Kavg_ar_Net\")\n",
    "fig.update_layout(title_text='Distribution P10 Kavg_ar_Net based on uncertainty analize with tolerance 10% for Phit, Vsh and cut-offs',\n",
    "                  xaxis_title_text='wells', yaxis_title_text='Kavg_ar_Net',\n",
    "                  autosize=True, width=1200, height=400, margin=dict(l=10,r=10,b=10,t=40))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel[[ 'well_name', 'Zone Name', 'Flag Name','NewProb', 'Gross (M)', 'Net(M)', 'POR avg',\n",
    "                'VSH avg', 'LPERM arithmetic avg','LPERM geometric avg', 'LPERM Hamonic avg', 'Kavg_ar_Net']].sort_values(by=['well_name', 'NewProb']).head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncert_sel.sort_values(by=['Kavg_ar_Net'], inplace=True, ascending=False)\n",
    "fig = px.bar(df_uncert_sel[df_uncert_sel.Kavg_ar_Net>100], x=\"well_name\", y=\"Kavg_ar_Net\", color=\"NewProb\")\n",
    "fig.update_layout(title_text='Distribution P10-50-90 Kavg_ar_Net based on uncertainty analize with tolerance 10% for Phit, Vsh and cut-offs',\n",
    "                  xaxis_title_text='wells', yaxis_title_text='Kavg_ar_Net',\n",
    "                  autosize=True, width=1200, height=400, margin=dict(l=10,r=10,b=10,t=40))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

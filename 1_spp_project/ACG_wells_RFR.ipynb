{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statistics as st\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Link to my OneDrive where the actual version of TL-dataset is stored\n",
    "# https://eigcom-my.sharepoint.com/:x:/g/personal/taras_dolgushin_eilink_az/ET4iIiIeUUNCvtixzYiBLFkBc6qYHetw0H0WIqJrR1B6Uw?e=ZUJEIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ACG_wells_JOINT_BEST_v6.csv file\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "data_init = pd.read_csv(path + 'ACG_wells_JOINT_BEST_v6.csv', sep=',')\n",
    "# Data cleaning of TL-dataset\n",
    "df = data_init.copy()\n",
    "df = df[1:]\n",
    "#Select only neccessary data\n",
    "df_cln = df[['wellName', 'DEPTH', 'AREA', 'BADPORLOG', 'Casings', 'FORMATION',\n",
    "            'FLANK1', 'FLANK2', 'Fluidcode', 'Fluidcode_mod', 'FLUIDCODE_PP',\n",
    "            'LPERM', 'PHIT', 'NET', \n",
    "            'GR_N', 'GRMATRIX', 'GRSHALE','VSH', 'NPSS', 'RHOB', 'RHOF', 'RHOMA', \n",
    "            'RDEEP',  'SON', 'SONSH', \n",
    "            'TVD_SCS','TST', 'DEVI','HAZI','X', 'Y', 'Dip_Azimuth', 'Dip_TRU']]\n",
    "#Fill up nan and -9999 values with 0\n",
    "df_cln = df_cln.fillna(0)\n",
    "df_cln = df_cln.replace(-9999, 0)\n",
    "df_cln = df_cln.replace('-9999', '0')\n",
    "#Assing proper datatypes for df\n",
    "dicttypes = {'wellName':'string', 'DEPTH':'float', 'AREA':'int', 'BADPORLOG':'int', 'Casings':'float', 'FLANK1':'int', 'FLANK2':'int',\n",
    "             'Fluidcode':'int', 'Fluidcode_mod':'int','FLUIDCODE_PP':'int','FORMATION':'string', 'GR_N':'float', 'GRMATRIX':'float', \n",
    "             'GRSHALE':'float', 'LPERM':'float', 'NPSS':'float',\n",
    "             'PHIT':'float', 'NET':'float', 'RDEEP':'float', 'RHOB':'float', 'RHOF':'float', 'RHOMA':'float', 'TVD_SCS':'float', 'TST':'float',\n",
    "             'VSH':'float', 'X':'float', 'Y':'float', 'Dip_Azimuth':'float', 'Dip_TRU':'float'}\n",
    "df_cln = df_cln.astype(dicttypes, errors='ignore')\n",
    "df_cln.loc[df_cln.FORMATION=='0', 'FORMATION']='None'\n",
    "#Save data to parquet\n",
    "df_cln.to_parquet('ACG_wells_JOINT_BEST_v6.parquet.gzip', compression='gzip')\n",
    "\n",
    "#Loading metadata, distribution wells per Platforms and all the that.\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "metadata = metadata_init.copy()\n",
    "metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "metadata.Status = metadata.Status.str.strip()\n",
    "metadata.Status = metadata.Status.str.lower()\n",
    "metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "\n",
    "#Read data from parquet\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v6.parquet.gzip')\n",
    "df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "# print('wells in df totally:', len(df_prq.well.unique()))\n",
    "# Filter data with bad_well_list \n",
    "bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP']\n",
    "df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "#Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "df_prq.loc[df_prq.Fluidcode_mod>0, 'gross_pay'] = 1\n",
    "df_prq.loc[df_prq.Fluidcode_mod<=0, 'gross_pay'] = 0\n",
    "df_prq.gross_pay = df_prq.gross_pay.astype('int')\n",
    "#Getting XY coords of Balakhany formation tops\n",
    "xy_coord = df_prq[['well', 'FORMATION', 'X', 'Y']]\n",
    "xy_coord = xy_coord.groupby(['well', 'FORMATION']).apply(lambda x: x.iloc[0]).drop(columns=['well', 'FORMATION']).reset_index()\n",
    "xy_coord = xy_coord[xy_coord.FORMATION.str.contains('Balakhany') & (xy_coord.X>0) & (xy_coord.Y>0)]\n",
    "#Find top TVD_SCS for each formation\n",
    "df_prq_tvdss = df_prq[['well','DEPTH','FORMATION','TVD_SCS']].groupby(['well','FORMATION']).apply(lambda x: x.iloc[0])\n",
    "df_prq_tvdss = df_prq_tvdss.drop(['well','FORMATION'], axis=1).reset_index()\n",
    "df_prq_tvdss = df_prq_tvdss[df_prq_tvdss.TVD_SCS>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataset for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "#Clean dataset for outliers for Balakhany VIII & X  for AZR and CHG fields by rule 1.5 * IQR\n",
    "fm_list_8_10 = ['Balakhany VIII', 'Balakhany VIII sand', 'Balakhany VIII 25','Balakhany VIII 20', \n",
    "                'Balakhany VIII 15', 'Balakhany VIII 10', 'Balakhany VIII 5',\n",
    "                'Balakhany X', 'Balakhany X sand', 'Balakhany X 40', 'Balakhany X 20'] \n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_lst = []\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(azr_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} azr IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(chg_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} chg IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "df_khtst_bal_qcl = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting TST-thick Bal VIII & X + uploading df_prq_htst_avgprop_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution tst-thickness Balaknany VIII / X over Chirag and Azeri zones\n",
    "#Calculation of TST-thickness Balakhany VIII & X\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_8bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_8bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany VIII sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_8bal_phhpv = df_8bal_hpv.set_index(['well','FORMATION']).join(df_8bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany X sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_10bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany X sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_10bal_phhpv = df_10bal_hpv.set_index(['well','FORMATION']).join(df_10bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# #Preparing x,y matrices for ML\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_8bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop8_final_wa = df_8bal_phhpv_tstint.copy()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_10bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop10_final_wa = df_10bal_phhpv_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 \n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)]\n",
    "df_avgprop_bal8_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                          df_avgprop8_final_wa.well.isin(well_no_outliers8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation dataset for X_train/x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation dataset for X_train/x_test data splitting based on outliers cleaned data\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "well_clean_azr = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand') & \n",
    "                                  (df_khtst_bal_qcl.field.isin(azr_lst))].well\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand.\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy_tvd[(df_khtst_xy_tvd.FORMATION == formation) & \n",
    "                            (df_khtst_xy_tvd.X > 0) & (df_khtst_xy_tvd.Y > 0) &\n",
    "                            (~df_khtst_xy_tvd.TVD_SCS.isna())]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuclDist Dist based dataset Balakhany VIII sand + X sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                 df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                 ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                 ['well','FORMATION'], axis=1)).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')    \n",
    "# Preparation dataset for X_train/x_test data splitting\n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "\n",
    "df_collect8 = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect8.append(result)\n",
    "df_well_kh_dist8 = pd.concat(df_collect8).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist8.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_8)) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_collect10 = []\n",
    "for num, well_name in enumerate(dist_bal10.well):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect10.append(result)\n",
    "df_well_kh_dist10 = pd.concat(df_collect10).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal10 = df_well_kh_dist10.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10_fld[(df_well_kh_dist_bal10_fld.well.isin(well_clean_10)) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_all = pd.concat([df_well_kh_dist_bal8_fld, df_well_kh_dist_bal10_fld])\n",
    "# df_well_kh_dist_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XY based on EuclDist Balakhany VIII sand & X sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting XY based on Euclidean Distances for the top of Balakhany VIII sand.\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()['index']\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == 'Balakhany VIII sand') & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    data[data.well.isin(well_dist3)][['well','X','Y']].T[1:]\n",
    "    well_dist3_x = data[data.well.isin(well_dist3)][['well','X','Y']].T[1:2].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y = data[data.well.isin(well_dist3)][['well','X','Y']].T[2:3].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y.columns =['y1', 'y2', 'y3']\n",
    "    well_dist3_x.columns =['x1', 'x2', 'x3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_x, well_dist3_y, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_xy = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_xy_bal8 = df_well_kh_xy.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal8_fld = df_well_kh_xy_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "# Making up dataset with xy for azeri field\n",
    "df_well_kh_xy_bal8_fld_azr = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.field.isin(azr_lst)) & \n",
    "                                                    (df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# Making up dataset with xy for chirag & azeri fields\n",
    "df_well_kh_xy_bal8_fld_all = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_xy_bal8_fld_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting XY based on Euclidean Distances for the top of Balakhany X sand.\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal10.well[:]):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()['index']\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == 'Balakhany X sand') & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    data[data.well.isin(well_dist3)][['well','X','Y']].T[1:]\n",
    "    well_dist3_x = data[data.well.isin(well_dist3)][['well','X','Y']].T[1:2].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y = data[data.well.isin(well_dist3)][['well','X','Y']].T[2:3].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y.columns =['y1', 'y2', 'y3']\n",
    "    well_dist3_x.columns =['x1', 'x2', 'x3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_x, well_dist3_y, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_xy = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_xy_bal10 = df_well_kh_xy.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal10_fld = df_well_kh_xy_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "# Making up dataset with xy for azeri field\n",
    "df_well_kh_xy_bal10_fld_azr = df_well_kh_xy_bal10_fld[(df_well_kh_xy_bal10_fld.field.isin(azr_lst)) & \n",
    "                                                    (df_well_kh_xy_bal10_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# Making up dataset with xy for chirag & azeri fields\n",
    "df_well_kh_xy_bal10_fld_all = df_well_kh_xy_bal10_fld[(df_well_kh_xy_bal10_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_xy_bal10_fld_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe of wells with casing shoe inside Bal VIII or X intervals\n",
    "df_prq_csg = df_prq[df_prq.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','Casings']]\n",
    "df_prq_csg_name = df_prq.groupby(['well','FORMATION'])['Casings'].apply(lambda x: (x.iloc[:].unique())).reset_index()\n",
    "df_prq_csg_8 = df_prq_csg.groupby(['well','FORMATION'])['Casings'].apply(lambda x: len(x.iloc[:].unique())).reset_index()\n",
    "df_prq_csg_8.rename(columns={'Casings':'csg_qty_bal8'}, inplace=True)\n",
    "df_prq_csg = df_prq[df_prq.FORMATION == 'Balakhany X sand'][['well','FORMATION','Casings']]\n",
    "df_prq_csg_10 = df_prq_csg.groupby(['well','FORMATION'])['Casings'].apply(lambda x: len(x.iloc[:].unique())).reset_index()\n",
    "df_prq_csg_10.rename(columns={'Casings':'csg_qty_bal10'}, inplace=True)\n",
    "df_khtst_bal_qcl_nm = df_khtst_bal_qcl.set_index(['well','FORMATION']).join(df_prq_csg_name.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_bal_qcl10 = df_khtst_bal_qcl_nm.set_index(['well','FORMATION']).join(df_prq_csg_10.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_bal_qcl_csg = df_khtst_bal_qcl10.set_index(['well','FORMATION']).join(df_prq_csg_8.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_bal_qcl_csg_sel = df_khtst_bal_qcl_csg[(df_khtst_bal_qcl_csg.csg_qty_bal10 ==2) | (df_khtst_bal_qcl_csg.csg_qty_bal8 ==2)].sort_values(by='FORMATION')\n",
    "df_khtst_bal_qcl_csg_sel[['well','FORMATION','KHtst','field','Casings']].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy RFR for Bal8_sand & Bal10_sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base settings for MLFlow tracking\n",
    "mlflow.set_tracking_uri(\"http://16.171.23.137:5000\")\n",
    "mlflow.set_experiment('SPP_RandForReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_ml_plot(res, dataset, kh, max_val):\n",
    "    \"\"\"\n",
    "    res = dataset with results of ML prediction\n",
    "    dataset = dataframe with wellnames to join it with res based on actual KHtst values\n",
    "    kh = title of variable with KH values\n",
    "    max_val = max value for scatter plot\n",
    "    \"\"\"\n",
    "    final = res.set_index('Actual').join(dataset[['well', kh]].set_index(kh)).reset_index()\n",
    "    fig1_ml = px.scatter(final, x='Actual', y='Predicted', hover_data=['well'], width=400, height=400)\n",
    "    fig1_ml.update_traces(marker=dict(size=10))\n",
    "    fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "    fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "    fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "    fig2_ml.update_traces(line=dict(color = 'red'))\n",
    "    fig2_1_ml.update_traces(line=dict(color = 'red', dash='dash'))\n",
    "    fig2_2_ml.update_traces(line=dict(color = 'red', dash='dash'))\n",
    "    fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "    fig3_ml.update_layout(title = 'Comparison Actual vs Pred',width=600,height=400, xaxis_title=kh + '_test', yaxis_title=kh + '_pred',\n",
    "                    margin=dict(l=10,r=10,b=10,t=40))\n",
    "    return fig3_ml.show()\n",
    "def metric_result_print(y_train,y_pred_train,y_test, y_pred):\n",
    "    r2_test = r2(y_test, y_pred)\n",
    "    mae_test = mae(y_test, y_pred)\n",
    "    mse_test = mse(y_test, y_pred)\n",
    "    print(f'R2 test: {r2_test.round(2)}', \n",
    "        f'MAE test: {mae_test.round(3)}',\n",
    "        f'sqrt MSE test: {np.sqrt(mse_test.round(3)):.3f}')\n",
    "    r2_train = r2(y_train, y_pred_train)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    mse_train = mse(y_train, y_pred_train)\n",
    "    print(f'R2 train: {r2_train.round(2)}', \n",
    "        f'MAE train: {mae_train.round(3)}', \n",
    "        f'sqrt MSE train: {np.sqrt(mse_train.round(3)):.3f}')\n",
    "def conv_log10_nat(y_log10):\n",
    "    result = []\n",
    "    for i in y_log10:\n",
    "        result.append(10**i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading df_prq_htst_avgprop_v1 and getting outliers, create kavg_htst\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "df_htst_avgprop['kavg_htst'] = df_htst_avgprop.h_tst * df_htst_avgprop.md_perm_avg\n",
    "#Preparation simple dataframe with df_htst_avgprop-data without distances\n",
    "df_avgprop_gb = df_htst_avgprop.groupby(['well','FORMATION'])[['h_tst','kavg_htst', 'md_phit_avg','md_vsh_avg']].agg(\n",
    "                                        {'h_tst':'sum','kavg_htst':'sum', 'md_phit_avg':'mean', 'md_vsh_avg':'mean' }).reset_index()\n",
    "df_avgprop_gb_tstint = df_avgprop_gb.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_avgprop_gb_tstint = df_avgprop_gb_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'h_tst', 'TST_interv',\n",
    "                                             'kavg_htst', 'md_phit_avg', 'md_vsh_avg']]\n",
    "df_avgprop_gb_tstint.rename(columns={'TST_interv':'interv_tst', 'h_tst':'gross_tst'}, inplace=True)\n",
    "df_avgprop_final = df_avgprop_gb_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 for Chi / Azr\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_avgprop_bal8chi = df_avgprop_final[df_avgprop_final.FORMATION.str.contains('Balakhany VIII sand') & df_avgprop_final.field.isin(chg_lst) & \n",
    "                                      df_avgprop_final.well.isin(well_no_outliers8)].dropna()\n",
    "df_avgprop_bal8azr = df_avgprop_final[df_avgprop_final.FORMATION.str.contains('Balakhany VIII sand') & df_avgprop_final.field.isin(azr_lst) & \n",
    "                                      df_avgprop_final.well.isin(well_no_outliers8)].dropna()\n",
    "df_avgprop_bal10 = df_avgprop_final[df_avgprop_final.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                    df_avgprop_final.well.isin(well_no_outliers10)].dropna()\n",
    "# X_train/x_test data splitting\n",
    "y1 = np.array(df_avgprop_bal8chi['kavg_htst'].values)\n",
    "x1 = np.array(df_avgprop_bal8chi.drop(['well','FORMATION','field','kavg_htst'], axis=1))\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run RFR Bal8_sand smpl Chirag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal VIII sand\n",
    "RF1 = RandomForestRegressor()\n",
    "grid_param_RF1 = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "    'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF1 = GridSearchCV(estimator = RF1, param_grid = grid_param_RF1, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF1.fit(x1_train, y1_train)\n",
    "print(gd_sr_RF1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor for Bal VIII sand\n",
    "# with mlflow.start_run(run_name='rfm_gs_r2'):\n",
    "      # mlflow.set_tag(\"model_name\", \"RandForReg\")\n",
    "RF_setting = {'bootstrap':True, \n",
    "                  'max_depth':150, \n",
    "                  'min_samples_leaf':1, \n",
    "                  'min_samples_split':5,\n",
    "                  'n_estimators':10} \n",
    "RF1 = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                              max_depth=RF_setting['max_depth'], \n",
    "                              min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                              min_samples_split=RF_setting['min_samples_split'], \n",
    "                              n_estimators=RF_setting['n_estimators'])\n",
    "RF1.fit(x1_train, y1_train)\n",
    "#Returning our prediction values for the test data\n",
    "y1_pred_train = RF1.predict(x1_train)\n",
    "y1_pred = RF1.predict(x1_test)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results_v1 = pd.DataFrame({'Actual': y1_test, 'Predicted': y1_pred})\n",
    "result_ml_plot(res = df_results_v1, dataset = df_avgprop_bal8chi, kh='kavg_htst', max_val=14000)\n",
    "metric_result_print(y1_train, y1_pred_train, y1_test, y1_pred)\n",
    "\n",
    "      # mlflow.log_param(\"bootstrap\", RF_setting['bootstrap'])\n",
    "      # mlflow.log_param(\"max_depth\", RF_setting['max_depth'])\n",
    "      # mlflow.log_param(\"min_samples_leaf\", RF_setting['min_samples_leaf'])\n",
    "      # mlflow.log_param(\"min_samples_split\", RF_setting['min_samples_split'])\n",
    "      # mlflow.log_param(\"n_estimators\", RF_setting['n_estimators'])\n",
    "\n",
    "      # mlflow.log_metric(\"r2_test\", r2_test)\n",
    "      # mlflow.log_metric(\"mae_test\", mae_test)\n",
    "      # mlflow.log_metric(\"mse_test\", mse_test)\n",
    "\n",
    "      # mlflow.sklearn.log_model(RF, \"RFR_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run RFR Bal8_sand wa Chirag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_8bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_8bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany VIII sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_8bal_phhpv = df_8bal_hpv.set_index(['well','FORMATION']).join(df_8bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany X sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_10bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany X sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_10bal_phhpv = df_10bal_hpv.set_index(['well','FORMATION']).join(df_10bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# #Preparing x,y matrices for ML\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_8bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop8_final_wa = df_8bal_phhpv_tstint.copy()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_10bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop10_final_wa = df_10bal_phhpv_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 for Chi / Azr\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_avgprop_bal8chi_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                            df_avgprop8_final_wa.field.isin(chg_lst) & df_avgprop8_final_wa.well.isin(well_no_outliers8)].dropna()\n",
    "df_avgprop_bal8azr_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                            df_avgprop8_final_wa.field.isin(azr_lst) & df_avgprop8_final_wa.well.isin(well_no_outliers8)].dropna()\n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)]\n",
    "#X_train/x_test data splitting\n",
    "y2 = np.array(df_avgprop_bal8chi_wa['kavg_htst'].values)\n",
    "x2 = np.array(df_avgprop_bal8chi_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1))\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.33, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal VIII sand Chirag\n",
    "RF2 = RandomForestRegressor()\n",
    "grid_param_RF2 = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "    'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF2 = GridSearchCV(estimator = RF2, param_grid = grid_param_RF2, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF2.fit(x2_train, y2_train)\n",
    "print(gd_sr_RF2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor for Bal VIII sand Chirag weighted avg df_htst_avgprop-dataset \n",
    "# with mlflow.start_run(run_name='rfm_weighted_avg_gs_r2'):\n",
    "# mlflow.set_tag(\"model_name\", \"RandForReg\")\n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':None, \n",
    "              'min_samples_leaf':2, \n",
    "              'min_samples_split':5,\n",
    "              'n_estimators':10} \n",
    "RF2 = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                           max_depth=RF_setting['max_depth'], \n",
    "                           min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                           min_samples_split=RF_setting['min_samples_split'], \n",
    "                           n_estimators=RF_setting['n_estimators'])\n",
    "RF2.fit(x2_train, y2_train)\n",
    "#Returning our prediction values for the test data\n",
    "y2_pred_train = RF2.predict(x2_train)\n",
    "y2_pred = RF2.predict(x2_test)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results_v2 = pd.DataFrame({'Actual': y2_test, 'Predicted': y2_pred})\n",
    "result_ml_plot(res = df_results_v2, dataset = df_avgprop_bal8chi_wa, kh='kavg_htst', max_val=14000)\n",
    "metric_result_print(y2_train, y2_pred_train, y2_test, y2_pred)\n",
    "      # mlflow.log_param(\"bootstrap\", RF_setting['bootstrap'])\n",
    "      # mlflow.log_param(\"max_depth\", RF_setting['max_depth'])\n",
    "      # mlflow.log_param(\"min_samples_leaf\", RF_setting['min_samples_leaf'])\n",
    "      # mlflow.log_param(\"min_samples_split\", RF_setting['min_samples_split'])\n",
    "      # mlflow.log_param(\"n_estimators\", RF_setting['n_estimators'])\n",
    "\n",
    "      # mlflow.log_metric(\"r2_test\", r2_test)\n",
    "      # mlflow.log_metric(\"mae_test\", mae_test)\n",
    "      # mlflow.log_metric(\"mse_test\", mse_test)\n",
    "\n",
    "      # mlflow.sklearn.log_model(RF, \"RFR_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal VIII sand wa Azeri test set\n",
    "result_pi_test = permutation_importance(RF2, x2_test, y2_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx = result_pi_test.importances_mean.argsort()\n",
    "importances = pd.DataFrame(result_pi_test.importances[sorted_importances_idx].T,\n",
    "                           columns=df_avgprop_bal8chi_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx])\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal VIII sand wa Chirag (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal VIII sand wa Azeri train set\n",
    "result_pi_train = permutation_importance(RF2, x2_train, y2_train, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx_train = result_pi_train.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(result_pi_train.importances[sorted_importances_idx_train].T,\n",
    "                                 columns=df_avgprop_bal8chi_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx_train])\n",
    "ax = importances_train.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal VIII sand wa Chirag (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run RFR Bal8_sand wa Azeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balakhany VIII Azeri weighted averaging\n",
    "df_avgprop_bal8azr_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                            df_avgprop8_final_wa.field.isin(azr_lst) & df_avgprop8_final_wa.well.isin(well_no_outliers8)].dropna()\n",
    "#X_train/x_test data splitting\n",
    "y2_1 = np.array(df_avgprop_bal8azr_wa['kavg_htst'].values)\n",
    "x2_1 = np.array(df_avgprop_bal8azr_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1))\n",
    "x2_1_train, x2_1_test, y2_1_train, y2_1_test = train_test_split(x2_1, y2_1, test_size=0.33, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display on map x_train & x_test for Azeri\n",
    "fig = go.Figure()\n",
    "field_avg_coord_chg = field_avg_coord[field_avg_coord.field.isin(chg_lst)]\n",
    "# field_avg_coord_azr = field_avg_coord[field_avg_coord.field.isin(azr_lst)] \n",
    "fig.add_trace(go.Scatter(x=x2_1_train[:,0], y=x2_1_train[:,1], \n",
    "                         marker=dict(color='rgb(255, 255, 255)', size=y2_1_train*0.01, line=dict(color='rgb(252, 48, 3)', width=3)),\n",
    "                         mode='markers', name='train set'))\n",
    "fig.add_trace(go.Scatter(x=x2_1_test[:,0], y=x2_1_test[:,1], \n",
    "                         marker=dict(color='rgb(255, 255, 255)', size=y2_1_test*0.01, line=dict(color='rgb(52, 61, 235)', width=3)),\n",
    "                         mode='markers', name='test set'))\n",
    "fig.add_trace(go.Scatter(x=list(df_avgprop_bal8azr_wa.X), y=list(df_avgprop_bal8azr_wa.Y), customdata = df_avgprop_bal8azr_wa[['well', 'kavg_htst']],\n",
    "                         marker=dict(color=df_avgprop_bal8azr_wa.TVD_SCS, size=df_avgprop_bal8azr_wa.kavg_htst*0.01, colorscale='Viridis_r',  showscale=True,\n",
    "                         line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                         mode='markers', name='kavg_htst wells', hovertemplate=\"\".join([\"well:%{customdata[0]}, kavg_htst:%{customdata[1]}<extra></extra>\"])))\n",
    "fig.add_trace(go.Scatter(x=field_avg_coord_azr.X_wellhead, y=field_avg_coord_azr.Y_wellhead, customdata = field_avg_coord_azr[['field']],\n",
    "                         text=field_avg_coord_azr['field'], textposition=\"middle right\",\n",
    "                         marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                         mode='markers+text', name='Platforms', \n",
    "                         marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])))\n",
    "fig.update_layout(title_text='Balakhany VIII sand KHtst, size=f(KHtst), color=f(TVD_SCS) for RFR prediction Azeri',\n",
    "                  autosize=True, width=1000, height=500, margin=dict(l=10,r=10,b=10,t=50))\n",
    "fig.update_layout(legend=dict( yanchor=\"top\", y=1, xanchor=\"right\", x=1, bgcolor='rgba(255,255,255,1)', bordercolor='Black',borderwidth=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal VIII sand Azeri\n",
    "RF2_1 = RandomForestRegressor()\n",
    "grid_param_RF2_1 = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "    'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF2_1 = GridSearchCV(estimator = RF2_1, param_grid = grid_param_RF2_1, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF2_1.fit(x2_1_train, y2_1_train)\n",
    "print(gd_sr_RF2_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor for Bal VIII sand Azeri avg df_htst_avgprop-dataset \n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':None, \n",
    "              'min_samples_leaf':2, \n",
    "              'min_samples_split':3,\n",
    "              'n_estimators':10}\n",
    "RF2_1 = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                              max_depth=RF_setting['max_depth'], \n",
    "                              min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                              min_samples_split=RF_setting['min_samples_split'], \n",
    "                              n_estimators=RF_setting['n_estimators'])\n",
    "RF2_1.fit(x2_1_train, y2_1_train)\n",
    "#Returning our prediction values for the test data\n",
    "y2_1_pred_train = RF2_1.predict(x2_1_train)\n",
    "y2_1_pred = RF2_1.predict(x2_1_test)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results_v2_1 = pd.DataFrame({'Actual': y2_1_test, 'Predicted': y2_1_pred})\n",
    "result_ml_plot(res = df_results_v2_1, dataset = df_avgprop_bal8azr_wa, kh='kavg_htst', max_val=3000)\n",
    "metric_result_print(y2_1_train, y2_1_pred_train, y2_1_test, y2_1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature_importances for Bal VIII sand wa Azeri\n",
    "feature_names = df_avgprop_bal8azr_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns\n",
    "mdi_importances = pd.Series(RF2_1.feature_importances_, index=feature_names).sort_values(ascending=True)\n",
    "ax = mdi_importances.plot.barh()\n",
    "ax.set_title(\"RFR Feature Importances Bal VIII sand wa Azeri\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal VIII sand wa Azeri test set\n",
    "result_pi_test = permutation_importance(RF2_1, x2_1_test, y2_1_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx = result_pi_test.importances_mean.argsort()\n",
    "importances = pd.DataFrame(result_pi_test.importances[sorted_importances_idx].T,\n",
    "                           columns=df_avgprop_bal8azr_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx])\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal VIII sand wa Azeri (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal VIII sand wa Azeri training set\n",
    "result_pi_train = permutation_importance(RF2_1, x2_1_train, y2_1_train, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx_train = result_pi_train.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(result_pi_train.importances[sorted_importances_idx_train].T,\n",
    "                                 columns=df_avgprop_bal8azr_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx_train])\n",
    "ax = importances_train.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal VIII sand wa Azeri (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run RFR Bal10_sand smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balakhany X simple averaging\n",
    "df_avgprop_bal10 = df_avgprop_final[df_avgprop_final.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                    df_avgprop_final.well.isin(well_no_outliers10)].dropna()\n",
    "# X_train/x_test data splitting\n",
    "y3 = np.array(df_avgprop_bal10['kavg_htst'].values)\n",
    "x3 = np.array(df_avgprop_bal10.drop(['well','FORMATION','field','kavg_htst'], axis=1))\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.33, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal X sand\n",
    "RF3 = RandomForestRegressor()\n",
    "grid_param_RF3 = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "    'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF3 = GridSearchCV(estimator = RF3, param_grid = grid_param_RF3, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF3.fit(x3_train, y3_train)\n",
    "print(gd_sr_RF3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor for Bal X simple avg df_htst_avgprop-dataset \n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':100, \n",
    "              'min_samples_leaf':2, \n",
    "              'min_samples_split':3,\n",
    "              'n_estimators':25} \n",
    "RF3 = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                           max_depth=RF_setting['max_depth'], \n",
    "                           min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                           min_samples_split=RF_setting['min_samples_split'], \n",
    "                           n_estimators=RF_setting['n_estimators'])\n",
    "RF3.fit(x3_train, y3_train)\n",
    "#Returning our prediction values for the test data\n",
    "y3_pred_train = RF3.predict(x3_train)\n",
    "y3_pred = RF3.predict(x3_test)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results_v3 = pd.DataFrame({'Actual': y3_test, 'Predicted': y3_pred})\n",
    "result_ml_plot(res = df_results_v3, dataset = df_avgprop_bal10, kh='kavg_htst', max_val=6000)\n",
    "metric_result_print(y3_train, y3_pred_train, y3_test, y3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run RFR Bal10_sand wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balakhany X weighted averaging\n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)].dropna()\n",
    "#X_train/x_test data splitting\n",
    "y4 = np.array(df_avgprop_bal10_wa['kavg_htst'].values)\n",
    "x4 = np.array(df_avgprop_bal10_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1))\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.33, random_state=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal X sand\n",
    "RF4 = RandomForestRegressor()\n",
    "grid_param_RF4 = {'bootstrap': [True, False],\n",
    "                  'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "                  'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "                  'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "                  'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF4 = GridSearchCV(estimator = RF4, param_grid = grid_param_RF4, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF4.fit(x4_train, y4_train)\n",
    "print(gd_sr_RF4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor for Bal X weighted avg df_htst_avgprop-dataset \n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':100, \n",
    "              'min_samples_leaf':1, \n",
    "              'min_samples_split':5,\n",
    "              'n_estimators':10} \n",
    "RF4 = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                           max_depth=RF_setting['max_depth'], \n",
    "                           min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                           min_samples_split=RF_setting['min_samples_split'], \n",
    "                           n_estimators=RF_setting['n_estimators'])\n",
    "RF4.fit(x4_train, y4_train)\n",
    "#Returning our prediction values for the test data\n",
    "y4_pred_train = RF4.predict(x4_train)\n",
    "y4_pred = RF4.predict(x4_test)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results_v4 = pd.DataFrame({'Actual': y4_test, 'Predicted': y4_pred})\n",
    "result_ml_plot(res = df_results_v4, dataset = df_avgprop_bal10_wa, kh='kavg_htst', max_val=6000)\n",
    "metric_result_print(y4_train, y4_pred_train, y4_test, y4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal X sand wa test set\n",
    "result_pi_test = permutation_importance(RF4, x4_test, y4_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx = result_pi_test.importances_mean.argsort()\n",
    "importances = pd.DataFrame(result_pi_test.importances[sorted_importances_idx].T,\n",
    "                           columns=df_avgprop_bal10_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx])\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal X sand wa (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance for Bal X sand wa train set\n",
    "result_pi_train = permutation_importance(RF4, x4_train, y4_train, n_repeats=10, random_state=42, n_jobs=2)\n",
    "sorted_importances_idx_train = result_pi_train.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(result_pi_train.importances[sorted_importances_idx_train].T,\n",
    "                                 columns=df_avgprop_bal10_wa.drop(['well','FORMATION','field','kavg_htst'], axis=1).columns[sorted_importances_idx_train])\n",
    "ax = importances_train.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp Bal X sand wa (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation dist-kh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                 df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                 ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                 ['well','FORMATION'], axis=1)).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand.\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation dataset for X_train/x_test data splitting\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "well_clean_azr = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand') & \n",
    "                                  (df_khtst_bal_qcl.field.isin(azr_lst))].well\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_dist = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld_azr = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.field.isin(azr_lst)) & \n",
    "                                                        (df_well_kh_dist_bal8_fld.well.isin(well_clean_azr)) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_bal8_fld_all = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# df_well_kh_dist_bal8_fld_azr[['kh1','kh2', 'kh3', 'KHtst' ]] = df_well_kh_dist_bal8_fld_azr[['kh1','kh2', 'kh3','KHtst' ]].apply(lambda x: np.log10(x))\n",
    "# df_well_kh_dist_bal8_fld_azr = df_well_kh_dist_bal8_fld_azr[~((df_well_kh_dist_bal8_fld_azr.well.str.contains('Z')) | \n",
    "#                                                              (df_well_kh_dist_bal8_fld_azr.well.str.contains('Y')))].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation dataset for Balakhany X\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_dist = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld_azr = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.field.isin(azr_lst)) & \n",
    "                                                        (df_well_kh_dist_bal8_fld.well.isin(well_clean_azr)) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_bal8_fld_all = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                        (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# df_well_kh_dist_bal8_fld_azr[['kh1','kh2', 'kh3', 'KHtst' ]] = df_well_kh_dist_bal8_fld_azr[['kh1','kh2', 'kh3','KHtst' ]].apply(lambda x: np.log10(x))\n",
    "# df_well_kh_dist_bal8_fld_azr = df_well_kh_dist_bal8_fld_azr[~((df_well_kh_dist_bal8_fld_azr.well.str.contains('Z')) | \n",
    "#                                                              (df_well_kh_dist_bal8_fld_azr.well.str.contains('Y')))].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loop with RFR for dist-kh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for ML-model\n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':20, \n",
    "              'min_samples_leaf':2, \n",
    "              'min_samples_split':2,\n",
    "              'n_estimators':5}\n",
    "# Starting of the loop\n",
    "y_test_lst = []\n",
    "y_pred_lst = []\n",
    "well_exclude_lst = []\n",
    "for i in tqdm(range(len(df_well_kh_dist_bal8_fld_all))):\n",
    "    df_wo_well = df_well_kh_dist_bal8_fld_all.drop([i])\n",
    "    well_exclude = df_well_kh_dist_bal8_fld_all.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[['dist1', 'dist2', 'dist3', 'kh1', 'kh2', 'kh3']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_well_kh_dist_bal8_fld_all.iloc[i]['KHtst'])\n",
    "    x_test = np.array(df_well_kh_dist_bal8_fld_all.iloc[i][['dist1', 'dist2', 'dist3', 'kh1', 'kh2', 'kh3']])\n",
    "    y_test_lst.append(y_test)\n",
    "# Statement of ML-model\n",
    "    RF = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                               max_depth=RF_setting['max_depth'], \n",
    "                               min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                               min_samples_split=RF_setting['min_samples_split'], \n",
    "                               n_estimators=RF_setting['n_estimators'])\n",
    "    RF.fit(x_train, y_train)\n",
    "    y_pred = RF.predict([x_test]).round(0) \n",
    "    y_pred_lst.append(y_pred[0])\n",
    "# Building up of dataframe\n",
    "res_rfr = pd.DataFrame(zip(y_test_lst,y_pred_lst,well_exclude_lst), columns = ['test','predict','well_excl'])\n",
    "res_rfr['l_test'] = res_rfr.test*0.75\n",
    "res_rfr['h_test'] = res_rfr.test*1.25\n",
    "res_rfr['qc'] = 'out'\n",
    "res_rfr.loc[(res_rfr.predict >= res_rfr.l_test) & (res_rfr.predict <= res_rfr.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_rfr.shape[0])\n",
    "print('wells unpredicted:', res_rfr['qc'].value_counts()['out'], (res_rfr['qc'].value_counts()['out']/res_rfr.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_rfr['qc'].value_counts()['in'], (res_rfr['qc'].value_counts()['in']/res_rfr.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_rfr.test, res_rfr.predict).round(0)\n",
    "r2_df_xy = r2(res_rfr.test, res_rfr.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)\n",
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_rfr, x='test', y='predict', color='qc', hover_data=['well_excl'], width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred dist-kh RFR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run RFR for Bal VIII sand train/test for azeri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch test run for RandForRegr Bal VIII sand\n",
    "RF = RandomForestRegressor()\n",
    "grid_param_RF = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 75, 100, 150, 200, 500],\n",
    "    'min_samples_leaf': [1, 2, 3, 5, 10],\n",
    "    'min_samples_split': [1, 2, 3, 5, 10, 20],\n",
    "    'n_estimators': [10, 25, 50, 100, 200]}\n",
    "gd_sr_RF = GridSearchCV(estimator = RF, param_grid = grid_param_RF, scoring='r2', cv = None, n_jobs = -1)\n",
    "gd_sr_RF.fit(x_train, y_train)\n",
    "print(gd_sr_RF.best_params_)\n",
    "# X_train/x_test data splitting\n",
    "y = np.array(df_well_kh_dist_bal8_fld_azr['KHtst'].values)\n",
    "x = np.array(df_well_kh_dist_bal8_fld_azr.drop(['well','FORMATION','field','KHtst'], axis=1))\n",
    "w = np.array(df_well_kh_dist_bal8_fld_azr['well'].values)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "RF_setting = {'bootstrap':True, \n",
    "              'max_depth':75, \n",
    "              'min_samples_leaf':1, \n",
    "              'min_samples_split':10,\n",
    "              'n_estimators':25}\n",
    "RF = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                           max_depth=RF_setting['max_depth'], \n",
    "                           min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                           min_samples_split=RF_setting['min_samples_split'], \n",
    "                           n_estimators=RF_setting['n_estimators']) \n",
    "# RF = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "#                                                                         max_depth=RF_setting['max_depth'], \n",
    "#                                                                         min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "#                                                                         min_samples_split=RF_setting['min_samples_split'], \n",
    "#                                                                         n_estimators=RF_setting['n_estimators']))])\n",
    "# #hard verstion with target transformer\n",
    "# ttr = TransformedTargetRegressor(regressor=RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "#                                                                  max_depth=RF_setting['max_depth'], \n",
    "#                                                                  min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "#                                                                  min_samples_split=RF_setting['min_samples_split'], \n",
    "#                                                                  n_estimators=RF_setting['n_estimators']), \n",
    "#                                 transformer = StandardScaler())\n",
    "# RF = Pipeline([(\"scaler\",StandardScaler()),(\"RF\",ttr)])\n",
    "\n",
    "RF.fit(x_train, y_train)\n",
    "#Returning our prediction values for the test data\n",
    "y_pred_train = RF.predict(x_train)\n",
    "y_pred = RF.predict(x_test)\n",
    "# # Converting log-data to natural values\n",
    "# y_pred_nat = conv_log10_nat(y_pred)\n",
    "# y_test_nat = conv_log10_nat(y_test)\n",
    "# y_pred_train_nat = conv_log10_nat(y_pred_train)\n",
    "# y_train_nat = conv_log10_nat(y_train)\n",
    "#Combining the actual and predicted values into a single df\n",
    "df_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df_results_train = pd.DataFrame({'Actual': y_train, 'Predicted': y_pred_train})\n",
    "result_ml_plot(res = df_results, dataset = df_well_kh_dist_bal8_fld_azr, kh='KHtst', max_val=4000)\n",
    "metric_result_print(y_train,y_pred_train,y_test, y_pred)\n",
    "result_ml_plot(res = df_results_train, dataset = df_well_kh_dist_bal8_fld_azr, kh='KHtst', max_val=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature_importances for Bal VIII sand wa Azeri\n",
    "feature_names = df_well_kh_dist_bal8_fld_azr.drop(['well','FORMATION','field','KHtst'], axis=1).columns\n",
    "# mdi_importances = pd.Series(ttr.regressor_.feature_importances_, index=feature_names).sort_values(ascending=True) #for TransformedTargetRegressor\n",
    "# mdi_importances = pd.Series(RF.steps[1][1].feature_importances_, index=feature_names).sort_values(ascending=True) #for pure Pipeline\n",
    "ax = mdi_importances.plot.barh()\n",
    "ax.set_title(\"RFR Feature Importances Bal VIII Azeri\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation xy-dist-kh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy['KH_log10'] = round(np.log(df_khtst_xy.KHtst))\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy_tvd.set_index('well').join(df_prq_wstat.set_index('well')).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "#Clean dataset for outliers for Balakhany VIII & X  for AZR and CHG fields by rule 1.5 * IQR\n",
    "fm_list_8_10 = ['Balakhany VIII', 'Balakhany VIII sand', 'Balakhany VIII 25','Balakhany VIII 20', \n",
    "             'Balakhany VIII 15', 'Balakhany VIII 10', 'Balakhany VIII 5',\n",
    "             'Balakhany X', 'Balakhany X sand', 'Balakhany X 40', 'Balakhany X 20'] \n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_lst = []\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(azr_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} azr IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(chg_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} chg IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "df_khtst_bal_qcl = pd.concat(df_lst)\n",
    "#Uploading k_htst data from csv-file\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                 df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                 ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                 ['well','FORMATION'], axis=1)).reset_index()\n",
    "# Preparation dataset for X_train/x_test data splitting based on outliers cleaned data\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "well_clean_azr = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand') & \n",
    "                                  (df_khtst_bal_qcl.field.isin(azr_lst))].well\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand.\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')  \n",
    "#Collecting XY based on Euclidean Distances for the top of Balakhany VIII sand.\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == 'Balakhany VIII sand') & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    data[data.well.isin(well_dist3)][['well','X','Y']].T[1:]\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()['index']\n",
    "    well_dist3_x = data[data.well.isin(well_dist3)][['well','X','Y']].T[1:2].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y = data[data.well.isin(well_dist3)][['well','X','Y']].T[2:3].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y.columns =['y1', 'y2', 'y3']\n",
    "    well_dist3_x.columns =['x1', 'x2', 'x3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_x, well_dist3_y, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_xy = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_xy_bal8 = df_well_kh_xy.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal8_fld = df_well_kh_xy_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "# Making up dataset with xy for azeri field\n",
    "df_well_kh_xy_bal8_fld_azr = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.field.isin(azr_lst)) & \n",
    "                                                    (df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# Making up dataset with xy for chirag & azeri fields\n",
    "df_well_kh_xy_bal8_fld_all = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_xy_bal8_fld_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loop with RFR for xy-kh dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop with RFR for azeri fields\n",
    "y_test_lst = []\n",
    "y_pred_lst = []\n",
    "well_exclude_lst = []\n",
    "for i in tqdm(range(len(df_well_kh_xy_bal8_fld_all))):\n",
    "    df_wo_well = df_well_kh_xy_bal8_fld_all.drop([i])\n",
    "    well_exclude = df_well_kh_xy_bal8_fld_all.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[['x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_well_kh_xy_bal8_fld_all.iloc[i]['KHtst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_well_kh_xy_bal8_fld_all.iloc[i][['x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3']])\n",
    "# Statement of ML-model\n",
    "    RF = RandomForestRegressor(bootstrap= RF_setting['bootstrap'], \n",
    "                               max_depth=RF_setting['max_depth'], \n",
    "                               min_samples_leaf=RF_setting['min_samples_leaf'], \n",
    "                               min_samples_split=RF_setting['min_samples_split'], \n",
    "                               n_estimators=RF_setting['n_estimators'])\n",
    "    RF.fit(x_train, y_train)\n",
    "    y_pred = RF.predict([x_test]).round(0) \n",
    "    y_pred_lst.append(y_pred[0])\n",
    "# Building up of dataframe\n",
    "res_rfrxy = pd.DataFrame(zip(y_test_lst,y_pred_lst,well_exclude_lst), columns = ['test','predict','well_excl'])\n",
    "res_rfrxy['l_test'] = res_rfrxy.test*0.75\n",
    "res_rfrxy['h_test'] = res_rfrxy.test*1.25\n",
    "res_rfrxy['qc'] = 'out'\n",
    "res_rfrxy.loc[(res_rfrxy.predict >= res_rfrxy.l_test) & (res_rfrxy.predict <= res_rfrxy.h_test), 'qc'] = 'in'\n",
    "res_rfrxy['l_test'] = res_rfrxy.test*0.75\n",
    "res_rfrxy['h_test'] = res_rfrxy.test*1.25\n",
    "res_rfrxy['qc'] = 'out'\n",
    "res_rfrxy.loc[(res_rfrxy.predict >= res_rfrxy.l_test) & (res_rfrxy.predict <= res_rfrxy.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_rfrxy.shape[0])\n",
    "print('wells unpredicted:', res_rfrxy['qc'].value_counts()['out'], (res_rfrxy['qc'].value_counts()['out']/res_rfrxy.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_rfrxy['qc'].value_counts()['in'], (res_rfrxy['qc'].value_counts()['in']/res_rfrxy.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_rfrxy.test, res_rfrxy.predict).round(0)\n",
    "r2_df_xy = r2(res_rfrxy.test, res_rfrxy.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)\n",
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_rfrxy, x='test', y='predict', color='qc', hover_data=['well_excl'], width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred xy-kh RFR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadir's dataset based on ALL Bal8+10 FU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "# Preparation dataset for X_train/x_test data splitting based on outliers cleaned data\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION.str.contains('Balakhany VIII'))].well\n",
    "df_khtst_xy_tvd_fld_bal = df_khtst_xy_tvd_fld[  df_khtst_xy_tvd_fld.FORMATION.str.contains('Balakhany VIII') |\n",
    "                                                df_khtst_xy_tvd_fld.FORMATION.str.contains('Balakhany X')].drop('DEPTH', axis=1)\n",
    "#Calculation of TST-thickness for ALL Balakhany FU\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION.str.contains('Balakhany')][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]     \n",
    "df_bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION.str.contains('Balakhany')].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_bal_phhpv = df_bal_hpv.set_index(['well','FORMATION']).join(df_bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# df_bal_phhpv\n",
    "#Preparing x,y matrices for ML\n",
    "df_bal_phhpv_tstint = df_bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_bal_phhpv_tstint.rename(columns={'gross_tst':'rock_tst'}, inplace=True)\n",
    "df_bal_phhpv_tstint = df_bal_phhpv_tstint[['well','FORMATION','X', 'Y','TVD_SCS','field','interv_tst','rock_tst', 'vsh_wavg', 'kavg_htst']]\n",
    "df_bal_avgprop = df_bal_phhpv_tstint[df_bal_phhpv_tstint.X.notna() & df_bal_phhpv_tstint.Y.notna() & df_bal_phhpv_tstint.TVD_SCS.notna()]\n",
    "df_bal_avgprop_ohe = pd.get_dummies(df_bal_avgprop, columns = ['FORMATION', 'field'])\n",
    "# Rotating field across the middle to reflect x and y more geologically sensible\n",
    "def rotate(x,y): #rotate x,y around xo,yo by theta (rad)\n",
    "    theta = (math.pi/180)*34\n",
    "    xo = st.median(np.array(df_khtst_xy['X'].to_list()))\n",
    "    yo = st.median(np.array(df_khtst_xy['Y'].to_list()))\n",
    "    xr = math.cos(theta)*(x-xo)-math.sin(theta)*(y-yo) + xo\n",
    "    yr = math.sin(theta)*(x-xo)+math.cos(theta)*(y-yo) + yo\n",
    "    return [xr,yr]\n",
    "df_bal_avgprop_ohe[['X_new', 'Y_new']] = df_bal_avgprop_ohe.apply(lambda row: rotate(row['X'], row['Y']), axis=1, result_type='expand')\n",
    "df_bal_avgprop_ohe = df_bal_avgprop_ohe[(df_bal_avgprop_ohe.kavg_htst < 13000) & (df_bal_avgprop_ohe.kavg_htst > 100)]\n",
    "print('features: ',df_bal_avgprop_ohe.columns)\n",
    "print('dataset size: ',df_bal_avgprop_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadir's dataset 70/30 split RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train/x_test data splitting\n",
    "y = np.array(df_bal_avgprop_ohe[[   'well','kavg_htst']])\n",
    "x = np.array(df_bal_avgprop_ohe[[   'well','X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                    'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                    'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                    'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                    'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                    'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                    'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "num = random.randint(0,100)\n",
    "print('num', num)\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "# Taking well names from train/test datasets\n",
    "y_train_wells = y_train_init[:,0]\n",
    "y_test_wells = y_test_init[:,0]\n",
    "x_train = x_train_init[:,1:]\n",
    "x_test = x_test_init[:,1:]\n",
    "y_train = y_train_init[:,1]\n",
    "y_test = y_test_init[:,1]\n",
    "#Gridsearch test run for RandForRegr Bal VIII sand\n",
    "rfr_gr_sr = RandomForestRegressor()\n",
    "grid_param_RFR = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'min_samples_split': [1, 2, 3, 5],\n",
    "    'n_estimators': [10, 25, 50, 100]}\n",
    "scorer = make_scorer(mae, greater_is_better=False)\n",
    "gd_sr_RFR = GridSearchCV(estimator = rfr_gr_sr, param_grid = grid_param_RFR, scoring=scorer, cv = 15, n_jobs = -1)\n",
    "gd_sr_RFR.fit(x_train, y_train)\n",
    "GS_setting = gd_sr_RFR.best_params_\n",
    "print(GS_setting)\n",
    "# Applying Pipeline for ML-model\n",
    "rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(   bootstrap= GS_setting['bootstrap'], \n",
    "                                                                            max_depth=GS_setting['max_depth'], \n",
    "                                                                            min_samples_leaf=GS_setting['min_samples_leaf'], \n",
    "                                                                            min_samples_split=GS_setting['min_samples_split'], \n",
    "                                                                            n_estimators=GS_setting['n_estimators']))])\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred_train = rfr.predict(x_train)\n",
    "y_pred_test = rfr.predict(x_test)\n",
    "print('---------------------')\n",
    "print('r2_train', r2(y_train, y_pred_train).round(2), 'x_train', x_train.shape)\n",
    "print('r2_test', r2(y_test, y_pred_test).round(2), 'x_test', x_test.shape)\n",
    "print('mae_train', mae(y_train, y_pred_train).round(0))\n",
    "print('mae_test', mae(y_test, y_pred_test).round(0))\n",
    "# QC of predicted values for train & test datasets\n",
    "df_rfr_train = pd.DataFrame(zip(y_train_wells, y_train, y_pred_train), columns=['well', 'actual','predict'])\n",
    "df_rfr_train['l_limit'] = df_rfr_train.actual*0.75\n",
    "df_rfr_train['h_limit'] = df_rfr_train.actual*1.25\n",
    "df_rfr_train['qc'] = 'out'\n",
    "df_rfr_train.loc[(df_gbr_train.predict >= df_gbr_train.l_limit) & (df_gbr_train.predict <= df_gbr_train.h_limit), 'qc'] = 'in'\n",
    "df_rfr_test = pd.DataFrame(zip(y_test_wells, y_test, y_pred_test), columns=['well', 'actual','predict'])\n",
    "df_rfr_test['l_limit'] = df_rfr_test.actual*0.75\n",
    "df_rfr_test['h_limit'] = df_rfr_test.actual*1.25\n",
    "df_rfr_test['qc'] = 'out'\n",
    "df_rfr_test.loc[(df_rfr_test.predict >= df_rfr_test.l_limit) & (df_rfr_test.predict <= df_rfr_test.h_limit), 'qc'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop for Balakhany VIII chirag & azeri\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_bal_avgprop_ohe_gbr = df_bal_avgprop_ohe.sample(frac = 1).reset_index().drop('index', axis=1)\n",
    "for i in tqdm(range(len(df_bal_avgprop_ohe_gbr))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_bal_avgprop_ohe_gbr.drop([i])\n",
    "    well_exclude = df_bal_avgprop_ohe_gbr.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['kavg_htst'])\n",
    "    x_train = np.array(df_wo_well[[ 'X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                    'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                    'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                    'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                    'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                    'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                    'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_bal_avgprop_ohe_gbr.iloc[i]['kavg_htst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_bal_avgprop_ohe_gbr.iloc[i][[  'X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                                        'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                                        'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                                        'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                                        'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                                        'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                                        'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                                        'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                                        'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    # GridSearch for ML-model\n",
    "    # {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
    "    grid_param_RFR = {  'bootstrap' : True,\n",
    "                        'max_depth': [10],\n",
    "                        'min_samples_leaf':[2],\n",
    "                        'min_samples_split' : [5],\n",
    "                        'n_estimators': [50]}\n",
    "    GS_setting = grid_param_RFR\n",
    "    gs_settings_lst.append((    GS_setting['bootstrap'],GS_setting['max_depth'],GS_setting['min_samples_leaf'], \n",
    "                                GS_setting['min_samples_split'], GS_setting['n_estimators']))\n",
    "    # Statement of ML-model\n",
    "    rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(   bootstrap= GS_setting['bootstrap'], \n",
    "                                                                                max_depth=GS_setting['max_depth'][0], \n",
    "                                                                                min_samples_leaf=GS_setting['min_samples_leaf'][0], \n",
    "                                                                                min_samples_split=GS_setting['min_samples_split'][0],\n",
    "                                                                                n_estimators=GS_setting['n_estimators'][0]))])\n",
    "    # Fitting the ML-model\n",
    "    rfr.fit(x_train, y_train)\n",
    "    y_pred_train = rfr.predict(x_train)\n",
    "    y_pred_test = rfr.predict([x_test])\n",
    "    y_pred_test_lst.append(y_pred_test[0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train.round(0)))\n",
    "# Building up of dataframe\n",
    "res_rfr = pd.DataFrame( zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst), \n",
    "                        columns = ['test','predict','well', 'gs_setting',])\n",
    "res_rfr['l_test'] = res_rfr.test*0.75\n",
    "res_rfr['h_test'] = res_rfr.test*1.25\n",
    "res_rfr['qc'] = 'out'\n",
    "res_rfr.loc[(res_rfr.predict >= res_rfr.l_test) & (res_rfr.predict <= res_rfr.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_rfr.shape[0])\n",
    "print('wells unpredicted:', res_rfr['qc'].value_counts()['out'], (res_rfr['qc'].value_counts()['out']/res_rfr.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_rfr['qc'].value_counts()['in'], (res_rfr['qc'].value_counts()['in']/res_rfr.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_rfr.test, res_rfr.predict).round(0)\n",
    "r2_df_xy = r2(res_rfr.test, res_rfr.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_rfr, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred xy-kh rotated full Balakhany GBR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shahriyar request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                                            df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                                            ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                                            ['well','FORMATION'], axis=1)\n",
    "                                                            ).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')    \n",
    "# Preparation dataset for X_train/x_test data splitting\n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "df_collect8 = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect8.append(result)\n",
    "df_well_kh_dist8 = pd.concat(df_collect8).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist8.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_8)) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_collect10 = []\n",
    "for num, well_name in enumerate(dist_bal10.well):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect10.append(result)\n",
    "df_well_kh_dist10 = pd.concat(df_collect10).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal10 = df_well_kh_dist10.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10_fld[(df_well_kh_dist_bal10_fld.well.isin(well_clean_10)) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_all = pd.concat([df_well_kh_dist_bal8_fld, df_well_kh_dist_bal10_fld])\n",
    "#Calculation of TST-thickness Balakhany VIII & X\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_8bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_8bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany VIII sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_8bal_phhpv = df_8bal_hpv.set_index(['well','FORMATION']).join(df_8bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany X sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_10bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany X sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_10bal_phhpv = df_10bal_hpv.set_index(['well','FORMATION']).join(df_10bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# #Preparing x,y matrices for ML\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_8bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop8_final_wa = df_8bal_phhpv_tstint.copy()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_10bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop10_final_wa = df_10bal_phhpv_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 \n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)]\n",
    "df_avgprop_bal8_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                          df_avgprop8_final_wa.well.isin(well_no_outliers8)]\n",
    "df_avgprop_bal_wa = pd.concat([df_avgprop_bal8_wa, df_avgprop_bal10_wa])\n",
    "# For Shahriyar\n",
    "df_dist_kh_bal_shahriayr =  df_avgprop_bal_wa.set_index(['well','FORMATION']).join(\n",
    "                            df_well_kh_dist_all.drop('field',axis=1).set_index(['well','FORMATION'])\n",
    "                            ).reset_index()\n",
    "#rotate x,y around xo,yo by theta (rad)\n",
    "def rotate(x,y): \n",
    "    theta = (math.pi/180)*34\n",
    "    xo = st.median(np.array(df_khtst_xy['X'].to_list()))\n",
    "    yo = st.median(np.array(df_khtst_xy['Y'].to_list()))\n",
    "    xr = math.cos(theta)*(x-xo)-math.sin(theta)*(y-yo) + xo\n",
    "    yr = math.sin(theta)*(x-xo)+math.cos(theta)*(y-yo) + yo\n",
    "    return [xr,yr]\n",
    "df_dist_kh_bal_shahriayr[['X_new', 'Y_new']] = df_dist_kh_bal_shahriayr.apply(lambda row: rotate(row['X'], row['Y']), axis=1, result_type='expand')\n",
    "df_dist_kh_bal_shahriayr_final = df_dist_kh_bal_shahriayr[[ 'well','FORMATION', 'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', \n",
    "                                                            'interv_tst','gross_tst','kavg_htst' ]]\n",
    "df_dist_kh_bal_shahriayr_final = pd.get_dummies(df_dist_kh_bal_shahriayr_final, columns = ['FORMATION'])\n",
    "df_dist_kh_bal_shahriayr_final = df_dist_kh_bal_shahriayr_final[(df_dist_kh_bal_shahriayr_final.TVD_SCS.notna()) &\n",
    "                                                                (df_dist_kh_bal_shahriayr_final.kh1.notna())]\n",
    "# df_dist_kh_bal_shahriayr_final.to_csv('df_dist_kh_bal_shahriayr_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70/30 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train/x_test data splitting\n",
    "y = np.array(df_dist_kh_bal_shahriayr_final[[   'well','kavg_htst']])\n",
    "x = np.array(df_dist_kh_bal_shahriayr_final[[   'well','X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst','gross_tst', \n",
    "                                                       'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand']])\n",
    "num = random.randint(0,100)\n",
    "print('num', num)\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "# Taking well names from train/test datasets\n",
    "y_train_wells = y_train_init[:,0]\n",
    "y_test_wells = y_test_init[:,0]\n",
    "x_train = x_train_init[:,1:]\n",
    "x_test = x_test_init[:,1:]\n",
    "y_train = y_train_init[:,1]\n",
    "y_test = y_test_init[:,1]\n",
    "#Gridsearch test run for RandForRegr Bal VIII sand\n",
    "rfr_gr_sr = RandomForestRegressor()\n",
    "grid_param_RFR = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'min_samples_split': [1, 2, 3, 5],\n",
    "    'n_estimators': [10, 25, 50, 100]}\n",
    "scorer = make_scorer(mae, greater_is_better=False)\n",
    "gd_sr_RFR = GridSearchCV(estimator = rfr_gr_sr, param_grid = grid_param_RFR, scoring=scorer, cv = 15, n_jobs = -1)\n",
    "gd_sr_RFR.fit(x_train, y_train)\n",
    "GS_setting = gd_sr_RFR.best_params_\n",
    "print(GS_setting)\n",
    "# Applying Pipeline for ML-model\n",
    "rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(   bootstrap= GS_setting['bootstrap'], \n",
    "                                                                            max_depth=GS_setting['max_depth'], \n",
    "                                                                            min_samples_leaf=GS_setting['min_samples_leaf'], \n",
    "                                                                            min_samples_split=GS_setting['min_samples_split'], \n",
    "                                                                            n_estimators=GS_setting['n_estimators']))])\n",
    "rfr.fit(x_train, y_train)\n",
    "y_pred_train = rfr.predict(x_train)\n",
    "y_pred_test = rfr.predict(x_test)\n",
    "print('---------------------')\n",
    "print('r2_train', r2(y_train, y_pred_train).round(2), 'x_train', x_train.shape)\n",
    "print('r2_test', r2(y_test, y_pred_test).round(2), 'x_test', x_test.shape)\n",
    "print('mae_train', mae(y_train, y_pred_train).round(0))\n",
    "print('mae_test', mae(y_test, y_pred_test).round(0))\n",
    "# QC of predicted values for train & test datasets\n",
    "df_rfr_train = pd.DataFrame(zip(y_train_wells, y_train, y_pred_train), columns=['well', 'actual','predict'])\n",
    "df_rfr_train['l_limit'] = df_rfr_train.actual*0.75\n",
    "df_rfr_train['h_limit'] = df_rfr_train.actual*1.25\n",
    "df_rfr_train['qc'] = 'out'\n",
    "df_rfr_train.loc[(df_gbr_train.predict >= df_gbr_train.l_limit) & (df_gbr_train.predict <= df_gbr_train.h_limit), 'qc'] = 'in'\n",
    "df_rfr_test = pd.DataFrame(zip(y_test_wells, y_test, y_pred_test), columns=['well', 'actual','predict'])\n",
    "df_rfr_test['l_limit'] = df_rfr_test.actual*0.75\n",
    "df_rfr_test['h_limit'] = df_rfr_test.actual*1.25\n",
    "df_rfr_test['qc'] = 'out'\n",
    "df_rfr_test.loc[(df_rfr_test.predict >= df_rfr_test.l_limit) & (df_rfr_test.predict <= df_rfr_test.h_limit), 'qc'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_dist_kh_bal_shahriayr_rfr = df_dist_kh_bal_shahriayr_final.sample(frac = 1).reset_index().drop('index', axis=1)\n",
    "for i in tqdm(range(len(df_dist_kh_bal_shahriayr_rfr))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_dist_kh_bal_shahriayr_rfr.drop([i])\n",
    "    well_exclude = df_dist_kh_bal_shahriayr_rfr.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['kavg_htst'])\n",
    "    x_train = np.array(df_wo_well[[ 'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst','gross_tst', \n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_dist_kh_bal_shahriayr_rfr.iloc[i]['kavg_htst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_dist_kh_bal_shahriayr_rfr.iloc[i][[  'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst','gross_tst', \n",
    "                                                              'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand']])\n",
    "    # GridSearch for ML-model\n",
    "    # {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
    "    grid_param_RFR = {  'bootstrap' : True,\n",
    "                        'max_depth': [10],\n",
    "                        'min_samples_leaf':[2],\n",
    "                        'min_samples_split' : [5],\n",
    "                        'n_estimators': [50]}\n",
    "    GS_setting = grid_param_RFR\n",
    "    gs_settings_lst.append((    GS_setting['bootstrap'],GS_setting['max_depth'],GS_setting['min_samples_leaf'], \n",
    "                                GS_setting['min_samples_split'], GS_setting['n_estimators']))\n",
    "    # Statement of ML-model\n",
    "    rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(   bootstrap= GS_setting['bootstrap'], \n",
    "                                                                                max_depth=GS_setting['max_depth'][0], \n",
    "                                                                                min_samples_leaf=GS_setting['min_samples_leaf'][0], \n",
    "                                                                                min_samples_split=GS_setting['min_samples_split'][0],\n",
    "                                                                                n_estimators=GS_setting['n_estimators'][0]))])\n",
    "    # Fitting the ML-model\n",
    "    rfr.fit(x_train, y_train)\n",
    "    y_pred_train = rfr.predict(x_train)\n",
    "    y_pred_test = rfr.predict([x_test])\n",
    "    y_pred_test_lst.append(y_pred_test[0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train.round(0)))\n",
    "# Building up of dataframe\n",
    "res_rfr_sha = pd.DataFrame( zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst), \n",
    "                        columns = ['test','predict','well', 'gs_setting',])\n",
    "res_rfr_sha['l_test'] = res_rfr_sha.test*0.75\n",
    "res_rfr_sha['h_test'] = res_rfr_sha.test*1.25\n",
    "res_rfr_sha['qc'] = 'out'\n",
    "res_rfr_sha.loc[(res_rfr_sha.predict >= res_rfr_sha.l_test) & (res_rfr_sha.predict <= res_rfr_sha.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_rfr_sha.shape[0])\n",
    "print('wells unpredicted:', res_rfr_sha['qc'].value_counts()['out'], (res_rfr_sha['qc'].value_counts()['out']/res_rfr_sha.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_rfr_sha['qc'].value_counts()['in'], (res_rfr_sha['qc'].value_counts()['in']/res_rfr_sha.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_rfr_sha.test, res_rfr_sha.predict).round(0)\n",
    "r2_df_xy = r2(res_rfr_sha.test, res_rfr_sha.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_rfr_sha, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Shahriyar RFR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

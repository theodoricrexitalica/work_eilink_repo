{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import statistics as st\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import gmean\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as go_offline\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score as r2 \n",
    "from sklearn.metrics import mean_absolute_error as mae \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from yellowbrick.regressor import PredictionError\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import random\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NetThicknessDistribution():\n",
    "\n",
    "    def metadata_parquet_loading():\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "        metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "        metadata = metadata_init.copy()\n",
    "        metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "        metadata.Status = metadata.Status.str.strip()\n",
    "        metadata.Status = metadata.Status.str.lower()\n",
    "        metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "        metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "        metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "        metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "        metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "        metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "        metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "        metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "        metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "        metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "        metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "        metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "        metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "        metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "        metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "        metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "        metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "        metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "        metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "        metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "        metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "        metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "        metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "\n",
    "        #Read data from parquet\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "        df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v10.parquet.gzip')\n",
    "        df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "        df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "        # print('wells in df totally:', len(df_prq.well.unique()))\n",
    "        # Filter data with bad_well_list \n",
    "        bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP', 'A01W_2']\n",
    "        df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "        #Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "        df_prq.loc[df_prq.FLUIDS>0, 'FLUIDS_int'] = 1\n",
    "        df_prq.loc[df_prq.FLUIDS<=0, 'FLUIDS_int'] = 0\n",
    "        df_prq.FLUIDS_int = df_prq.FLUIDS_int.astype('int')\n",
    "        # Unite of FU for each formation\n",
    "\n",
    "        df_bal = df_prq[df_prq.FORMATION.str.contains('Balakhany')]\n",
    "        df_bal.loc[df_bal.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "        df_bal.loc[df_bal.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "        df_bal = df_bal[df_bal.FORMATION_up.notna()]\n",
    "        #Getting XY mean coords of Balakhany formation\n",
    "        xy_coord_mean = df_bal[['well', 'FORMATION_up', 'X', 'Y']]\n",
    "        xy_coord_mean = xy_coord_mean.groupby(['well', 'FORMATION_up']).agg({'X': 'mean', 'Y':'mean'}).reset_index()\n",
    "        xy_coord_mean = xy_coord_mean.rename(columns={'X':'X_mean', 'Y':'Y_mean'})\n",
    "        xy_coord_mean = xy_coord_mean[xy_coord_mean.FORMATION_up.str.contains('Balakhany') & (xy_coord_mean.X_mean>0) & (xy_coord_mean.Y_mean>0)]\n",
    "        df_bal.rename(columns={'X':'X_traj', 'Y':'Y_traj'}, inplace=True)\n",
    "        df_bal = df_bal.set_index(['well', 'FORMATION_up']).join(xy_coord_mean.set_index(['well', 'FORMATION_up'])).reset_index()\n",
    "        return df_bal\n",
    "    df_bal = metadata_parquet_loading()\n",
    "\n",
    "    def well_clean_v2():\n",
    "        #Counting of bad quality logs\n",
    "        bal8_list = [   'Balakhany VIII sand', 'Balakhany VIII 20',   'Balakhany VIII 10',   'Balakhany VIII 25',\n",
    "                        'Balakhany VIII 15',    'Balakhany VIII 5']\n",
    "        well_tot8 = []\n",
    "        well_zero8 = []\n",
    "        well_clean8 = []\n",
    "        for j in df_bal[(df_bal.FORMATION.isin(bal8_list) & (df_bal.PHIT>0))].well.unique():\n",
    "            phit_zero = (len(df_bal[(df_bal.well==j) & (df_bal.FORMATION_up == 'Balakhany VIII')]))\n",
    "            phit_nonzero = (len(df_bal[(df_bal.well==j) & (df_bal.FORMATION_up == 'Balakhany VIII') & (df_bal.PHIT > 0)]))\n",
    "            well_tot8.append(j)\n",
    "            if round((phit_nonzero/phit_zero),2)<=0.90:\n",
    "                well_zero8.append(j)\n",
    "            else:\n",
    "                well_clean8.append(j)\n",
    "                # well_display_ntd(df_bal, j, 'Balakhany VIII', 'NET', round((phit_nonzero/phit_zero),2), 1) #printing well plots with high quality logs\n",
    "\n",
    "        bal10_list = ['Balakhany X', 'Balakhany X sand', 'Balakhany X 40', 'Balakhany X 20', 'Balakhany X 50']\n",
    "        well_tot10 = []\n",
    "        well_zero10 = []\n",
    "        well_clean10 = []\n",
    "        for j in df_bal[(df_bal.FORMATION.isin(bal10_list) & (df_bal.PHIT>0))].well.unique():\n",
    "            phit_zero = (len(df_bal[(df_bal.well==j) & (df_bal.FORMATION_up == 'Balakhany X')]))\n",
    "            phit_nonzero = (len(df_bal[(df_bal.well==j) & (df_bal.FORMATION_up == 'Balakhany X') & (df_bal.PHIT > 0)]))\n",
    "            well_tot10.append(j)\n",
    "            if round((phit_nonzero/phit_zero),2)<=0.90:\n",
    "                # well_display_ntd(df_bal, j, 'Balakhany X', 'NET', round((phit_nonzero/phit_zero),2), 1)\n",
    "                well_zero10.append(j)\n",
    "            else:\n",
    "                well_clean10.append(j)\n",
    "        print('well_tot8', len(well_tot8))\n",
    "        print('well_zero8', len(well_zero8))\n",
    "        print('well_clean8', len(well_clean8))\n",
    "        print('----------------------')\n",
    "        print('well_tot10', len(well_tot10))\n",
    "        print('well_zero10', len(well_zero10))\n",
    "        print('well_clean10', len(well_clean10))\n",
    "\n",
    "        # broken wells Bal8\n",
    "        # A08, A19, H01Z, J05 \n",
    "        # broken wells Bal10\n",
    "        # C31, D25\n",
    "        # high tst_interv Bal8\n",
    "        # E30Z\n",
    "        # small tst_interv Bal8\n",
    "        # G01Z, E05, E01, E01Y, E11Z, E07, H01Y, H01Z, A14\n",
    "        # Add wells after review Bal8 \n",
    "        # D04Z, \n",
    "        # Remove wells from clean_list by any reasons\n",
    "        remove_tst8 = ['A08','A19','J05','E30Z','G01Z', 'E05', 'E01', 'E01Y', 'E11Z', 'E07', 'H01Y', 'H01Z', 'A14']\n",
    "        well_clean8_v2 = [i for i in well_clean8 if i not in remove_tst8]\n",
    "        remove_tst10 = ['C31','D25', 'E21A']\n",
    "        well_clean10_v2 = [i for i in well_clean10 if i not in remove_tst10]\n",
    "        print('----------------------')\n",
    "        print('well_clean8_v2: ', len(well_clean8_v2))\n",
    "        print('well_clean10_v2: ', len(well_clean10_v2))\n",
    "        return well_clean8_v2, well_clean10_v2\n",
    "    well_clean8_v2, well_clean10_v2 = well_clean_v2()\n",
    "\n",
    "    # Limitation dataframe to cleaned wells for Bal8 & Bal10\n",
    "    df_net_bal8 = df_bal[['well', 'MD', 'TST', 'NET', 'FORMATION_up', 'LPERM', 'PHIT', 'VSH']]\n",
    "    df_net_bal8 = df_net_bal8[df_net_bal8.well.isin(well_clean8_v2) & (df_net_bal8.FORMATION_up=='Balakhany VIII')]\n",
    "    df_net_bal10 = df_bal[['well', 'MD', 'TST', 'NET', 'FORMATION_up', 'LPERM', 'PHIT', 'VSH']]\n",
    "    df_net_bal10 = df_net_bal10[df_net_bal10.well.isin(well_clean10_v2) & (df_net_bal10.FORMATION_up=='Balakhany X')]\n",
    "    # Calculation dataframe with h_tst from MD to TST for Bal8\n",
    "\n",
    "    def ntd_calculation_brief(dataset,well,desired_fm, net_var='NET'):\n",
    "        data = dataset[(dataset.well==well) & (dataset.FORMATION_up==desired_fm)]\n",
    "        data.iloc[0, 3] = 0\n",
    "        data.iloc[-1, 3] = 0\n",
    "        tst_top = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i-1][net_var]==0)]\n",
    "        tst_bot = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i+1][net_var]==0)]\n",
    "        tops = zip(tst_top, tst_bot)\n",
    "        df_htst = pd.DataFrame(tops, columns=['tst_top', 'tst_bot'])\n",
    "        df_htst['FORMATION_up'] = desired_fm\n",
    "        df_htst['well'] = well\n",
    "        df_htst['h_tst'] = df_htst.tst_bot - df_htst.tst_top\n",
    "        df_htst = df_htst[['well','FORMATION_up','tst_top','tst_bot','h_tst']]\n",
    "        return df_htst\n",
    "    df_list8 = []\n",
    "    print('Calculation dataframe with h_tst from MD to TST for Bal8')\n",
    "    for well in tqdm(df_net_bal8.well.unique()):\n",
    "        df = ntd_calculation_brief(df_net_bal8, well, 'Balakhany VIII', 'NET')\n",
    "        df_list8.append(df)\n",
    "    ntd_net_8 = pd.concat(df_list8)\n",
    "    df_list10 = []\n",
    "    print('Calculation dataframe with h_tst from MD to TST for Bal10')\n",
    "    for well in tqdm(df_net_bal10.well.unique()):\n",
    "        df = ntd_calculation_brief(df_net_bal10, well, 'Balakhany X', 'NET')\n",
    "        df_list10.append(df)\n",
    "    ntd_net_10 = pd.concat(df_list10)\n",
    "    ntd_net_final = pd.concat([ntd_net_8, ntd_net_10])\n",
    "\n",
    "    # Cleaning NET variable and making up NET_clp with clipped data, join NET_clp to main dataframe\n",
    "    def ntd_htst_cleaning(dataset, cutoff):\n",
    "        \"\"\"\n",
    "        dataset - any updated dataset like df_bal...\n",
    "        cutoff - value in TST to remove layers with thickness below cutoff\n",
    "        \"\"\"\n",
    "        df_list_ntd = []\n",
    "        for well in tqdm(dataset.well.unique()):\n",
    "            ntd_well = dataset[(dataset.well ==well)]\n",
    "            ntd_well_cutoff = ntd_well[ntd_well.h_tst >= cutoff]\n",
    "            well_short = df_bal[['well', 'FORMATION_up', 'MD', 'TST', 'GR_N', 'NET', 'FORMATION']]\n",
    "            net_well = well_short[(well_short.well==well)]\n",
    "            net_well['NET_clp'] = 0\n",
    "            for j in range(len(ntd_well_cutoff.well)):\n",
    "                ntd_top = ntd_well_cutoff.iloc[j, 2].round(3)\n",
    "                ntd_bot = ntd_well_cutoff.iloc[j, 3].round(3)\n",
    "                for i in range(len(net_well.TST)):\n",
    "                    well_tst = net_well['TST'].iloc[i].round(3)\n",
    "                    if well_tst >= ntd_top and well_tst <= ntd_bot:\n",
    "                        net_well['NET_clp'].iloc[i] = 1\n",
    "            df_list_ntd.append(net_well)\n",
    "        net_clp = pd.concat(df_list_ntd)\n",
    "        return net_clp\n",
    "    print('Cleaning NET variable and making up NET_clp with clipped data')\n",
    "    net_clp =  ntd_htst_cleaning(ntd_net_final, 1)\n",
    "    df_bal_net = df_bal.set_index(['well','MD']).join(net_clp.drop(\n",
    "        ['FORMATION_up','NET','TST', 'FORMATION', 'GR_N'], axis=1).set_index(['well','MD'])).reset_index()\n",
    "    df_bal_net = df_bal_net[df_bal_net.NET_clp.notna()]\n",
    "\n",
    "    # Cleaning NET_clp from 1-point zero\n",
    "    print('Cleaning NET_clp from 1-point zero')\n",
    "    for i in tqdm(range(len(df_bal_net.NET_clp))):\n",
    "        if (df_bal_net.NET_clp.iloc[i] == 0 and  \n",
    "            df_bal_net.NET_clp.iloc[i-1] == 1 and \n",
    "            df_bal_net.NET_clp.iloc[i+1] == 1):\n",
    "            df_bal_net.NET_clp.iloc[i] = 1        \n",
    "\n",
    "    df_zero_bal = df_bal_net[['well', 'MD', 'TST', 'NET_clp', 'FORMATION_up']]\n",
    "    df_zero_bal8 = df_zero_bal[df_zero_bal.well.isin(well_clean8_v2) & (df_zero_bal.FORMATION_up=='Balakhany VIII')]\n",
    "    df_zero_bal10 = df_zero_bal[df_zero_bal.well.isin(well_clean10_v2) & (df_zero_bal.FORMATION_up=='Balakhany X')]\n",
    "    \n",
    "    def ntd_calculation_zero(dataset,well,formation, net_var='NET'):\n",
    "        data = dataset[(dataset.well==well) & (dataset.FORMATION_up==formation)]\n",
    "        data.iloc[0, 3] = 1\n",
    "        data.iloc[-1, 3] = 1\n",
    "        tst_zero_top = [data.iloc[i]['TST'].round(3) for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 0 and data.iloc[i-1][net_var] == 1)]\n",
    "        tst_zero_bot = [data.iloc[i]['TST'].round(3) for i in range(len(data)-1) \n",
    "                    if (data.iloc[i][net_var] == 0 and data.iloc[i+1][net_var] == 1)]\n",
    "        tops_zero = zip(tst_zero_top, tst_zero_bot)\n",
    "        df_zero_htst = pd.DataFrame(tops_zero, columns=['tst_zero_top', 'tst_zero_bot'])\n",
    "        df_zero_htst['FORMATION_up'] = formation\n",
    "        df_zero_htst['well'] = well\n",
    "        df_zero_htst['h_tst_zero'] = df_zero_htst.tst_zero_bot - df_zero_htst.tst_zero_top\n",
    "        df_zero_htst = df_zero_htst[['well','FORMATION_up','tst_zero_top','tst_zero_bot','h_tst_zero']]\n",
    "        return df_zero_htst\n",
    "    print('NET-zero layers removing Bal8')\n",
    "    df_zero_list8 = []\n",
    "    for well in tqdm(df_zero_bal8.well.unique()):\n",
    "        df = ntd_calculation_zero(df_zero_bal8, well, 'Balakhany VIII', 'NET_clp')\n",
    "        df_zero_list8.append(df)\n",
    "    ntd_zero_8 = pd.concat(df_zero_list8)\n",
    "    \n",
    "    print('NET-zero layers removing Bal10')\n",
    "    df_zero_list10 = []\n",
    "    for well in tqdm(df_zero_bal10.well.unique()):\n",
    "        df = ntd_calculation_zero(df_zero_bal10, well, 'Balakhany X', 'NET_clp')\n",
    "        df_zero_list10.append(df)\n",
    "    ntd_zero_10 = pd.concat(df_zero_list10)\n",
    "    \n",
    "    ntd_zero = pd.concat([ntd_zero_8, ntd_zero_10])\n",
    "\n",
    "    # NET-zero layers removing\n",
    "    print('Run ntd_htst_zero_cleaning')\n",
    "    def ntd_htst_zero_cleaning(dataset_zero, dataset, cutoff, net_var1, net_var2):\n",
    "        df_list_ntd_zero = []\n",
    "        for well in tqdm(dataset_zero.well.unique()):\n",
    "            ntd_well_zero = dataset_zero[(dataset_zero.well ==well)]\n",
    "            ntd_well_zero_sel = ntd_well_zero[ntd_well_zero.h_tst_zero <= cutoff]\n",
    "            well_zero_short = dataset[['well','FORMATION_up','MD','TST', net_var1, 'GR_N', 'NET', 'FORMATION']]\n",
    "            well_zero_short[net_var2] = well_zero_short[net_var1]\n",
    "            well_zero_sel = well_zero_short[(well_zero_short.well==well)]\n",
    "            for j in range(len(ntd_well_zero_sel.well)):\n",
    "                ntd_zero_top = ntd_well_zero_sel.iloc[j, 2].round(3)\n",
    "                ntd_zero_bot = ntd_well_zero_sel.iloc[j, 3].round(3)\n",
    "                for i in range(len(well_zero_sel.TST)):\n",
    "                    well_zero_tst = well_zero_sel['TST'].iloc[i].round(3)\n",
    "                    if well_zero_tst >= ntd_zero_top and well_zero_tst <= ntd_zero_bot:\n",
    "                        well_zero_sel[net_var2].iloc[i] = 1\n",
    "            df_list_ntd_zero.append(well_zero_sel)\n",
    "        result = pd.concat(df_list_ntd_zero)\n",
    "        return result\n",
    "    net_clp2 = ntd_htst_zero_cleaning(ntd_zero, df_bal_net, 1, 'NET_clp', 'NET_clp2')\n",
    "\n",
    "    #Joining NET_clp2 to main dataframe df_bal_net\n",
    "    df_bal_net2 = df_bal_net.set_index(['well','MD']).join(net_clp2.drop(\n",
    "        ['FORMATION_up','GR_N', 'NET','NET_clp', 'FORMATION','TST'], axis=1).set_index(['well','MD'])).reset_index()\n",
    "    df_bal_net2 = df_bal_net2[df_bal_net2.NET_clp2.notna()]\n",
    "\n",
    "    # KHtst calculation and join to the main dataframe df_bal_net2\n",
    "    def calculation_khtst(dataset, net_var):\n",
    "        df_smpl_lst = []\n",
    "        print('TST sampling calculation')\n",
    "        for well_smpl in tqdm(dataset.well.unique()[:]):\n",
    "            tst_sampl = dataset[dataset.well==well_smpl]['TST'].diff()\n",
    "            df_new = dataset[dataset.well==well_smpl].join(tst_sampl, rsuffix='_smpl')    \n",
    "            df_smpl_lst.append(df_new)\n",
    "        df_bal_tst_smpl = pd.concat(df_smpl_lst)\n",
    "        df_kh_lst_fm = []\n",
    "        print('KHtst calculation')\n",
    "        for fm_kh in ['Balakhany VIII', 'Balakhany X']:\n",
    "            df_kh_lst = []\n",
    "            for well_kh in tqdm(dataset.well.unique()[:]):\n",
    "                well_tst_perm = df_bal_tst_smpl[(df_bal_tst_smpl.well==well_kh) & \n",
    "                                                (df_bal_tst_smpl.FORMATION_up==fm_kh)].sort_values(by='MD', ascending=False)\n",
    "                well_tst_perm.loc[well_tst_perm[net_var] == 0, 'LPERM'] = 0\n",
    "                well_tst_perm.loc[well_tst_perm[net_var] == 0, 'PHIT'] = 0\n",
    "                well_tst_perm.loc[well_tst_perm[net_var] == 0, 'VSH'] = 0\n",
    "                well_tst_perm['khtst'] = well_tst_perm.LPERM*well_tst_perm.TST_smpl\n",
    "                well_tst_perm['phithtst'] = well_tst_perm.PHIT*well_tst_perm.TST_smpl\n",
    "                well_tst_perm['vshhtst'] = well_tst_perm.VSH*well_tst_perm.TST_smpl\n",
    "                well_tst_perm['KHtst'] = well_tst_perm.khtst.cumsum()\n",
    "                well_tst_perm['PHITHtst'] = well_tst_perm.phithtst.cumsum()\n",
    "                well_tst_perm['VSHHtst'] = well_tst_perm.vshhtst.cumsum()\n",
    "                well_tst_perm = well_tst_perm.sort_values(by='MD')\n",
    "                df_kh_lst.append(well_tst_perm)\n",
    "            df_khlst = pd.concat(df_kh_lst)\n",
    "            df_kh_lst_fm.append(df_khlst)\n",
    "        df_khlst_fm = pd.concat(df_kh_lst_fm)\n",
    "        # df_khlst_fm = df_khlst_fm.dropna()\n",
    "        return df_khlst_fm[['well', 'FORMATION_up', 'MD', 'TST', 'TST_smpl','KHtst','PHITHtst','VSHHtst']]\n",
    "    df_kh = calculation_khtst(df_bal_net2, 'NET_clp2')\n",
    "    df_bal_net2_kh_init = df_bal_net2.set_index(['well','MD']).join(df_kh.drop(['FORMATION_up', 'TST'], axis=1).set_index(['well','MD'])).reset_index()\n",
    "    df_bal_net2_kh8 = df_bal_net2_kh_init[(df_bal_net2_kh_init.well.isin(well_clean8_v2)) & (df_bal_net2_kh_init.FORMATION_up == 'Balakhany VIII')]\n",
    "    df_bal_net2_kh10 = df_bal_net2_kh_init[(df_bal_net2_kh_init.well.isin(well_clean10_v2)) & (df_bal_net2_kh_init.FORMATION_up == 'Balakhany X')]\n",
    "    df_bal_net2_kh = pd.concat([df_bal_net2_kh8, df_bal_net2_kh10])\n",
    "\n",
    "    # Displaying of ramdom well for example\n",
    "    def well_display_net(dataset, well, formation, net1='NET_clp', net2_flag=0, net2='NET_clp_v2'):\n",
    "        well_sel = dataset[(dataset.well == well) & (dataset.FORMATION_up == formation)]\n",
    "        depth = well_sel['TST']\n",
    "        grn = well_sel['GR_N']\n",
    "        net = well_sel['NET']\n",
    "        net_clp = well_sel[net1]\n",
    "        if net2_flag == 0:\n",
    "            fig, ax = plt.subplots(1,3, figsize=(4.5,8), sharey=True)\n",
    "            ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), 5))\n",
    "            ax[0].plot(grn, depth, color='green'), ax[0].invert_yaxis(), ax[0].set_xlim(0, 150), ax[0].grid(axis='y')\n",
    "            well_bal_tops = well_sel.groupby('FORMATION')['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains('Balakhany VIII')].FORMATION:\n",
    "                ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0], xmin=0, xmax=150, color='black', lw=2, alpha=0.66)\n",
    "                ax[0].text(10, well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0]+3, i, fontsize = 7, color =\"black\")\n",
    "            ax[1].plot(net, depth, color='orange'), ax[1].set_xlim(0, 1), ax[1].grid(axis='y')\n",
    "            ax[1].fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "            ax[2].plot(net_clp, depth, color='orange'), ax[2].set_xlim(0, 1), ax[2].grid(axis='y')\n",
    "            ax[2].fill_betweenx(depth,net_clp, color='orange', alpha=0.33)\n",
    "            fig.suptitle(well_sel.well.unique()[0], fontsize=14)\n",
    "            fig.tight_layout()\n",
    "        if net2_flag == 1:\n",
    "            net_clp2 = well_sel[net2]\n",
    "            fig, ax = plt.subplots(1,4, figsize=(6,8), sharey=True)\n",
    "            ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), 5))\n",
    "            ax[0].plot(grn, depth, color='green'), ax[0].invert_yaxis(), ax[0].set_xlim(0, 150), ax[0].grid(axis='y')\n",
    "            well_bal_tops = well_sel.groupby('FORMATION')['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains('Balakhany VIII')].FORMATION:\n",
    "                ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0], xmin=0, xmax=150, color='black', lw=2, alpha=0.66)\n",
    "                ax[0].text(10, well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0]+3, i, fontsize = 7, color =\"black\")\n",
    "            ax[1].plot(net, depth, color='orange', lw=0.25), ax[1].set_xlim(0, 1), ax[1].grid(axis='y')\n",
    "            ax[1].fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "            ax[2].plot(net_clp, depth, color='orange', lw=0.25), ax[2].set_xlim(0, 1), ax[2].grid(axis='y')\n",
    "            ax[2].fill_betweenx(depth,net_clp, color='orange', alpha=0.33)\n",
    "            ax[3].plot(net_clp2, depth, color='orange', lw=0.25), ax[3].set_xlim(0, 1), ax[3].grid(axis='y')\n",
    "            ax[3].fill_betweenx(depth,net_clp2, color='orange', alpha=0.33)\n",
    "            fig.suptitle(well_sel.well.unique()[0], fontsize=14)\n",
    "            fig.tight_layout()\n",
    "        return fig.show()\n",
    "    well_display_net(df_bal_net2_kh, 'J28', 'Balakhany VIII', 'NET_clp', 1, 'NET_clp2')\n",
    "    return df_bal_net2_kh\n",
    "\n",
    "# df_bal_net2_kh = NetThicknessDistribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_upload(path, filename):\n",
    "    df = pd.read_csv(path + filename)\n",
    "    df = df.rename(columns={'wellName':'well', 'FORMATION_JOIN_BEST':'FORMATION', 'FORMATION_TOPS_AZPU':'TOPS_AZPU'})\n",
    "    df['X_traj'] = df['SurfaceX'] + df['XOFFSET']\n",
    "    df['Y_traj'] = df['SurfaceY'] + df['YOFFSET']\n",
    "    df = df[df.FORMATION.notna()]\n",
    "    df.loc[df.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "    df.loc[df.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "    df = df.astype({'well':'string', 'FORMATION':'string', 'FORMATION_up':'string', 'TOPS_AZPU':'string', 'CurrentType':'string', 'Field':'string'})\n",
    "    xy_coord_mean = df.groupby(['well', 'FORMATION_up']).agg({'X_traj': 'mean', 'Y_traj':'mean'}).reset_index()\n",
    "    xy_coord_mean = xy_coord_mean.rename(columns={'X_traj':'X_mean', 'Y_traj':'Y_mean'})\n",
    "    df = df.set_index(['well', 'FORMATION_up']).join(xy_coord_mean.set_index(['well', 'FORMATION_up'])).reset_index()\n",
    "    df.insert(3, 'FORMATION_up',df.pop('FORMATION_up'))\n",
    "    df.insert(28, 'X_traj',df.pop('X_traj'))\n",
    "    df.insert(29, 'Y_traj',df.pop('Y_traj'))\n",
    "    df.insert(30, 'X_mean',df.pop('X_mean'))\n",
    "    df.insert(31, 'Y_mean',df.pop('Y_mean'))\n",
    "    return df\n",
    "df = data_upload('C:\\\\jupyter\\\\SPP\\\\input\\\\', 'newTechlogData_allWells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_by_depth_fm_run(df, step):\n",
    "    df_tst = df[df.TST.notna()].round({'MD':1})\n",
    "    \n",
    "    def interpolate_by_depth_fm(one_well, step):\n",
    "        one_well = one_well.sort_values(by='TST')\n",
    "        well_name = one_well[\"well\"].iloc[0]\n",
    "        data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "        starting_tst = one_well[\"TST\"].iloc[0]\n",
    "        new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "        interp_MD = interp1d(one_well['TST'], one_well['MD'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_DEVI = interp1d(one_well['TST'], one_well['DEVI'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_HAZI = interp1d(one_well['TST'], one_well['HAZI'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_NET = interp1d(one_well['TST'], one_well['NET'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_NET_VSH = interp1d(one_well['TST'], one_well['NET_VSH'], kind='linear', fill_value=\"extrapolate\")\n",
    "        # interp_FLUIDS = interp1d(one_well['TST'], one_well['FLUIDS'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_LPERM = interp1d(one_well['TST'], one_well['LPERM'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_PHIT = interp1d(one_well['TST'], one_well['PHIT'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_GR = interp1d(one_well['TST'], one_well['GR_N'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_VSH = interp1d(one_well['TST'], one_well['VSH'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_NPSS = interp1d(one_well['TST'], one_well['NPSS'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_RHOB = interp1d(one_well['TST'], one_well['RHOB'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_RDEEP = interp1d(one_well['TST'], one_well['RDEEP'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_SON = interp1d(one_well['TST'], one_well['SON'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_SONSH = interp1d(one_well['TST'], one_well['SONSH'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_TVDSCS = interp1d(one_well['TST'], one_well['TVD_SCS'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Xtraj = interp1d(one_well['TST'], one_well['X_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Ytraj = interp1d(one_well['TST'], one_well['Y_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Xmean = interp1d(one_well['TST'], one_well['X_mean'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Ymean = interp1d(one_well['TST'], one_well['Y_mean'], kind='linear', fill_value=\"extrapolate\")    \n",
    "        # Create a new DataFrame with the interpolated values for new TVD_SCS\n",
    "        new_data = {\n",
    "            'well': [well_name for _ in range(len(new_TST_values))],\n",
    "            # 'FORMATION_up': [formation_name for _ in range(len(new_TST_values))],\n",
    "            'tst_index': [_ for _ in range(len(new_TST_values))],\n",
    "            'MD': interp_MD(new_TST_values),\n",
    "            'TST': new_TST_values,\n",
    "            'DEVI': interp_DEVI(new_TST_values),\n",
    "            'HAZI': interp_HAZI(new_TST_values),\n",
    "            'NET': interp_NET(new_TST_values),\n",
    "            'NET_VSH': interp_NET_VSH(new_TST_values),\n",
    "            # 'FLUIDS': interp_FLUIDS(new_TST_values),\n",
    "            'LPERM': interp_LPERM(new_TST_values),\n",
    "            'PHIT': interp_PHIT(new_TST_values),\n",
    "            'GR_N': interp_GR(new_TST_values),\n",
    "            'VSH': interp_VSH(new_TST_values),\n",
    "            'NPSS': interp_NPSS(new_TST_values),\n",
    "            'RHOB': interp_RHOB(new_TST_values),\n",
    "            'RDEEP': interp_RDEEP(new_TST_values),\n",
    "            'SON': interp_SON(new_TST_values),\n",
    "            'SONSH': interp_SONSH(new_TST_values),\n",
    "            'TVD_SCS': interp_TVDSCS(new_TST_values),\n",
    "            'X_traj': interp_Xtraj(new_TST_values),\n",
    "            'Y_traj': interp_Ytraj(new_TST_values),\n",
    "            'Xmean': interp_Xmean(new_TST_values),\n",
    "            'Ymean':interp_Ymean(new_TST_values)\n",
    "        }\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        return new_df\n",
    "    df_lst = []\n",
    "    print('Start interpolation')\n",
    "    for wellnames in tqdm(df_tst.well.unique()):\n",
    "        well_sel = df_tst[df_tst.well == wellnames]\n",
    "        well_interp = interpolate_by_depth_fm(well_sel, step)\n",
    "        df_lst.append(well_interp)\n",
    "    df_interp = pd.concat(df_lst)\n",
    "    df_interp = df_interp.round({'MD':1, 'TVD_SCS':1, 'TST':1})\n",
    "\n",
    "    print('Start joining')\n",
    "    def well_bal_interp_join(dataset):\n",
    "        df_tst = df[df.TST.notna()].round({'MD':1})\n",
    "        data_fu = df_tst[['well','MD','FORMATION_up', 'FORMATION', 'Field']]\n",
    "        well_join = dataset.set_index(['well','MD']).join(data_fu.set_index(['well','MD'])).reset_index()\n",
    "        well_join.insert(3, 'FORMATION_up', well_join.pop('FORMATION_up'))\n",
    "        well_join.insert(4, 'FORMATION', well_join.pop('FORMATION'))\n",
    "        well_join.insert(5, 'tst_index', well_join.pop('tst_index'))\n",
    "        return well_join\n",
    "    well_interp_v2 = well_bal_interp_join(df_interp)\n",
    "    return well_interp_v2\n",
    "df_interp = interpolate_by_depth_fm_run(df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.well == 'A01Y'][['well','MD','TST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp[df_interp.well == 'A01Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phit_cleaning(df):\n",
    "    md_total = df.groupby(['well','FORMATION_up'])['MD'].count().reset_index()\n",
    "    phit_total = df.groupby(['well','FORMATION_up'])['PHIT'].count().reset_index()\n",
    "    vsh_total = df.groupby(['well','FORMATION_up'])['VSH'].count().reset_index()\n",
    "    full_df = md_total.set_index(['well','FORMATION_up']).join(phit_total.set_index(['well','FORMATION_up'])).reset_index()\n",
    "    full_df_v2 = full_df.set_index(['well','FORMATION_up']).join(vsh_total.set_index(['well','FORMATION_up'])).reset_index()\n",
    "    full_df_v2['phit%'] = full_df_v2['PHIT'] / full_df_v2['MD']\n",
    "    full_df_v2['vsh%'] = full_df_v2['VSH'] / full_df_v2['MD']\n",
    "    full_df_v2 = full_df_v2.round({'phit%':2, 'vsh%':2})\n",
    "    phit_clean_bal8 = full_df_v2[(full_df_v2['phit%'] >=0.9) & (full_df_v2.FORMATION_up == 'Balakhany VIII')].well.unique()\n",
    "    phit_clean_bal10 = full_df_v2[(full_df_v2['phit%'] >=0.9) & (full_df_v2.FORMATION_up == 'Balakhany X')].well.unique()\n",
    "    return phit_clean_bal8, phit_clean_bal10\n",
    "phit_clean_bal8, phit_clean_bal10 = phit_cleaning(df_interp)\n",
    "\n",
    "def vsh_cleaning(df):\n",
    "    md_total = df.groupby(['well','FORMATION_up'])['MD'].count().reset_index()\n",
    "    phit_total = df.groupby(['well','FORMATION_up'])['PHIT'].count().reset_index()\n",
    "    vsh_total = df.groupby(['well','FORMATION_up'])['VSH'].count().reset_index()\n",
    "    full_df = md_total.set_index(['well','FORMATION_up']).join(phit_total.set_index(['well','FORMATION_up'])).reset_index()\n",
    "    full_df_v2 = full_df.set_index(['well','FORMATION_up']).join(vsh_total.set_index(['well','FORMATION_up'])).reset_index()\n",
    "    full_df_v2['phit%'] = full_df_v2['PHIT'] / full_df_v2['MD']\n",
    "    full_df_v2['vsh%'] = full_df_v2['VSH'] / full_df_v2['MD']\n",
    "    full_df_v2 = full_df_v2.round({'phit%':2, 'vsh%':2})\n",
    "    vsh_clean_bal8 = full_df_v2[(full_df_v2['vsh%'] >=0.9) & (full_df_v2.FORMATION_up == 'Balakhany VIII')].well.unique()\n",
    "    vsh_clean_bal10 = full_df_v2[(full_df_v2['vsh%'] >=0.9) & (full_df_v2.FORMATION_up == 'Balakhany X')].well.unique()\n",
    "    return vsh_clean_bal8, vsh_clean_bal10\n",
    "vsh_clean_bal8, vsh_clean_bal10 = vsh_cleaning(df_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phit_clean_bal8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagramns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp.loc[df_interp.NET_VSH !=0, 'NET_VSH'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_interp\n",
    "wellname = 'A01Y'\n",
    "fmname = 'Balakhany VIII'\n",
    "\n",
    "# dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "dataset[(dataset.well==wellname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_display_khtst(dataset, wellname, fmname, net_var, comments, ref_depth, fm_flag, depth_step, kh_include, print):\n",
    "    \"\"\"\n",
    "    dataset = df_bal or something else\n",
    "    net_var = NET or FLUIDS_int\n",
    "    comments = put what you want\n",
    "    ref_depth = MD or TST\n",
    "    fm_flag = 1 if you need a FORMATION_up, 0 if just a simple FORMATION\n",
    "    depth_step = step for ticks on the diagramm\n",
    "    kh_include = 1 if we have KHtst in dataset, 0 if there is not KHtst\n",
    "    print = 1 if we want to print the plot\n",
    "    \"\"\"\n",
    "    if fm_flag == 0:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION == fmname)]\n",
    "    if fm_flag == 1:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "    depth = data[ref_depth]\n",
    "    grn = data['GR_N']\n",
    "    vsh = data['VSH']\n",
    "    rhob = data['RHOB'] \n",
    "    npss = data['NPSS']\n",
    "    rdeep = data['RDEEP']\n",
    "    phit = data['PHIT'] \n",
    "    net = data[net_var]\n",
    "    perm = data['LPERM']\n",
    "    if kh_include == 1:\n",
    "        kh = data['KHtst']\n",
    "    else:\n",
    "        data['KHtst'] = 0\n",
    "        kh = data['KHtst']\n",
    "    fig, ax = plt.subplots(1,4, figsize=(7,7), sharey=True)\n",
    "    well_bal_tops = dataset[(dataset.well == wellname)].groupby('FORMATION')[ref_depth].apply(lambda x: x.iloc[0]).reset_index()\n",
    "    ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "    ax[0].plot(grn, depth+10, color='lightgreen', lw=3, zorder=10)\n",
    "    ax[0].invert_yaxis() \n",
    "    ax[0].set_xlim(0, 150) \n",
    "    ax[0].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                    xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "    twin0 = ax[0].twiny()\n",
    "    twin0.plot(vsh, depth, color='black', alpha=0.5, zorder=5)\n",
    "    twin0.set_xlim(0, 1.5)\n",
    "    ax[1].plot(rhob, depth, color='red') \n",
    "    ax[1].invert_yaxis() \n",
    "    ax[1].xaxis.set_ticks(np.arange(1.65, 2.65, 0.3))\n",
    "    ax[1].set_xlim(1.65, 2.65)\n",
    "    ax[1].grid(axis='y'), ax[1].grid(axis='x')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[1].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "        xmin=0, xmax=150, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "        ax[1].text(1.67, well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0]+0.5*depth_step, i, fontsize = 7, color =\"black\")\n",
    "    twin1 = ax[1].twiny()\n",
    "    twin1.plot(npss, depth, color='blue')\n",
    "    twin1.set_xlim(0.6, 0)\n",
    "    # ax[2].plot(rdeep, depth, color='black'), ax[2].set_xscale('log'), ax[2].set_xlim(0.1, 50), ax[2].invert_yaxis(), ax[2].grid(axis='x', which='both')\n",
    "    ax[2].plot(phit, depth, color='green', linestyle='dashed'), ax[2].set_xlim(0.3, 0), ax[2].grid(axis='x') \n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[2].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "    ax[2].vlines(0.13, ymin=min(depth), ymax=max(depth), color='black', linestyle='dashed')\n",
    "    twin2 = ax[2].twiny()\n",
    "    twin2.plot(net, depth, color='orange', linewidth=0.5)\n",
    "    twin2.fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "    twin2.set_xlim(0, 1)\n",
    "    twin2.set_ylim(min(depth), max(depth))\n",
    "    ax[3].plot(perm, depth, color='purple', alpha=0.66), ax[3].set_xscale('log'), ax[3].set_xlim(0.1, 1000)\n",
    "    ax[3].invert_yaxis()\n",
    "    ax[3].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[3].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "    twin4 = ax[3].twiny()\n",
    "    twin4.plot(kh, depth, color='black', alpha=1)\n",
    "    fig.suptitle(wellname + ' ' + fmname + ' ' + ref_depth + ' ' + str(round(max(kh.dropna()),0)) + ' ' + str(comments), fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    if print == 1:\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\wellplots\\\\'\n",
    "        fig.savefig(path + fmname.replace(' ','') + '_' + wellname + '.png')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "well_display_khtst(df, 'C13Z', 'Balakhany VIII', 'NET_VSH', 'test', 'MD', 1, 10, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments to find wrong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_upload_v2(path, filename):\n",
    "    df = pd.read_csv(path + filename)\n",
    "    df = df.rename(columns={'wellName':'well', 'FORMATION_JOIN_BEST':'FORMATION', 'FORMATION_TOPS_AZPU':'TOPS_AZPU'})\n",
    "    df['X_traj'] = df['SurfaceX'] + df['XOFFSET']\n",
    "    df['Y_traj'] = df['SurfaceY'] + df['YOFFSET']\n",
    "    return df\n",
    "df_v2 = data_upload_v2('C:\\\\jupyter\\\\SPP\\\\input\\\\', 'newTechlogData_allWells.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_v2.groupby(['well'])[['MD','GR_N','TST']].count().reset_index()\n",
    "test['rel_gr'] = test['GR_N'] / test['MD']\n",
    "test['rel_tst'] = test['TST'] / test['MD']\n",
    "test[test.rel_tst <= 0.9 ].well.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_well_list_md = test[test.MD <= 100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2[df_v2.well.isin(check_well_list_md.well.unique())].to_csv('check_well_list_md.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2[df_v2.well.isin(check_well_list_md.well.unique())].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v2[df_v2.well.str.startswith('J')].well.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import gmean\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from IPython.display import display, HTML\n",
    "import math\n",
    "from catboost import CatBoostRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as mlines\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as go_offline\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, mapping\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score as r2 \n",
    "from sklearn.metrics import mean_absolute_error as mae \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "import random\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading metadata, distribution wells per Platforms and all the that.\n",
    "def metadata_parquet_loading():\n",
    "    path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "    metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "    metadata = metadata_init.copy()\n",
    "    metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "    metadata.Status = metadata.Status.str.strip()\n",
    "    metadata.Status = metadata.Status.str.lower()\n",
    "    metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "    metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "    metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "    metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "    metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "    metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "    metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "    metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "    metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "    metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "    metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "    metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "    metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "    metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "    metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "    metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "    metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "    metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "    metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "    metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "    metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "    metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "    metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "\n",
    "    #Read data from parquet\n",
    "    path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "    df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v10.parquet.gzip')\n",
    "    df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "    df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "    # print('wells in df totally:', len(df_prq.well.unique()))\n",
    "    # Filter data with bad_well_list \n",
    "    bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP', 'A01W_2']\n",
    "    df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "    #Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "    df_prq.loc[df_prq.FLUIDS>0, 'FLUIDS_int'] = 1\n",
    "    df_prq.loc[df_prq.FLUIDS<=0, 'FLUIDS_int'] = 0\n",
    "    df_prq.FLUIDS_int = df_prq.FLUIDS_int.astype('int')\n",
    "    # Unite of FU for each formation\n",
    "\n",
    "    df_bal = df_prq[df_prq.FORMATION.str.contains('Balakhany')]\n",
    "    df_bal.loc[df_bal.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "    df_bal.loc[df_bal.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "    df_bal = df_bal[df_bal.FORMATION_up.notna()]\n",
    "    #Getting XY mean coords of Balakhany formation\n",
    "    xy_coord_mean = df_bal[['well', 'FORMATION_up', 'X', 'Y']]\n",
    "    xy_coord_mean = xy_coord_mean.groupby(['well', 'FORMATION_up']).agg({'X': 'mean', 'Y':'mean'}).reset_index()\n",
    "    xy_coord_mean = xy_coord_mean.rename(columns={'X':'X_mean', 'Y':'Y_mean'})\n",
    "    xy_coord_mean = xy_coord_mean[xy_coord_mean.FORMATION_up.str.contains('Balakhany') & (xy_coord_mean.X_mean>0) & (xy_coord_mean.Y_mean>0)]\n",
    "    df_bal.rename(columns={'X':'X_traj', 'Y':'Y_traj'}, inplace=True)\n",
    "    df_bal = df_bal.set_index(['well', 'FORMATION_up']).join(xy_coord_mean.set_index(['well', 'FORMATION_up'])).reset_index()\n",
    "    return df_bal\n",
    "df_bal = metadata_parquet_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display in TST well plots with logging curves\n",
    "def well_display_khtst( dataset, wellname, fmname, net_var, comments, \n",
    "                        ref_depth, fm_flag, depth_step, kh_include, print):\n",
    "    \"\"\"\n",
    "    dataset = df_bal or something else\n",
    "    net_var = NET or FLUIDS_int\n",
    "    comments = put what you want\n",
    "    ref_depth = MD or TST\n",
    "    fm_flag = 1 if you need a FORMATION_up, 0 if just a simple FORMATION\n",
    "    depth_step = step for ticks on the diagramm\n",
    "    kh_include = 1 if we have KHtst in dataset, 0 if there is not KHtst\n",
    "    print = 1 if we want to print the plot\n",
    "    \"\"\"\n",
    "    if fm_flag == 0:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION == fmname)]\n",
    "    if fm_flag == 1:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "    depth = data[ref_depth]\n",
    "    grn = data['GR_N']\n",
    "    vsh = data['VSH']\n",
    "    rhob = data['RHOB'] \n",
    "    npss = data['NPSS']\n",
    "    rdeep = data['RDEEP']\n",
    "    phit = data['PHIT'] \n",
    "    net = data[net_var]\n",
    "    perm = data['LPERM']\n",
    "    if kh_include == 1:\n",
    "        kh = data['KHtst']\n",
    "    else:\n",
    "        data['KHtst'] = 0\n",
    "        kh = data['KHtst']\n",
    "    fig, ax = plt.subplots(1,4, figsize=(7,7), sharey=True)\n",
    "    well_bal_tops = df_bal[(df_bal.well == wellname)].groupby('FORMATION')[ref_depth].apply(lambda x: x.iloc[0]).reset_index()\n",
    "    ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "    ax[0].plot(grn, depth, color='lightgreen', lw=3, zorder=10)\n",
    "    ax[0].invert_yaxis() \n",
    "    ax[0].set_xlim(0, 150) \n",
    "    ax[0].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                    xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "    twin0 = ax[0].twiny()\n",
    "    twin0.plot(vsh, depth, color='black', alpha=0.5, zorder=5)\n",
    "    twin0.set_xlim(0, 1.5)\n",
    "    ax[1].plot(rhob, depth, color='red') \n",
    "    ax[1].invert_yaxis() \n",
    "    ax[1].xaxis.set_ticks(np.arange(1.65, 2.65, 0.3))\n",
    "    ax[1].set_xlim(1.65, 2.65)\n",
    "    ax[1].grid(axis='y'), ax[1].grid(axis='x')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[1].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "        xmin=0, xmax=150, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "        ax[1].text(1.67, well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0]+0.5*depth_step, i, fontsize = 7, color =\"black\")\n",
    "    twin1 = ax[1].twiny()\n",
    "    twin1.plot(npss, depth, color='blue')\n",
    "    twin1.set_xlim(0.6, 0)\n",
    "    # ax[2].plot(rdeep, depth, color='black'), ax[2].set_xscale('log'), ax[2].set_xlim(0.1, 50), ax[2].invert_yaxis(), ax[2].grid(axis='x', which='both')\n",
    "    ax[2].plot(phit, depth, color='green', linestyle='dashed'), ax[2].set_xlim(0.3, 0), ax[2].grid(axis='x') \n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].grid(axis='y')\n",
    "    ax[2].vlines(0.13, ymin=min(depth), ymax=max(depth), color='black', linestyle='dashed')\n",
    "    twin2 = ax[2].twiny()\n",
    "    twin2.plot(net, depth, color='orange', linewidth=0.5)\n",
    "    twin2.fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "    twin2.set_xlim(0, 1)\n",
    "    twin2.set_ylim(min(depth), max(depth))\n",
    "    ax[3].plot(perm, depth, color='purple', alpha=0.66), ax[3].set_xscale('log'), ax[3].set_xlim(0.1, 1000)\n",
    "    ax[3].invert_yaxis()\n",
    "    ax[3].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[3].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.66)\n",
    "    twin4 = ax[3].twiny()\n",
    "    twin4.plot(kh, depth, color='black', alpha=1)\n",
    "    fig.suptitle(wellname + ' ' + fmname + ' ' + ref_depth + ' ' + str(round(max(kh.dropna()),0)) + ' ' + str(comments), fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    if print == 1:\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\wellplots\\\\'\n",
    "        fig.savefig(path + fmname.replace(' ','') + '_' + wellname + '.png')\n",
    "    else:\n",
    "        pass\n",
    "# Draw a map\n",
    "def map_value_2plots(metadata, dataset, formation, value, color, multi_chr = 0.001, multi_azr = 0.001):\n",
    "    \"\"\"\n",
    "    metadata, \n",
    "    dataset = dataset with X & Y, \n",
    "    formation = 'Balakhany VIII',  \n",
    "    value = for example 'KHtst' or 'tst_interv'\n",
    "    multi_chr = 0.001, multi_azr = 0.001\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=('crg: ' + str(multi_chr), 'azr: ' + str(multi_azr)), \n",
    "                        vertical_spacing = 0.025)\n",
    "    azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "    chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "    field_avg_coord = metadata.groupby('field')[['X_wellhead','Y_wellhead']].mean().reset_index()\n",
    "    field_avg_coord_chg = field_avg_coord[field_avg_coord.field.isin(chg_lst)]\n",
    "    field_avg_coord_azr = field_avg_coord[field_avg_coord.field.isin(azr_lst)] \n",
    "    df_chg = dataset[(dataset.FORMATION_up == formation) & (dataset.field.isin(chg_lst))]\n",
    "    df_azr = dataset[(dataset.FORMATION_up == formation) & (dataset.field.isin(azr_lst))]\n",
    "    fig.add_trace(go.Scatter(x=df_chg.X, y=df_chg.Y, customdata = df_chg[['well', value, color]],\n",
    "                            marker=dict(color=df_chg[color], size=df_chg[value]*multi_chr, colorscale='Viridis_r',  showscale=True,\n",
    "                            line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            mode='markers', hovertemplate=\"\".join([\"well:%{customdata[0]}, value:%{customdata[1]}, color:%{customdata[2]}<extra></extra>\"])),\n",
    "                            row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=field_avg_coord_chg.X_wellhead, y=field_avg_coord_chg.Y_wellhead, customdata = field_avg_coord_chg[['field']],\n",
    "                            text=field_avg_coord_chg['field'], textposition=\"middle right\",\n",
    "                            marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                            mode='markers+text', \n",
    "                            marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])),\n",
    "                            row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df_azr.X, y=df_azr.Y, customdata = df_azr[['well', value, color]],\n",
    "                            marker=dict(color=df_azr[color], size=df_azr[value]*multi_azr, colorscale='Viridis_r',  showscale=False,\n",
    "                            line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            mode='markers', hovertemplate=\"\".join([\"well:%{customdata[0]}, value:%{customdata[1]}, color:%{customdata[2]}<extra></extra>\"])),\n",
    "                            row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=field_avg_coord_azr.X_wellhead, y=field_avg_coord_azr.Y_wellhead, customdata = field_avg_coord_azr[['field']],\n",
    "                            text=field_avg_coord_azr['field'], textposition=\"middle right\",\n",
    "                            marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                            mode='markers+text', \n",
    "                            marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])),\n",
    "                            row=2, col=1)\n",
    "    fig.update_layout(  title_text= ('formation: ' + str(formation) + ' value: ' + str(value) + ' color: ' + str(color)),\n",
    "                        autosize=True, width=1300, height=1400, margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    return fig.show()\n",
    "# Calculation NTD\n",
    "def ntd_calculation_big(dataset, desired_fm, net_var='NET'):\n",
    "    df_lst = []\n",
    "    for well_in_loop in tqdm(dataset.well.unique()[:]):\n",
    "        well_lst = []\n",
    "        data = dataset[(dataset.well==well_in_loop)]\n",
    "        data.iloc[0, 3] = 0\n",
    "        data.iloc[-1, 3] = 0\n",
    "        tst_top = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i-1][net_var]==0)]\n",
    "        tst_bot = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i+1][net_var]==0)]\n",
    "        for k in range(len(tst_top)):\n",
    "            if (round(tst_top[k],1) == round(tst_bot[k],1)):\n",
    "                h_tst = 0 \n",
    "            elif (round(tst_bot[k],1) == round(tst_top[k]+0.1,1)):\n",
    "                h_tst = 0\n",
    "            else:\n",
    "                h_tst = (round((tst_bot[k] - tst_top[k]),1))\n",
    "                md_perm = []\n",
    "                md_phit = []\n",
    "                md_vsh = []\n",
    "                for i in range(len(data)):\n",
    "                    if round(data.iloc[i]['TST'],1) >= round(tst_top[k],1) and round(data.iloc[i]['TST'],1) <= round(tst_bot[k],1):\n",
    "                        md_perm.append(data.iloc[i]['LPERM'])\n",
    "                        md_phit.append(data.iloc[i]['PHIT'])\n",
    "                        md_vsh.append(data.iloc[i]['VSH'])\n",
    "                if len(md_perm) == 0:\n",
    "                    md_perm.append(0)\n",
    "                if len(md_phit) == 0:\n",
    "                    md_phit.append(0)\n",
    "                if len(md_vsh) == 0:\n",
    "                    md_vsh.append(0)\n",
    "                well_lst.append([data.iloc[0]['well'], h_tst, tst_top[k], tst_bot[k], round(mean(md_perm),0), round(mean(md_phit),2), round(mean(md_vsh),2)])\n",
    "            df_tst = pd.DataFrame(well_lst, columns = ['well', 'h_tst', 'top_tst', 'bot_tst', 'md_perm_avg', 'md_phit_avg', 'md_vsh_avg'])\n",
    "        df_lst.append(df_tst)\n",
    "    ntd_bal = pd.concat(df_lst)\n",
    "    ntd_bal['FORMATION_up'] = desired_fm\n",
    "    return ntd_bal\n",
    "def ntd_calculation_brief(dataset,well,desired_fm, net_var='NET'):\n",
    "    data = dataset[(dataset.well==well) & (dataset.FORMATION_up==desired_fm)]\n",
    "    data.iloc[0, 3] = 0\n",
    "    data.iloc[-1, 3] = 0\n",
    "    tst_top = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                if (data.iloc[i][net_var] == 1 and data.iloc[i-1][net_var]==0)]\n",
    "    tst_bot = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                if (data.iloc[i][net_var] == 1 and data.iloc[i+1][net_var]==0)]\n",
    "    tops = zip(tst_top, tst_bot)\n",
    "    df_htst = pd.DataFrame(tops, columns=['tst_top', 'tst_bot'])\n",
    "    df_htst['FORMATION_up'] = desired_fm\n",
    "    df_htst['well'] = well\n",
    "    df_htst['h_tst'] = df_htst.tst_bot - df_htst.tst_top\n",
    "    df_htst = df_htst[['well','FORMATION_up','tst_top','tst_bot','h_tst']]\n",
    "    return df_htst\n",
    "# Calculation NTD zero\n",
    "def ntd_calculation_zero(dataset,well,formation, net_var='NET'):\n",
    "    data = dataset[(dataset.well==well) & (dataset.FORMATION_up==formation)]\n",
    "    data.iloc[0, 3] = 1\n",
    "    data.iloc[-1, 3] = 1\n",
    "    tst_zero_top = [data.iloc[i]['TST'].round(3) for i in range(len(data)-1)\n",
    "                if (data.iloc[i][net_var] == 0 and data.iloc[i-1][net_var] == 1)]\n",
    "    tst_zero_bot = [data.iloc[i]['TST'].round(3) for i in range(len(data)-1) \n",
    "                if (data.iloc[i][net_var] == 0 and data.iloc[i+1][net_var] == 1)]\n",
    "    tops_zero = zip(tst_zero_top, tst_zero_bot)\n",
    "    df_zero_htst = pd.DataFrame(tops_zero, columns=['tst_zero_top', 'tst_zero_bot'])\n",
    "    df_zero_htst['FORMATION_up'] = formation\n",
    "    df_zero_htst['well'] = well\n",
    "    df_zero_htst['h_tst_zero'] = df_zero_htst.tst_zero_bot - df_zero_htst.tst_zero_top\n",
    "    df_zero_htst = df_zero_htst[['well','FORMATION_up','tst_zero_top','tst_zero_bot','h_tst_zero']]\n",
    "    return df_zero_htst\n",
    "# Print numerical table with layers\n",
    "def ntd_numerical(dataset, wellname, fmname):\n",
    "    \"\"\"\n",
    "    dataset = ntd_final\n",
    "    \"\"\"\n",
    "    df = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname) ][['well','h_tst','top_tst', 'bot_tst','FORMATION_up']]\n",
    "    q50 = df['h_tst'].quantile(q=0.5, interpolation='nearest')\n",
    "    df['q50'] = q50\n",
    "    return df\n",
    "#Cleaning NET variable and making up NET_clp with clipped data\n",
    "def ntd_htst_cleaning(dataset, cutoff):\n",
    "    \"\"\"\n",
    "    dataset - any updated dataset like df_bal...\n",
    "    cutoff - value in TST to remove layers with thickness below cutoff\n",
    "    \"\"\"\n",
    "    df_list_ntd = []\n",
    "    for well in tqdm(dataset.well.unique()):\n",
    "        ntd_well = dataset[(dataset.well ==well)]\n",
    "        ntd_well_cutoff = ntd_well[ntd_well.h_tst >= cutoff]\n",
    "        well_short = df_bal[['well', 'FORMATION_up', 'MD', 'TST', 'GR_N', 'NET', 'FORMATION']]\n",
    "        net_well = well_short[(well_short.well==well)]\n",
    "        net_well['NET_clp'] = 0\n",
    "        for j in range(len(ntd_well_cutoff.well)):\n",
    "            ntd_top = ntd_well_cutoff.iloc[j, 2].round(3)\n",
    "            ntd_bot = ntd_well_cutoff.iloc[j, 3].round(3)\n",
    "            for i in range(len(net_well.TST)):\n",
    "                well_tst = net_well['TST'].iloc[i].round(3)\n",
    "                if well_tst >= ntd_top and well_tst <= ntd_bot:\n",
    "                    net_well['NET_clp'].iloc[i] = 1\n",
    "        df_list_ntd.append(net_well)\n",
    "    net_clp = pd.concat(df_list_ntd)\n",
    "    return net_clp\n",
    "# Cleaning NET_clp variable from zero values with zero_samples <=cutoff\n",
    "def ntd_htst_zero_cleaning(dataset_zero, dataset, cutoff, net_var1, net_var2):\n",
    "    df_list_ntd_zero = []\n",
    "    for well in tqdm(dataset_zero.well.unique()):\n",
    "        ntd_well_zero = dataset_zero[(dataset_zero.well ==well)]\n",
    "        ntd_well_zero_sel = ntd_well_zero[ntd_well_zero.h_tst_zero <= cutoff]\n",
    "        well_zero_short = dataset[['well','FORMATION_up','MD','TST', net_var1, 'GR_N', 'NET', 'FORMATION']]\n",
    "        well_zero_short[net_var2] = well_zero_short[net_var1]\n",
    "        well_zero_sel = well_zero_short[(well_zero_short.well==well)]\n",
    "        for j in range(len(ntd_well_zero_sel.well)):\n",
    "            ntd_zero_top = ntd_well_zero_sel.iloc[j, 2].round(3)\n",
    "            ntd_zero_bot = ntd_well_zero_sel.iloc[j, 3].round(3)\n",
    "            for i in range(len(well_zero_sel.TST)):\n",
    "                well_zero_tst = well_zero_sel['TST'].iloc[i].round(3)\n",
    "                if well_zero_tst >= ntd_zero_top and well_zero_tst <= ntd_zero_bot:\n",
    "                    well_zero_sel[net_var2].iloc[i] = 1\n",
    "        df_list_ntd_zero.append(well_zero_sel)\n",
    "    result = pd.concat(df_list_ntd_zero)\n",
    "    return result\n",
    "# View desired TST-interval\n",
    "def net_view1(dataset, well, top, bot):\n",
    "    dataset = dataset[dataset.well==well][['well','TST','GR_N', 'RHOB', 'NET','NET_clp']]\n",
    "    return dataset[(dataset.TST >= top) & (dataset.TST <= bot)].head(50)\n",
    "#TST sampling & TST KH curve calculation per formation/well\n",
    "def proph_calculation(dataset, net_var):\n",
    "    df_smpl_lst = []\n",
    "    print('TST sampling calculation')\n",
    "    for well_smpl in tqdm(dataset.well.unique()[:]):\n",
    "        tst_sampl = dataset[dataset.well==well_smpl]['TST'].diff()\n",
    "        df_new = dataset[dataset.well==well_smpl].join(tst_sampl, rsuffix='_smpl')    \n",
    "        df_smpl_lst.append(df_new)\n",
    "    df_bal_tst_smpl = pd.concat(df_smpl_lst)\n",
    "    df_kh_lst_fm = []\n",
    "    print('KHtst calculation')\n",
    "    for fm_kh in ['Balakhany VIII', 'Balakhany X']:\n",
    "        df_kh_lst = []\n",
    "        for well_kh in tqdm(dataset.well.unique()[:]):\n",
    "            well_tst_perm = df_bal_tst_smpl[(df_bal_tst_smpl.well==well_kh) & \n",
    "                                            (df_bal_tst_smpl.FORMATION_up==fm_kh)].sort_values(by='MD', ascending=False)\n",
    "            well_tst_perm.loc[well_tst_perm[net_var] == 0, 'LPERM'] = 0\n",
    "            well_tst_perm.loc[well_tst_perm[net_var] == 0, 'PHIT'] = 0\n",
    "            well_tst_perm.loc[well_tst_perm[net_var] == 0, 'VSH'] = 0\n",
    "            well_tst_perm['khtst'] = well_tst_perm.LPERM*well_tst_perm.TST_smpl\n",
    "            well_tst_perm['phithtst'] = well_tst_perm.PHIT*well_tst_perm.TST_smpl\n",
    "            well_tst_perm['vshhtst'] = well_tst_perm.VSH*well_tst_perm.TST_smpl\n",
    "            well_tst_perm['KHtst'] = well_tst_perm.khtst.cumsum()\n",
    "            well_tst_perm['PHITHtst'] = well_tst_perm.phithtst.cumsum()\n",
    "            well_tst_perm['VSHHtst'] = well_tst_perm.vshhtst.cumsum()\n",
    "            well_tst_perm = well_tst_perm.sort_values(by='MD')\n",
    "            df_kh_lst.append(well_tst_perm)\n",
    "        df_khlst = pd.concat(df_kh_lst)\n",
    "        df_kh_lst_fm.append(df_khlst)\n",
    "    df_khlst_fm = pd.concat(df_kh_lst_fm)\n",
    "    # df_khlst_fm = df_khlst_fm.dropna()\n",
    "    return df_khlst_fm[['well', 'FORMATION_up', 'MD', 'TST', 'TST_smpl','KHtst','PHITHtst','VSHHtst']]\n",
    "# Comparison NET_clp and NET_clp2\n",
    "def well_display_net(dataset, well, formation, net1='NET_clp', net2_flag=0, net2='NET_clp_v2'):\n",
    "    well_sel = dataset[(dataset.well == well) & (dataset.FORMATION_up == formation)]\n",
    "    depth = well_sel['TST']\n",
    "    grn = well_sel['GR_N']\n",
    "    net = well_sel['NET']\n",
    "    net_clp = well_sel[net1]\n",
    "    if net2_flag == 0:\n",
    "        fig, ax = plt.subplots(1,3, figsize=(4.5,8), sharey=True)\n",
    "        ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), 5))\n",
    "        ax[0].plot(grn, depth, color='green'), ax[0].invert_yaxis(), ax[0].set_xlim(0, 150), ax[0].grid(axis='y')\n",
    "        well_bal_tops = well_sel.groupby('FORMATION')['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "        for i in well_bal_tops[well_bal_tops.FORMATION.str.contains('Balakhany VIII')].FORMATION:\n",
    "            ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0], xmin=0, xmax=150, color='black', lw=2, alpha=0.66)\n",
    "            ax[0].text(10, well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0]+3, i, fontsize = 7, color =\"black\")\n",
    "        ax[1].plot(net, depth, color='orange'), ax[1].set_xlim(0, 1), ax[1].grid(axis='y')\n",
    "        ax[1].fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "        ax[2].plot(net_clp, depth, color='orange'), ax[2].set_xlim(0, 1), ax[2].grid(axis='y')\n",
    "        ax[2].fill_betweenx(depth,net_clp, color='orange', alpha=0.33)\n",
    "        fig.suptitle(well_sel.well.unique()[0], fontsize=14)\n",
    "        fig.tight_layout()\n",
    "    if net2_flag == 1:\n",
    "        net_clp2 = well_sel[net2]\n",
    "        fig, ax = plt.subplots(1,4, figsize=(6,8), sharey=True)\n",
    "        ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), 5))\n",
    "        ax[0].plot(grn, depth, color='green'), ax[0].invert_yaxis(), ax[0].set_xlim(0, 150), ax[0].grid(axis='y')\n",
    "        well_bal_tops = well_sel.groupby('FORMATION')['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "        for i in well_bal_tops[well_bal_tops.FORMATION.str.contains('Balakhany VIII')].FORMATION:\n",
    "            ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0], xmin=0, xmax=150, color='black', lw=2, alpha=0.66)\n",
    "            ax[0].text(10, well_bal_tops[well_bal_tops.FORMATION==i]['TST'].iloc[0]+3, i, fontsize = 7, color =\"black\")\n",
    "        ax[1].plot(net, depth, color='orange', lw=0.25), ax[1].set_xlim(0, 1), ax[1].grid(axis='y')\n",
    "        ax[1].fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "        ax[2].plot(net_clp, depth, color='orange', lw=0.25), ax[2].set_xlim(0, 1), ax[2].grid(axis='y')\n",
    "        ax[2].fill_betweenx(depth,net_clp, color='orange', alpha=0.33)\n",
    "        ax[3].plot(net_clp2, depth, color='orange', lw=0.25), ax[3].set_xlim(0, 1), ax[3].grid(axis='y')\n",
    "        ax[3].fill_betweenx(depth,net_clp2, color='orange', alpha=0.33)\n",
    "        fig.suptitle(well_sel.well.unique()[0], fontsize=14)\n",
    "        fig.tight_layout()\n",
    "    return fig.show()\n",
    "# Run RFR model with train/test split\n",
    "def rfr_train_test_split(train_dataset, gs_set, scorer, target='KHtst', rng=0.25, margin=0.005):\n",
    "    \"\"\"\n",
    "    'train_ds', \n",
    "    'metrics: r2_train, r2_test, mae_train, mae_test, test_in', \n",
    "    'grid_search', \n",
    "    'result_df', \n",
    "    'train_df', \n",
    "    'test_df'\n",
    "    --------\n",
    "    scorer = make_scorer(mse, greater_is_better=False) <- format scorer like this\n",
    "    \"\"\"\n",
    "    train_dataset_list = []\n",
    "    grids_setting_list = []\n",
    "    metrics_dict = []\n",
    "    # X_train/x_test data splitting\n",
    "    y = np.array(train_dataset[['well','FORMATION_up',target]])\n",
    "    x = np.array(train_dataset.drop(target, axis=1))\n",
    "    num = random.randint(0,100)\n",
    "    # num=42\n",
    "    train_dataset_list.append(train_dataset.drop(['FORMATION_up', target], axis=1).columns[1:].values.tolist())\n",
    "    x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "    # Taking well names from train/test datasets\n",
    "    # x_train_wells = x_train_init[:,2]\n",
    "    # x_test_wells = x_test_init[:,2]\n",
    "    y_train_wells = y_train_init[:,0:2]\n",
    "    y_test_wells = y_test_init[:,0:2]\n",
    "    x_train = x_train_init[:,2:]\n",
    "    x_test = x_test_init[:,2:]\n",
    "    y_train = y_train_init[:,2]\n",
    "    y_test = y_test_init[:,2]\n",
    "    # GridSearch for ML-model\n",
    "    grid_rfr = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    grid_calc_rfr = GridSearchCV(estimator = grid_rfr, param_grid = gs_set, scoring=scorer, cv = 5)\n",
    "    grid_calc_rfr.fit(x_train, y_train)\n",
    "    gd_sr_setting = grid_calc_rfr.best_params_\n",
    "    grids_setting_list.append(gd_sr_setting)\n",
    "    print('Grid_search: ', grid_rfr)\n",
    "    # Applying Pipeline for ML-model\n",
    "    rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(**gd_sr_setting, n_jobs=-1, random_state=42))])\n",
    "    rfr.fit(x_train, y_train)\n",
    "    y_pred_train = rfr.predict(x_train)\n",
    "    y_pred_test = rfr.predict(x_test)\n",
    "    # Reporting\n",
    "    print('Pipeline: ', rfr.steps[1][1])\n",
    "    up_range = rng + 1\n",
    "    dwn_range = 1 - rng\n",
    "    well_fm_train = pd.DataFrame(y_train_wells, columns=['well', 'FORMATION_up'])\n",
    "    rfr_train = pd.DataFrame(zip(y_train, y_pred_train), columns=['actual','predict'])\n",
    "    df_rfr_train = well_fm_train.join(rfr_train)\n",
    "    df_rfr_train['l_limit'] = df_rfr_train.actual*dwn_range - margin\n",
    "    df_rfr_train['h_limit'] = df_rfr_train.actual*up_range + margin\n",
    "    df_rfr_train['qc'] = 'out'\n",
    "    df_rfr_train['dataset'] = 'train'\n",
    "    df_rfr_train.loc[(df_rfr_train.predict >= df_rfr_train.l_limit) & (df_rfr_train.predict <= df_rfr_train.h_limit), 'qc'] = 'in'\n",
    "    well_fm_test = pd.DataFrame(y_test_wells, columns=['well', 'FORMATION_up'])\n",
    "    rfr_test = pd.DataFrame(zip(y_test, y_pred_test), columns=['actual','predict'])\n",
    "    df_rfr_test = well_fm_test.join(rfr_test)\n",
    "    df_rfr_test['l_limit'] = df_rfr_test.actual*dwn_range - margin\n",
    "    df_rfr_test['h_limit'] = df_rfr_test.actual*up_range + margin\n",
    "    df_rfr_test['qc'] = 'out'\n",
    "    df_rfr_test['dataset'] = 'test'\n",
    "    df_rfr_test.loc[(df_rfr_test.predict >= df_rfr_test.l_limit) & (df_rfr_test.predict <= df_rfr_test.h_limit), 'qc'] = 'in'\n",
    "    df_rfr_result = pd.concat([df_rfr_train,df_rfr_test])\n",
    "    df_rfr_result['diff'] = (df_rfr_result.actual - df_rfr_result.predict).round(3)\n",
    "    metrics_dict = {    'r2_train':     r2(y_train, y_pred_train).round(2), \n",
    "                        'r2_test':      r2(y_test, y_pred_test).round(2),\n",
    "                        'mae_train':    mae(y_train, y_pred_train).round(2), \n",
    "                        'mae_test':     mae(y_test, y_pred_test).round(2),\n",
    "                        'train_in':     df_rfr_train['qc'].value_counts(normalize=True)['in'].round(2),\n",
    "                        'test_in':      df_rfr_test['qc'].value_counts(normalize=True)['in'].round(2)}\n",
    "    feature_imp = pd.Series(rfr.steps[1][1].feature_importances_, index=train_dataset_list[0]).sort_values(ascending=True)\n",
    "    return {'train_ds':train_dataset_list[0], \n",
    "            'metrics':metrics_dict, \n",
    "            'grid_search' : grids_setting_list, \n",
    "            'result_df' : df_rfr_result,\n",
    "            'train_df' : df_rfr_train,\n",
    "            'test_df' : df_rfr_test,\n",
    "            'feature_imp' : feature_imp}\n",
    "# Run RFR model with loop\n",
    "def rfr_loop(dataset, fmname, target, hyperdict, rng, margin):\n",
    "    \"\"\"\n",
    "    'train_ds', 'train_ftrs', 'result_df', 'grid_search', 'metrics'\n",
    "    \"\"\"\n",
    "    y_test_lst = []\n",
    "    y_pred_test_lst = []\n",
    "    well_exclude_lst = []\n",
    "    fm_exclude_lst = []\n",
    "    gs_settings_lst = []\n",
    "    metrics_r2_lst = []\n",
    "    metrics_mae_lst = []\n",
    "    ftr_imp_lst = []\n",
    "    for i in tqdm(range(len(dataset))[:]):\n",
    "        #Making up the feature and target datasets\n",
    "        df_wo_well = dataset.drop([i])\n",
    "        well_exclude = dataset.iloc[i]['well']\n",
    "        well_exclude_lst.append(well_exclude)\n",
    "        fm_exclude = dataset.iloc[i][fmname]\n",
    "        fm_exclude_lst.append(fm_exclude)\n",
    "        y_train = np.array(df_wo_well[target])\n",
    "        x_train = np.array(df_wo_well.drop(['well',fmname, target], axis=1))\n",
    "        well_train = np.array(df_wo_well['well'])\n",
    "        y_test = np.array(dataset.iloc[i][target])\n",
    "        y_test_lst.append(y_test)\n",
    "        x_test = np.array(dataset.drop(['well', fmname, target], axis=1).iloc[i])\n",
    "        # Statement of ML-model\n",
    "        rfr = Pipeline([(\"scaler\",StandardScaler()),(\"rfr\",RandomForestRegressor(**hyperdict, n_jobs=-1, random_state=42))])                                                                                  \n",
    "        # Fitting the ML-model\n",
    "        rfr.fit(x_train, y_train)\n",
    "        y_pred_train = rfr.predict(x_train)\n",
    "        y_pred_test = rfr.predict([x_test])\n",
    "        y_pred_test_lst.append(y_pred_test[0])\n",
    "        # Metrics computation for the ML-model\n",
    "        r2_train = r2(y_train, y_pred_train).round(5)\n",
    "        mae_train = mae(y_train, y_pred_train)\n",
    "        metrics_r2_lst.append(r2_train)\n",
    "        metrics_mae_lst.append(mae_train.round(5))\n",
    "        feature_imp = pd.Series(rfr.steps[1][1].feature_importances_, index=df_wo_well.drop(['well', fmname,target], axis=1).columns.tolist()).sort_values(ascending=True)\n",
    "        ftr_imp_lst.append(feature_imp)\n",
    "    # Building up of dataframe\n",
    "    print(rfr.steps[1][1])\n",
    "    res_rfr_sha = pd.DataFrame( zip(y_test_lst, y_pred_test_lst, well_exclude_lst, fm_exclude_lst, metrics_r2_lst, metrics_mae_lst, ftr_imp_lst), \n",
    "                            columns = ['actual','predict','well', 'FORMATION_up','metrics_r2', 'metrics_mae','features_imp'])\n",
    "    res_rfr_sha['l_range'] = res_rfr_sha.actual*(1-rng) - margin \n",
    "    res_rfr_sha['h_range'] = res_rfr_sha.actual*(1+rng) + margin\n",
    "    res_rfr_sha['qc'] = 'out'\n",
    "    res_rfr_sha.loc[(res_rfr_sha.predict >= res_rfr_sha.l_range) & (res_rfr_sha.predict <= res_rfr_sha.h_range), 'qc'] = 'in'\n",
    "    wells_tot = res_rfr_sha.shape[0]\n",
    "    wells_unpred = res_rfr_sha['qc'].value_counts()['out']\n",
    "    wells_unpred_vv = (res_rfr_sha['qc'].value_counts()['out']/res_rfr_sha.shape[0]).round(3)\n",
    "    try:\n",
    "        wells_pred = res_rfr_sha['qc'].value_counts()['in']\n",
    "        wells_pred_vv =  (res_rfr_sha['qc'].value_counts()['in']/res_rfr_sha.shape[0]).round(3)\n",
    "    except:\n",
    "        wells_pred = 0\n",
    "        wells_pred_vv = 0\n",
    "    res_rfr_sha['diff'] = res_rfr_sha.actual - res_rfr_sha.predict\n",
    "    res_rfr_sha = res_rfr_sha[['well','FORMATION_up','actual','predict', 'diff', 'l_range', 'h_range', 'qc', 'metrics_r2', 'metrics_mae', 'features_imp']]\n",
    "    types_dict = {'actual': 'float64', 'predict': 'float64', 'diff': 'float64', 'l_range': 'float64', 'h_range': 'float64'}\n",
    "    res_rfr_sha = res_rfr_sha.astype(types_dict)\n",
    "    res_rfr_sha = res_rfr_sha.round({'actual': 3, 'predict': 3, 'diff': 3})\n",
    "    metrics_dict = {    'wells_total':          wells_tot, \n",
    "                        'wells_unpred':         wells_unpred,\n",
    "                        'wells_unpred_v/v':     wells_unpred_vv,\n",
    "                        'wells_pred':           wells_pred,\n",
    "                        'wells_pred_v/v':       wells_pred_vv\n",
    "                    }\n",
    "    return {    'train_ds': dataset.columns.tolist(),\n",
    "                'train_ftrs': df_wo_well.drop(['well', fmname,target], axis=1).columns.tolist(),\n",
    "                'result_df': res_rfr_sha,\n",
    "                'grid_search' : hyperdict,\n",
    "                'metrics':metrics_dict,\n",
    "                'feature_imp' : feature_imp\n",
    "            }\n",
    "# Run XGBR model with loop \n",
    "def xgbr_loop(dataset, fmname, target, hyperdict, rng, margin):\n",
    "    \"\"\"\n",
    "    'train_ds', 'train_ftrs', 'result_df', 'grid_search', 'metrics'\n",
    "    \"\"\"\n",
    "    y_test_lst = []\n",
    "    y_pred_test_lst = []\n",
    "    well_exclude_lst = []\n",
    "    fm_exclude_lst = []\n",
    "    gs_settings_lst = []\n",
    "    metrics_r2_lst = []\n",
    "    metrics_mae_lst = []\n",
    "    ftr_imp_lst = []\n",
    "    for i in tqdm(range(len(dataset))[:]):\n",
    "        #Making up the feature and target datasets\n",
    "        df_wo_well = dataset.drop([i])\n",
    "        well_exclude = dataset.iloc[i]['well']\n",
    "        well_exclude_lst.append(well_exclude)\n",
    "        fm_exclude = dataset.iloc[i][fmname]\n",
    "        fm_exclude_lst.append(fm_exclude)\n",
    "        y_train = np.array(df_wo_well[target])\n",
    "        x_train = np.array(df_wo_well.drop(['well',fmname, target], axis=1))\n",
    "        well_train = np.array(df_wo_well['well'])\n",
    "        y_test = np.array(dataset.iloc[i][target])\n",
    "        y_test_lst.append(y_test)\n",
    "        x_test = np.array(dataset.drop(['well', fmname, target], axis=1).iloc[i])\n",
    "        xgbr = Pipeline([(\"scaler\",StandardScaler()),(\"xgbr\",XGBRegressor(**hyperdict, n_jobs=-1, random_state=42))])\n",
    "        # Fitting the ML-model\n",
    "        xgbr.fit(x_train, y_train)\n",
    "        y_pred_train = xgbr.predict(x_train)\n",
    "        y_pred_test = xgbr.predict([x_test])\n",
    "        y_pred_test_lst.append(y_pred_test[0])\n",
    "        # Metrics computation for the ML-model\n",
    "        r2_train = r2(y_train, y_pred_train).round(5)\n",
    "        mae_train = mae(y_train, y_pred_train)\n",
    "        metrics_r2_lst.append(r2_train)\n",
    "        metrics_mae_lst.append(mae_train.round(5))\n",
    "        feature_imp = pd.Series(xgbr.steps[1][1].feature_importances_, index=df_wo_well.drop(['well', fmname,target], axis=1).columns.tolist()).sort_values(ascending=True)\n",
    "        ftr_imp_lst.append(feature_imp)\n",
    "\n",
    "    # Building up of dataframe\n",
    "    print(xgbr.steps[1][1])\n",
    "    res_rfr_sha = pd.DataFrame( zip(y_test_lst, y_pred_test_lst, well_exclude_lst, fm_exclude_lst, metrics_r2_lst, metrics_mae_lst, ftr_imp_lst), \n",
    "                            columns = ['actual','predict','well', 'FORMATION_up','metrics_r2', 'metrics_mae','features_imp'])\n",
    "    res_rfr_sha['l_range'] = res_rfr_sha.actual*(1-rng) - margin \n",
    "    res_rfr_sha['h_range'] = res_rfr_sha.actual*(1+rng) + margin \n",
    "    res_rfr_sha['qc'] = 'out'\n",
    "    res_rfr_sha.loc[(res_rfr_sha.predict >= res_rfr_sha.l_range) & (res_rfr_sha.predict <= res_rfr_sha.h_range), 'qc'] = 'in'\n",
    "    wells_tot = res_rfr_sha.shape[0]\n",
    "    wells_unpred = res_rfr_sha['qc'].value_counts()['out']\n",
    "    wells_unpred_vv = (res_rfr_sha['qc'].value_counts()['out']/res_rfr_sha.shape[0]).round(3)\n",
    "    try:\n",
    "        wells_pred = res_rfr_sha['qc'].value_counts()['in']\n",
    "        wells_pred_vv =  (res_rfr_sha['qc'].value_counts()['in']/res_rfr_sha.shape[0]).round(3)\n",
    "    except:\n",
    "        wells_pred = 0\n",
    "        wells_pred_vv = 0\n",
    "    res_rfr_sha['diff'] = res_rfr_sha.actual - res_rfr_sha.predict\n",
    "    res_rfr_sha = res_rfr_sha[['well','FORMATION_up','actual','predict', 'diff','l_range', 'h_range', 'qc', 'metrics_r2', 'metrics_mae', 'features_imp']]\n",
    "    types_dict = {'actual': 'float64', 'predict': 'float64', 'diff': 'float64', 'l_range': 'float64', 'h_range': 'float64'}\n",
    "    res_rfr_sha = res_rfr_sha.astype(types_dict)\n",
    "    res_rfr_sha = res_rfr_sha.round({'actual': 0, 'predict': 0, 'diff': 0})\n",
    "    metrics_dict = {    'wells_total':          wells_tot, \n",
    "                        'wells_unpred':         wells_unpred,\n",
    "                        'wells_unpred_v/v':     wells_unpred_vv,\n",
    "                        'wells_pred':           wells_pred,\n",
    "                        'wells_pred_v/v':       wells_pred_vv\n",
    "                    }\n",
    "    return {    'train_ds': dataset.columns.tolist(),\n",
    "                'train_ftrs': df_wo_well.drop(['well', fmname,target], axis=1).columns.tolist(),\n",
    "                'result_df': res_rfr_sha,\n",
    "                'grid_search' : hyperdict,\n",
    "                'metrics':metrics_dict,\n",
    "                'feature_imp' : feature_imp\n",
    "            }\n",
    "# Display results of ML-modeling\n",
    "def xplot_qc(dataset, dataframe, max_val, rng=0.25):\n",
    "    fig1_ml = px.scatter(dataset[dataframe], x='actual', y='predict', \n",
    "                        color='qc', \n",
    "                        hover_data=['well'], \n",
    "                        width=400, height=400,\n",
    "                        #  color_discrete_sequence=[\"red\", \"green\"]\n",
    "                        )\n",
    "    up_range = rng+1\n",
    "    dwn_range = 1- rng\n",
    "    fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "    fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "    fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*up_range])\n",
    "    fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*dwn_range])\n",
    "    fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "    fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "    fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "    fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "    fig3_ml.update_layout(  title = 'Comparison Actual vs Pred' + \n",
    "                                    ' QC_train: ' + str(dataset['metrics']['train_in']) +\n",
    "                                    ' QC_test: ' + str(dataset['metrics']['test_in']),\n",
    "                            width=600,height=400, xaxis_title='actual', yaxis_title='predict',\n",
    "                            margin=dict(l=10,r=10,b=10,t=40))\n",
    "    return fig3_ml.show()\n",
    "# Calculate weighted avg properties \n",
    "def avg_prop_calculation(dataset_ntd, dataset, formation):\n",
    "    well_data = []\n",
    "    well_formation = formation\n",
    "    for well in tqdm(dataset_ntd.well.unique()):\n",
    "        # print(well)\n",
    "        ntd_well_avgprop = dataset_ntd[(dataset_ntd.well ==well)]\n",
    "        well_avgprop_sel = dataset[(dataset.well==well)]\n",
    "        well_phit = []\n",
    "        well_phit10 = []\n",
    "        well_phit50 = []\n",
    "        well_phit90 = []\n",
    "        well_vsh = []\n",
    "        well_vsh10 = []\n",
    "        well_vsh50 = []\n",
    "        well_vsh90 = []\n",
    "        well_gperm = []\n",
    "        well_h = []\n",
    "        for layers in range(len(ntd_well_avgprop.well)):\n",
    "            ntd_top = ntd_well_avgprop.iloc[layers, 2].round(3)\n",
    "            ntd_bot = ntd_well_avgprop.iloc[layers, 3].round(3)\n",
    "            ntd_h = ntd_well_avgprop.iloc[layers, 4].round(3)\n",
    "            phit_lst = []\n",
    "            vsh_lst = []\n",
    "            perm_lst = []\n",
    "            for depth in range(len(well_avgprop_sel.TST)):\n",
    "                well_avgprop_tst = well_avgprop_sel['TST'].iloc[depth].round(3)\n",
    "                if well_avgprop_tst >= ntd_top and well_avgprop_tst <= ntd_bot:\n",
    "                    phit_lst.append(well_avgprop_sel['PHIT'].iloc[depth])\n",
    "                    vsh_lst.append(well_avgprop_sel['VSH'].iloc[depth])\n",
    "                    perm_lst.append(well_avgprop_sel['LPERM'].iloc[depth])\n",
    "            well_phit.append(mean(phit_lst)*ntd_h)\n",
    "            well_phit10.append(np.quantile(phit_lst, 0.1)*ntd_h)\n",
    "            well_phit50.append(np.quantile(phit_lst, 0.5)*ntd_h)\n",
    "            well_phit90.append(np.quantile(phit_lst, 0.9)*ntd_h)\n",
    "            well_vsh.append(mean(vsh_lst)*ntd_h)\n",
    "            well_vsh10.append(np.quantile(vsh_lst, 0.1)*ntd_h)\n",
    "            well_vsh50.append(np.quantile(vsh_lst, 0.5)*ntd_h)\n",
    "            well_vsh90.append(np.quantile(vsh_lst, 0.9)*ntd_h)\n",
    "            well_gperm.append(gmean(perm_lst)*ntd_h)\n",
    "            well_h.append(ntd_h)\n",
    "        well_phit_wavg = sum(well_phit)/sum(well_h)\n",
    "        well_phit10_wavg = sum(well_phit10)/sum(well_h)\n",
    "        well_phit50_wavg = sum(well_phit50)/sum(well_h)\n",
    "        well_phit90_wavg = sum(well_phit90)/sum(well_h)\n",
    "        well_vsh_wavg = sum(well_vsh)/sum(well_h)\n",
    "        well_vsh10_wavg = sum(well_vsh10)/sum(well_h)\n",
    "        well_vsh50_wavg = sum(well_vsh50)/sum(well_h)\n",
    "        well_vsh90_wavg = sum(well_vsh90)/sum(well_h)\n",
    "        well_perm_wavg = sum(well_gperm)/sum(well_h)\n",
    "        well_hmax = max(well_h)\n",
    "        well_h_p50 = np.quantile(well_h, 0.5)\n",
    "        well_layers_count =len(well_h)\n",
    "        well_hsum = sum(well_h)\n",
    "        well_data.append([  well, well_formation, \n",
    "                            well_hmax, well_h_p50, well_layers_count, well_hsum,\n",
    "                            well_phit_wavg, well_phit10_wavg, well_phit50_wavg, well_phit90_wavg,\n",
    "                            well_vsh_wavg, well_vsh10_wavg, well_vsh50_wavg, well_vsh90_wavg,\n",
    "                            well_perm_wavg])\n",
    "    result = pd.DataFrame(well_data, columns=[  'well','FORMATION_up',\n",
    "                                                'htst_max', 'htst_p50','htst_count', 'htst_sum',            \n",
    "                                                'phit_wavg', 'phit10_wavg','phit50_wavg','phit90_wavg',\n",
    "                                                'vsh_wavg', 'vsh10_wavg', 'vsh50_wavg', 'vsh90_wavg',\n",
    "                                                'perm_wavg'])\n",
    "    return result\n",
    "# Euclidian dist calculation with prop\n",
    "def dist_prop_calc(dataset, dist_formation, dist_cutoff, value):\n",
    "    \"\"\"\n",
    "    dataset have to contain 'X_mean', 'Y_mean', 'TVD_SCS' and 'KHtst', if you assing value as KHtst\n",
    "    \"\"\"\n",
    "    data = dataset[(dataset.FORMATION_up == dist_formation)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X_mean', 'Y_mean', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index(inplace=True)\n",
    "    def well_kh_accum(wells, dataset, kh_formation):\n",
    "        well_kh_accum = []\n",
    "        well_x_accum = []\n",
    "        well_y_accum = []\n",
    "        for i in wells:\n",
    "            well_kh_accum.append(dataset[(dataset.well==i)&(dataset.FORMATION_up == kh_formation)][value].reset_index())    \n",
    "            well_x_accum.append(dataset[(dataset.well==i)&(dataset.FORMATION_up == kh_formation)]['X_mean'].reset_index())\n",
    "            well_y_accum.append(dataset[(dataset.well==i)&(dataset.FORMATION_up == kh_formation)]['Y_mean'].reset_index())\n",
    "        well_kh3 = pd.concat(well_kh_accum).T[1:]\n",
    "        well_kh3.columns = [value + '_1',value + '_2', value + '_3']\n",
    "        well_x3 = pd.concat(well_x_accum).T[1:]\n",
    "        well_x3.columns = ['x1','x2','x3']\n",
    "        well_y3 = pd.concat(well_y_accum).T[1:]\n",
    "        well_y3.columns = ['y1','y2','y3']\n",
    "        final = pd.concat([ well_kh3.reset_index().drop('index',axis=1), \n",
    "                            well_x3.reset_index().drop('index',axis=1), \n",
    "                            well_y3.reset_index().drop('index',axis=1)], axis=1)\n",
    "        return final\n",
    "    df_collect = []\n",
    "    for num, well_name in enumerate(distance_fm_well.well[:]):\n",
    "        well_dist3 = distance_fm_well[distance_fm_well.well == well_name].T[1:].sort_values(by=num)\n",
    "        well_dist3_s2 = well_dist3[well_dist3[num] > dist_cutoff][:3].reset_index()\n",
    "        well_dist3_tuple = tuple(well_dist3_s2['index'])\n",
    "        well_dist3_res = well_dist3_s2.T[1:].reset_index().drop('index', axis=1)   \n",
    "        well_name3_res = well_dist3_s2.T[:1].reset_index().drop('index', axis=1)\n",
    "        well_kh3_res = well_kh_accum(well_dist3_tuple,dataset, dist_formation)\n",
    "        well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "        well_name3_res.columns =['well1', 'well2', 'well3']\n",
    "        concat_df = pd.concat([well_dist3_res, well_kh3_res, well_name3_res], axis=1)\n",
    "        result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "        df_collect.append(result)     \n",
    "    df_well_kh_dist = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "    df_well_kh_dist['FORMATION_up'] = dist_formation\n",
    "    return df_well_kh_dist\n",
    "# Feature importance bar chart for 1-to-all algorithm\n",
    "def feature_imp_loop(dataset, wellname, fmname, xsize, ysize):\n",
    "    # dataset = test['result_df']\n",
    "    data = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "    ftr_imp = data['features_imp'].values[0]\n",
    "    f, ax = plt.subplots(figsize=(xsize, ysize))\n",
    "    ftr_imp.plot.barh()\n",
    "    ax.set_title('RFR feature imp  ' + wellname + ' ' + fmname)\n",
    "    ax.tick_params(axis='y', labelsize=8, rotation=0)\n",
    "    return f.show()\n",
    "# Save datafram to csv\n",
    "def save_tocsv(dataframe, filename, flag):\n",
    "    if flag == 1:\n",
    "        # Saving avg_prop dataframe to .csv\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "        dataframe.to_csv(path + filename)\n",
    "    else:\n",
    "        pass\n",
    "# Feature importance bar chart for split dataframe\n",
    "def feature_imp_split(dataset, xsize, ysize):\n",
    "    fig, ax = plt.subplots(figsize=(xsize, ysize))\n",
    "    ax = dataset.plot.barh()\n",
    "    ax.set_title(\"RFR Feature Importances\")\n",
    "    ax.tick_params(axis='y', labelsize=9, rotation=0)\n",
    "    ax.figure.tight_layout()\n",
    "    return fig.show()\n",
    "# Logging results of ml\n",
    "def write_res_file(finename, comments, target, trainds, metrics, gridsearch):\n",
    "    with open(finename, 'a') as file:\n",
    "        # Get the current date and time\n",
    "        current_datetime = datetime.now()\n",
    "        # Write the result to the file\n",
    "        file.write(f'\\n{current_datetime} \\n {comments} target: {target}')\n",
    "        file.write(f'\\n training_ds_{trainds} \\n metrics_{[metrics]} \\n grid_search_{gridsearch}')\n",
    "    file.close()\n",
    "# Remover categorical values from datasets\n",
    "def cat_finder(dataset):\n",
    "    \"\"\"\n",
    "    cat_list: categorical columns to drop out\n",
    "    get_dum_list: categorical columns to run via pd.get_dummies\n",
    "    \"\"\"\n",
    "    cat_list = []\n",
    "    gm_list = []\n",
    "    for col in dataset.columns:\n",
    "        # print(i)\n",
    "        if dataset[col].dtype == 'string':\n",
    "            cat_list.append(col)\n",
    "            if col != 'well':\n",
    "                gm_list.append(col)\n",
    "    # return {'cat_list':cat_list,\n",
    "    #         'get_dum_list': gm_list}\n",
    "    return cat_list, gm_list\n",
    "# Display results of ML-modeling ver2\n",
    "def xplot_qc2(data, max_val, rng, margin, round):\n",
    "    data = data.round({'actual': round, 'predict': round, 'diff': round})\n",
    "    ds_train = data[data.dataset == 'train']\n",
    "    ds_test = data[data.dataset == 'test']\n",
    "    up_range = rng + 1\n",
    "    dwn_range = 1 - rng\n",
    "    colors = {'in': 'green', 'out': 'red'}\n",
    "    qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "    qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "    scatter_train = go.Scatter( x=ds_train.actual, y=ds_train.predict,\n",
    "                                mode='markers',\n",
    "                                marker=dict(color=qc_colors_tr, size=7, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                customdata = ds_train[['well','actual','predict','diff', 'FORMATION_up']],\n",
    "                                hovertemplate=\"\".join(\n",
    "                                [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]},d:%{customdata[3]}, f:%{customdata[4]}<extra></extra>\"])\n",
    "                                )\n",
    "    scatter_test = go.Scatter(  x=ds_test.actual, y=ds_test.predict, \n",
    "                                mode='markers',\n",
    "                                marker=dict(color=qc_colors_ts, size=7, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                customdata = ds_test[['well','actual','predict','diff', 'FORMATION_up']],\n",
    "                                hovertemplate=\"\".join(\n",
    "                                [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]},d:%{customdata[3]}, f:%{customdata[4]}<extra></extra>\"])\n",
    "                                )\n",
    "    line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "    line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('train ds', 'test ds'))\n",
    "    fig.add_trace(scatter_train,  row=1, col=1)\n",
    "    fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "    fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "    fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "    fig.add_trace(scatter_test,  row=1, col=2)\n",
    "    fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "    fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "    fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "    fig.update_layout(  title_text= ('rfr_train_test_split'), width=900, height=450, \n",
    "                        margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    return fig.show()\n",
    "# Display results of ML-modeling ver2 via loop    \n",
    "def xplot_qc2_loop(data, max_val, rng, margin=0.005):\n",
    "    data = data.round({'actual': 3, 'predict': 3, 'diff ': 3})\n",
    "    up_range = rng + 1\n",
    "    dwn_range = 1 - rng\n",
    "    colors = {'in': 'green', 'out': 'red'}\n",
    "    qc_colors = [colors[qc] for qc in data.qc]\n",
    "    scatter = go.Scatter( x=data.actual, y=data.predict,\n",
    "                            mode='markers',\n",
    "                            marker=dict(color=qc_colors, size=7, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            customdata = data[['well','actual','predict', 'diff', 'FORMATION_up']],\n",
    "                            hovertemplate=\"\".join(\n",
    "                            [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, d:%{customdata[3]}, f:%{customdata[4]}<extra></extra>\"])\n",
    "                            )\n",
    "    fig = go.Figure()\n",
    "    line_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "    line_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "    fig.add_trace(scatter)\n",
    "    fig.add_trace(line_up)\n",
    "    fig.add_trace(line_dw)\n",
    "    fig.update_xaxes(title_text='actual')\n",
    "    fig.update_yaxes(title_text='predict')\n",
    "    fig.update_layout(  title_text= ('rfr_loop'), width=450, height=450, \n",
    "                        margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    return fig.show()\n",
    "# Display results of ML-modeling on map\n",
    "def map_qc(metadata, data, fmname, scale):\n",
    "    data['diff'] = abs(data['diff'])\n",
    "    data = data[data.FORMATION_up == fmname]\n",
    "    data_in = data[data.qc=='in']\n",
    "    data_out = data[data.qc=='out']\n",
    "    field_avg_coord = metadata.groupby('field')[['X_wellhead','Y_wellhead']].mean().reset_index()\n",
    "    platform  = go.Scatter(         x=field_avg_coord.X_wellhead, y=field_avg_coord.Y_wellhead, customdata = field_avg_coord[['field']],\n",
    "                                    text=field_avg_coord['field'], textposition=\"middle right\",\n",
    "                                    marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                                    mode='markers+text', \n",
    "                                    marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])\n",
    "                                    )\n",
    "    scatter_data_in = go.Scatter(   x=data_in.X, y=data_in.Y,\n",
    "                                    mode='markers',\n",
    "                                    marker=dict(symbol='circle', color='green', size=data_in['actual']*scale,\n",
    "                                    opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)\n",
    "                                    ),\n",
    "                                    customdata = data_in[['well', 'diff']],\n",
    "                                    hovertemplate=\"\".join([\"well:%{customdata[0]}, diff:%{customdata[1]}<extra></extra>\"])\n",
    "                                    )\n",
    "    scatter_data_out = go.Scatter(  x=data_out.X, y=data_out.Y, \n",
    "                                    mode='markers',\n",
    "                                    marker=dict(symbol='diamond', color='red', size=data_out['diff']*scale,\n",
    "                                    opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                    customdata = data_out[['well', 'diff']],\n",
    "                                    hovertemplate=\"\".join([\"well:%{customdata[0]}, diff:%{customdata[1]}<extra></extra>\"])\n",
    "                                    )\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(platform)\n",
    "    fig.add_trace(scatter_data_in)\n",
    "    fig.add_trace(scatter_data_out)\n",
    "    fig.update_layout(title_text= ('rfr_train_test_split'),autosize=True, width=1000, height=600, margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    return fig.show()\n",
    "# Pairplot new version\n",
    "def pairplot_special(dataset, xsize, ysize, flag=1):\n",
    "    if flag == 1:\n",
    "        def corrfunc(x, y, **kws):\n",
    "            r, _ = stats.pearsonr(x, y)\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                        xy=(.1, .9), xycoords=ax.transAxes)\n",
    "        sns.set_context(rc={'axes.labelsize':10, 'lines.linewidth': 0.75})\n",
    "        g = sns.PairGrid(dataset)\n",
    "        g.fig.set_size_inches(xsize,ysize)\n",
    "        g.set(xticklabels=[], yticklabels=[]) \n",
    "        g.map_upper(plt.scatter, s=10, alpha=0.5)\n",
    "        g.map_diag(sns.distplot, kde=False)\n",
    "        g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g.map_lower(corrfunc)\n",
    "    else:\n",
    "        pass\n",
    "# Columns reorder for better display of variables\n",
    "def columns_reorder(dataset, selected_column):\n",
    "    new_order = [col for col in dataset.columns if col != selected_column] + [selected_column]\n",
    "    dataset = dataset[new_order]\n",
    "    return dataset\n",
    "# Just simple x-plot for 1 dataframe\n",
    "def log_map_plot(dataframe, x_var, y_var, min_val, max_val):\n",
    "    fig = go.Figure()\n",
    "    scatter = go.Scatter(   x=dataframe[x_var], y=dataframe[y_var], \n",
    "                            mode='markers',\n",
    "                            marker=dict(color='orange', size=10, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            customdata = dataframe[['well',x_var,y_var]],\n",
    "                            hovertemplate=\"\".join(\n",
    "                            [\"w:%{customdata[0]},x:%{customdata[1]}, y:%{customdata[2]}<extra></extra>\"])\n",
    "                            )\n",
    "    line = go.Scatter(x=[min_val, max_val], y=[min_val, max_val], mode='lines', line=dict(color='blue'))\n",
    "    fig.add_trace(scatter)\n",
    "    fig.add_trace(line)\n",
    "    fig.update_layout(  title_text= ('scatter plot'), width=600, height=600, \n",
    "                        margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    return fig.show()\n",
    "# Joining main and additional dataframes for predictions\n",
    "def join_add_df_prediction(base_dataframe, add_dataframe, target_var):\n",
    "    \"\"\"\n",
    "    Both dataframes have contain 'well' & 'FORMATION_up' for joining\n",
    "    \"\"\"\n",
    "    join_dataframe = base_dataframe.set_index(['well','FORMATION_up']).join(add_dataframe.set_index(['well','FORMATION_up'])).reset_index()\n",
    "    col_names, gm_list = cat_finder(join_dataframe)\n",
    "    df_corr = join_dataframe.drop(col_names, axis=1)\n",
    "    df_corr = columns_reorder(df_corr, target_var)\n",
    "    mem_cell = pd.get_dummies(join_dataframe[gm_list], columns=gm_list, drop_first=True)\n",
    "    mem_cell.rename(columns={'FORMATION_up_Balakhany X':'FORMATION_up_gm'},inplace=True)\n",
    "    join_dataframe_gm = pd.concat([join_dataframe, mem_cell], axis=1)\n",
    "    return df_corr, join_dataframe_gm\n",
    "# Preparation dataframes for pairplot and for predictions\n",
    "def join_df_prediction(base_dataframe, target_var):\n",
    "    def columns_reorder(dataset, selected_column):\n",
    "        new_order = [col for col in dataset.columns if col != selected_column] + [selected_column]\n",
    "        dataset = dataset[new_order]\n",
    "        return dataset\n",
    "    def cat_finder(dataset):\n",
    "        \"\"\"\n",
    "        cat_list: categorical columns to drop out\n",
    "        get_dum_list: categorical columns to run via pd.get_dummies\n",
    "        \"\"\"\n",
    "        cat_list = []\n",
    "        gm_list = []\n",
    "        for col in dataset.columns:\n",
    "            # print(i)\n",
    "            if dataset[col].dtype == 'string':\n",
    "                cat_list.append(col)\n",
    "                if col != 'well':\n",
    "                    gm_list.append(col)\n",
    "        # return {'cat_list':cat_list,\n",
    "        #         'get_dum_list': gm_list}\n",
    "        return cat_list, gm_list\n",
    "    col_names, gm_list = cat_finder(base_dataframe)\n",
    "    df_corr = base_dataframe.drop(col_names, axis=1)\n",
    "    df_corr = columns_reorder(df_corr, target_var)\n",
    "    mem_cell = pd.get_dummies(base_dataframe[gm_list], columns=gm_list, drop_first=True)\n",
    "    mem_cell.rename(columns={'FORMATION_up_Balakhany X':'FORMATION_up_gm'},inplace=True)\n",
    "    dataframe = pd.concat([base_dataframe, mem_cell], axis=1)\n",
    "    return df_corr, dataframe\n",
    "# Function to calculate grid_search via train_split\n",
    "def run_rfr_train_test_split(dataset, gs_set, scorer, target, rng, margin, logtxt_name, comment, xplot_flag, ftr_imp_flag):\n",
    "    model_res = rfr_train_test_split(dataset, gs_set, scorer, target, rng, margin)\n",
    "    write_res_file(logtxt_name, comment, target, \n",
    "                    model_res['train_ds'], model_res['metrics'], model_res['grid_search'])\n",
    "    print('train_ds: ', model_res['train_ds'])\n",
    "    print('metrics: ', model_res['metrics'])\n",
    "    print('grid_search: ', model_res['grid_search'])\n",
    "    model_res_hyper_par = model_res['grid_search'][0]\n",
    "    if xplot_flag == 1:\n",
    "        xplot_qc2(dataset['result_df'], 0.3, 0.05, margin)\n",
    "    else:\n",
    "        pass\n",
    "    if ftr_imp_flag == 1:\n",
    "        feature_imp_split(dataset['feature_imp'], 6, 4)\n",
    "    else:\n",
    "        pass\n",
    "    return model_res_hyper_par\n",
    "# Function to calculate target via 1-to-all\n",
    "def run_rfr_1_to_all(dataset, hyperdict, target, rng, margin, logtxt_name, comment, xplot_flag, max_val, ftr_imp_flag):\n",
    "    loop_res = rfr_loop(dataset, 'FORMATION_up', target, hyperdict, rng, margin)\n",
    "    write_res_file(logtxt_name, comment, target, loop_res['train_ds'], loop_res['metrics'], loop_res['grid_search'])\n",
    "    loop_res_pred = loop_res['result_df']\n",
    "    print('train_ftrs: ',loop_res['train_ftrs'])\n",
    "    print('metrics: ',loop_res['metrics'])\n",
    "    if xplot_flag == 1:\n",
    "        xplot_qc2_loop(loop_res['result_df'], max_val, rng, margin)\n",
    "    else:\n",
    "        pass\n",
    "    if ftr_imp_flag == 1:\n",
    "        feature_imp_split(loop_res['feature_imp'], 6, 4)\n",
    "    else:\n",
    "        pass\n",
    "    return loop_res_pred\n",
    "# Just display 2 df side by side\n",
    "def display_2df_side_side(df1, df2):\n",
    "    df_combined = pd.concat([df1, df2], axis=1)\n",
    "    display(HTML(df_combined.to_html(index=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetThicknessDistribution upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal_net2_kh = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\df_bal_net2_kh.csv').drop('Unnamed: 0', axis=1)\n",
    "df_dist_kh_bal_fin = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\df_dist_kh_bal_fin.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 3 offsets wells\n",
    "def display_3offset_wells(well, formation, dataset_dist=df_dist_kh_bal_fin, dataset_logs=df_bal_net2_kh):\n",
    "    \"\"\"\n",
    "    Pay attention dataset_dist=df_dist_kh_bal_fin, dataset_logs=df_bal_net2_kh\n",
    "    well:       just well name\n",
    "    formation:  just formation\n",
    "    \"\"\"\n",
    "    def well_offset_selection(dataset_dist, fmname, well_target):\n",
    "        try:\n",
    "            well_df = dataset_dist[(dataset_dist.well == well_target) & (dataset_dist.FORMATION_up == fmname)][['well', 'well1', 'well2', 'well3',\n",
    "                                                                                                                        'dist1', 'dist2', 'dist3',\n",
    "                                                                                                                'KHtst','KHtst_1', 'KHtst_2', 'KHtst_3']]\n",
    "            well1 = well_df['well1'].iloc[0]\n",
    "            well2 = well_df['well2'].iloc[0]\n",
    "            well3 = well_df['well3'].iloc[0]\n",
    "            dist1 = well_df['dist1'].astype('int').iloc[0]\n",
    "            dist2 = well_df['dist2'].astype('int').iloc[0]\n",
    "            dist3 = well_df['dist3'].astype('int').iloc[0]\n",
    "            kh = well_df['KHtst'].astype('int').iloc[0]\n",
    "            kh1 = well_df['KHtst_1'].astype('int').iloc[0]\n",
    "            kh2 = well_df['KHtst_2'].astype('int').iloc[0]\n",
    "            kh3 = well_df['KHtst_3'].astype('int').iloc[0]\n",
    "        except Exception as e:\n",
    "            print(f'It looks like the desired formation is absent. The error is \"{e}\"')\n",
    "        return {'target': well_target, 'w1':well1, 'w2':well2, 'w3':well3, \n",
    "                'dist': 0,'d1':dist1, 'd2':dist2,'d3':dist3,\n",
    "                'kh':kh,'kh1':kh1, 'kh2':kh2, 'kh3':kh3}\n",
    "    def display_tracks(dataset, wellname, fmname, ref_depth, depth_step, r, c, kh_value, dist):\n",
    "        try:\n",
    "            data = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "            depth = data[ref_depth]\n",
    "            grn = data['GR_N']\n",
    "            vsh = data['VSH']\n",
    "            rhob = data['RHOB'] \n",
    "            npss = data['NPSS']\n",
    "            rdeep = data['RDEEP']\n",
    "            phit = data['PHIT'] \n",
    "            net = data['NET_clp2']\n",
    "            perm = data['LPERM']\n",
    "            kh = data['KHtst']\n",
    "            well_bal_tops = df_bal[(df_bal.well == wellname)].groupby('FORMATION')[ref_depth].apply(lambda x: x.iloc[0]).reset_index()\n",
    "            ax[r,c].plot(grn, depth, color='lightgreen', lw=2, zorder=10)\n",
    "            ax[r,c].set_xlim(0, 150) \n",
    "            ax[r,c].grid(axis='y')\n",
    "            ax[r,c].invert_yaxis()\n",
    "            ax[r,c].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "            ax[r,c].set_xticks([])\n",
    "            ax[r,c].tick_params(axis='y', labelsize=8)\n",
    "            ax[r,c].set_title(wellname + ' ' + fmname + ' kh:' + str(kh_value) + ' dist:' + str(dist), fontsize=12) \n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "                ax[r,c].hlines(    well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                                    xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "                # ax[r,c].text(10, well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0]+0.5*depth_step, i, fontsize = 7, color =\"black\")\n",
    "            ax[r,c+1].plot(rhob, depth, color='red')\n",
    "            ax[r,c+1].xaxis.set_ticks(np.arange(1.65, 2.65, 0.3))\n",
    "            ax[r,c+1].set_xlim(1.65, 2.65)\n",
    "            ax[r,c+1].grid(axis='y')\n",
    "            ax[r,c+1].grid(axis='x')\n",
    "            ax[r,c+1].invert_yaxis()\n",
    "            ax[r,c+1].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "            ax[r,c+1].set_xticks([])\n",
    "            ax[r,c+1].set_yticks([])\n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "                ax[r,c+1].hlines( well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                                xmin=0, xmax=150, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "                ax[r,c+1].text(1.67, well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0]+0.5*depth_step, i, fontsize = 7, color =\"black\")\n",
    "            twin1 = ax[r,c+1].twiny()\n",
    "            twin1.plot(npss, depth, color='blue')\n",
    "            twin1.set_xlim(0.6, 0)\n",
    "            twin1.set_xticks([])\n",
    "            ax[r,c+2].plot(phit, depth, color='green', linestyle='dashed')\n",
    "            ax[r,c+2].set_xlim(0.3, 0)\n",
    "            ax[r,c+2].grid(axis='x')\n",
    "            ax[r,c+2].grid(axis='y')\n",
    "            ax[r,c+2].invert_yaxis()\n",
    "            ax[r,c+2].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "            ax[r,c+2].set_xticks([])\n",
    "            ax[r,c+2].set_yticks([])\n",
    "            ax[r,c+2].vlines(0.13, ymin=min(depth), ymax=max(depth), color='black', linestyle='dashed')\n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "                ax[r,c+2].hlines(    well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                                    xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "            twin2 = ax[r,c+2].twiny()\n",
    "            twin2.plot(net, depth, color='orange', linewidth=0.5)\n",
    "            twin2.fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "            twin2.set_xlim(0, 1)\n",
    "            twin2.set_xticks([])\n",
    "            ax[r,c+3].plot(perm, depth, color='purple', alpha=0.66)\n",
    "            ax[r,c+3].set_xscale('log')\n",
    "            ax[r,c+3].set_xlim(0.1, 1000)\n",
    "            ax[r,c+3].grid(axis='y')\n",
    "            ax[r,c+3].grid(axis='x')\n",
    "            ax[r,c+3].invert_yaxis()\n",
    "            ax[r,c+3].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "            ax[r,c+3].set_xticks([])\n",
    "            ax[r,c+3].set_yticks([])\n",
    "            for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "                ax[r,c+3].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.5)\n",
    "            twin4 = ax[r,c+3].twiny()\n",
    "            twin4.plot(kh, depth, color='black', alpha=1)\n",
    "            twin4.set_xticks([])\n",
    "        except Exception as e:\n",
    "            print(f'It looks like the desired formation is absent. The error is \"{e}\"')\n",
    "        return fig.show()\n",
    "    def display_subplots():\n",
    "        try:\n",
    "            well_dist_dict = well_offset_selection(dataset_dist, fmname, well_target)\n",
    "            display_tracks(dataset_logs, well_dist_dict['target'], fmname,'TST', 10, 0,0,well_dist_dict['kh'], well_dist_dict['dist'])\n",
    "            display_tracks(dataset_logs, well_dist_dict['w1'], fmname,'TST', 10 ,0,4, well_dist_dict['kh1'], well_dist_dict['d1'])  \n",
    "            display_tracks(dataset_logs, well_dist_dict['w2'], fmname,'TST', 10,1,0, well_dist_dict['kh2'], well_dist_dict['d2'])      \n",
    "            display_tracks(dataset_logs, well_dist_dict['w3'], fmname,'TST', 10,1,4, well_dist_dict['kh3'], well_dist_dict['d3'])\n",
    "        except Exception as e:\n",
    "            print(f'It looks like the desired formation is absent. The error is \"{e}\"')\n",
    "    well_target = well\n",
    "    fmname = formation\n",
    "    fig, ax = plt.subplots(2,8, figsize=(9,8), constrained_layout=True)\n",
    "    return display_subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps & 3D view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing maps of well trajectories\n",
    "def well_traj_dataprep(dataset):\n",
    "    map_data = dataset.dropna()\n",
    "    map_data_top = map_data.groupby(['well','FORMATION_up'])[['X_traj','Y_traj']].apply(lambda x: x.iloc[0:-100:100]).reset_index()\n",
    "    map_data_bot = map_data.groupby(['well','FORMATION_up'])[['X_traj','Y_traj']].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "    map_data_middle = map_data.groupby(['well','FORMATION_up'])[['X_mean', 'Y_mean', 'KHtst', 'TVD_SCS', 'Status']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "    map_trajectory_display = pd.concat([map_data_top, map_data_bot]).sort_values(by=['well','FORMATION_up']).drop('level_2', axis=1)\n",
    "    return map_trajectory_display, map_data_middle\n",
    "map_trajectory_display, map_data_middle = well_traj_dataprep(df_bal_net2_kh)\n",
    "\n",
    "bal8_1510 = pd.read_csv(r'C:\\jupyter\\SPP\\input\\surfaces\\petrel\\bal8_1510_base.csv', sep=' ', names=['X','Y','geobody'])\n",
    "def display_well_traj(trajectory, map_data_middle, petrel, fmname, mult, path, comment, print_flag):\n",
    "    trajectory = trajectory[trajectory.FORMATION_up == fmname]\n",
    "    map_data_middle = map_data_middle[map_data_middle.FORMATION_up == fmname]\n",
    "    map_data_middle['KHtst'] = map_data_middle['KHtst'].round(0)\n",
    "    traj = go.Scatter(  x=trajectory.X_traj, y=trajectory.Y_traj, \n",
    "                        mode='markers',\n",
    "                        marker=dict(color='black', size=1),\n",
    "                        customdata = trajectory[['well']],\n",
    "                        hovertemplate=\"\".join([\"well:%{customdata[0]}<extra></extra>\"])\n",
    "                        )\n",
    "    wells = go.Scatter( x=map_data_middle.X_mean, y=map_data_middle.Y_mean, \n",
    "                        mode='markers',\n",
    "                        # marker=dict(symbol='diamond', color='red', size=7, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                        marker=dict(color=map_data_middle.KHtst, size=map_data_middle.KHtst*mult, colorscale='RdYlGn',  showscale=True,\n",
    "                                    line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                        customdata = map_data_middle[['well', 'KHtst']],\n",
    "                        hovertemplate=\"\".join([\"well:%{customdata[0]},kh:%{customdata[1]}<extra></extra>\"]))\n",
    "    geobody_map = go.Scatter(   x=petrel['X'], y=petrel['Y'],\n",
    "                                mode='markers',\n",
    "                                marker=dict(size=5, color=petrel['geobody'],colorscale='Viridis', opacity=0.5))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(geobody_map)\n",
    "    fig.add_trace(traj)\n",
    "    fig.add_trace(wells)\n",
    "    fig.update_layout(  title_text= ('Map of traj and well mean points with'+ ' ' + fmname + ' 1510 polygons. Size of bubbles is KHtst.'),\n",
    "                        autosize=True, width=1000, height=700, margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "    if print_flag == 'print':\n",
    "        go_offline.plot(fig, filename=path + comment, validate=True, auto_open=False)\n",
    "    else:\n",
    "        pass\n",
    "    return fig.show()\n",
    "display_well_traj(map_trajectory_display, map_data_middle, bal8_1510, 'Balakhany VIII', 0.00125, 'plots/', 'Balakhany8_KHtst', 'dont_print')\n",
    "# display_well_traj(map_trajectory_display, map_data_middle, 'Balakhany X', 0.003, 'plots/', 'Balakhany10_KHtst', 'dont_print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_by_depth_fm(dataset_logs, formation_name, step):\n",
    "    def interpolate_by_depth(one_well, formation_name, step):\n",
    "        one_well = one_well.sort_values(by='TST')\n",
    "        well_name = one_well[\"well\"].iloc[0]\n",
    "        data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "        starting_tst = one_well[\"TST\"].iloc[0]\n",
    "        new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "        interp_X = interp1d(one_well['TST'], one_well['X_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Y = interp1d(one_well['TST'], one_well['Y_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_PHIT = interp1d(one_well['TST'], one_well['PHIT'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_TVD = interp1d(one_well['TST'], one_well['TVD_SCS'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_NET_clp2 = interp1d(one_well['TST'], one_well['NET_clp2'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_LPERM = interp1d(one_well['TST'], one_well['LPERM'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_KHtst = interp1d(one_well['TST'], one_well['KHtst'], kind='linear', fill_value=\"extrapolate\")\n",
    "        # Create a new DataFrame with the interpolated values for new TVD_SCS\n",
    "        new_data = {\n",
    "            'well': [well_name for _ in range(len(new_TST_values))],\n",
    "            'FORMATION_up': [formation_name for _ in range(len(new_TST_values))],\n",
    "            'tst_index': [_ for _ in range(len(new_TST_values))],\n",
    "            'TST': new_TST_values,\n",
    "            'X_traj': interp_X(new_TST_values),\n",
    "            'Y_traj': interp_Y(new_TST_values),\n",
    "            'PHIT': interp_PHIT(new_TST_values),\n",
    "            'TVD_SCS': interp_TVD(new_TST_values),\n",
    "            'NET_clp2': interp_NET_clp2(new_TST_values),\n",
    "            'LPERM': interp_LPERM(new_TST_values),\n",
    "            'KHtst': interp_KHtst(new_TST_values),\n",
    "        }\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        return new_df\n",
    "    df_lst = []\n",
    "    print(f'Start interpolation of {formation_name}')\n",
    "    for wellnames in tqdm(dataset_logs.well.unique()):\n",
    "        well_sel = dataset_logs[dataset_logs.well == wellnames]\n",
    "        well_interp = interpolate_by_depth(well_sel, formation_name, step)\n",
    "        df_lst.append(well_interp)\n",
    "    result = pd.concat(df_lst)\n",
    "    return result\n",
    "well_bal8 = df_bal_net2_kh[(df_bal_net2_kh.FORMATION_up == 'Balakhany VIII')]\n",
    "well_bal10 = df_bal_net2_kh[(df_bal_net2_kh.FORMATION_up == 'Balakhany X')]\n",
    "well_bal8_interp = interpolate_by_depth_fm(well_bal8, 'Balakhany VIII', 0.1)\n",
    "well_bal10_interp = interpolate_by_depth_fm(well_bal10, 'Balakhany X', 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHIT_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_bal8_interp_rn = well_bal8_interp.rename(columns={'PHIT':'PHIT_orig'})\n",
    "well_bal10_interp_rn = well_bal10_interp.rename(columns={'PHIT':'PHIT_orig'})\n",
    "\n",
    "def phit_rolling_averaging(input_dataset, samples_per_window):\n",
    "    df_lst = []\n",
    "    avg_report = []\n",
    "    fmname = input_dataset['FORMATION_up'].iloc[0] \n",
    "    print(f'Start rolling averaging of {fmname}')\n",
    "    for wellname in tqdm(input_dataset.well.unique()):\n",
    "        dataset = input_dataset[input_dataset.well == wellname]\n",
    "        window_size = int(len(dataset) / samples_per_window)\n",
    "        dataset['PHIT'] = dataset['PHIT_orig'].rolling(window=window_size, center=True).mean()\n",
    "        dataset =  dataset.dropna(subset=['PHIT'])\n",
    "        df_lst.append(dataset)\n",
    "        avg_report.append((wellname, len(dataset), window_size, samples_per_window))\n",
    "    result = pd.concat(df_lst)\n",
    "    avg_report_df = pd.DataFrame(avg_report, columns=['well','lenght_ds','window_size','samples_per_window'])\n",
    "    return result, avg_report_df\n",
    "samples_per_window = 100\n",
    "well_bal8_interp_phavg, avg_report_df8 = phit_rolling_averaging(well_bal8_interp_rn, samples_per_window)\n",
    "well_bal10_interp_phavg, avg_report_df10 = phit_rolling_averaging(well_bal10_interp_rn, samples_per_window)\n",
    "well_bal8_interp_phavg['PHIT_clp'] = well_bal8_interp_phavg['PHIT']\n",
    "well_bal10_interp_phavg['PHIT_clp'] = well_bal10_interp_phavg['PHIT']\n",
    "well_bal8_interp_phavg['LPERM_clp'] = well_bal8_interp_phavg['LPERM']\n",
    "well_bal10_interp_phavg['LPERM_clp'] = well_bal10_interp_phavg['LPERM']\n",
    "well_bal8_interp_phavg.loc[well_bal8_interp_phavg.NET_clp2 == 0, 'PHIT_clp'] = 0.12\n",
    "well_bal10_interp_phavg.loc[well_bal10_interp_phavg.NET_clp2 == 0, 'PHIT_clp'] = 0.12\n",
    "well_bal8_interp_phavg.loc[well_bal8_interp_phavg.NET_clp2 == 0, 'LPERM_clp'] = 0.1\n",
    "well_bal10_interp_phavg.loc[well_bal10_interp_phavg.NET_clp2 == 0, 'LPERM_clp'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting_block_lenght(dataset, block_lenght):\n",
    "    df_lst = []\n",
    "    fmname = dataset['FORMATION_up'].iloc[0]\n",
    "    print(f'Start processing of dataset for {fmname} with block lenght {block_lenght}')\n",
    "    for wellname in tqdm(dataset.well.unique()):\n",
    "        data = dataset[dataset.well == wellname]\n",
    "        tst_index_repaired = [i for i in range(0, len(data))]\n",
    "        data['tst_index'] = tst_index_repaired\n",
    "        new_index = [i for i in range(0, len(data), block_lenght)]\n",
    "        data_cut = data[(data.tst_index < new_index[-1])]\n",
    "        df_lst.append(data_cut)\n",
    "    result = pd.concat(df_lst)\n",
    "    return result\n",
    "block_lenght = 100\n",
    "well_bal8_interp_phavg_cut = cutting_block_lenght(well_bal8_interp_phavg, block_lenght)\n",
    "well_bal10_interp_phavg_cut = cutting_block_lenght(well_bal10_interp_phavg, block_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exercise_phit_avg_kh(dataset, wellname):\n",
    "    well_a01w = dataset[(dataset.well==wellname) & (dataset.FORMATION_up=='Balakhany VIII')]\n",
    "\n",
    "    well_a01w['PHIT_clipped'] = well_a01w['PHIT']\n",
    "    well_a01w.loc[well_a01w.NET_clp2 == 0, 'PHIT_clipped'] = 0\n",
    "    well_a01w['LPERM_avg'] = 0.00000002*(np.exp(well_a01w.PHIT*105.56))\n",
    "    well_a01w.loc[well_a01w['PHIT'] >= 0.2, 'LPERM_avg'] = (7.7925*((well_a01w.PHIT*100)**2))-(29881.0*well_a01w.PHIT)+2891.8\n",
    "    well_a01w.loc[well_a01w['PHIT'] < 0.16, 'LPERM_avg'] = 0.0159*(np.exp(well_a01w.PHIT*21.27))\n",
    "    well_a01w['khtst'] = well_a01w.LPERM_avg*0.1\n",
    "    well_a01w['KHtst_avg'] = well_a01w.loc[::-1, 'khtst'].cumsum()[::-1]\n",
    "\n",
    "    y = well_a01w.TST\n",
    "    phit_orig = well_a01w.PHIT_orig\n",
    "    phit_avg = well_a01w.PHIT\n",
    "    phit_cliped = well_a01w.PHIT_clipped\n",
    "    net = well_a01w.NET_clp2\n",
    "    perm = well_a01w.LPERM\n",
    "    perm_avg = well_a01w.LPERM_avg\n",
    "    kh = well_a01w.KHtst\n",
    "    kh_avg = well_a01w.KHtst_avg\n",
    "    print(  'KH orig:', kh.iloc[0].round(0), \n",
    "            'KH avg:',kh_avg.iloc[0].round(0), \n",
    "            'KHavg/KHorig:',((kh.iloc[0].round(0)-kh_avg.iloc[0].round(0))/kh.iloc[0].round(0)).round(2))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(6, 7))\n",
    "    ax[0].plot(phit_orig, y, color='green')\n",
    "    ax[0].plot(phit_avg, y, color='red')\n",
    "    ax[0].set_xlim(0, 0.3)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title(wellname)\n",
    "    ax[1].plot(phit_cliped, y, color='red', zorder=1)\n",
    "    ax[1].plot(net, y, color='orange', zorder=0)\n",
    "    ax[1].set_xlim(0, 0.3)\n",
    "    ax[1].invert_yaxis()\n",
    "    ax[2].plot(perm, y, color='purple', lw=3)\n",
    "    ax[2].plot(perm_avg, y, color='yellow')\n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].set_xscale('log')\n",
    "    ax[3].plot(kh, y, color='black')\n",
    "    ax[3].plot(kh_avg, y, color='gray')\n",
    "    ax[3].invert_yaxis()\n",
    "    fig.show()\n",
    "exercise_phit_avg_kh(well_bal8_interp_phavg_cut, 'A01W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  PHIT & GRcube - martix plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_cube_upload():\n",
    "    path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "    vsh_cube_log = pd.read_parquet(path + 'ACG_GRcube_VSH_v3.parquet.gzip')\n",
    "    vsh_cube_log = vsh_cube_log.replace(-9999.000, np.nan)\n",
    "    vsh_cube_log = vsh_cube_log.dropna()\n",
    "    vsh_cube_log.loc[vsh_cube_log.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "    vsh_cube_log.loc[vsh_cube_log.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "    vsh_cube_log = vsh_cube_log[vsh_cube_log.FORMATION_up.isin(['Balakhany VIII', 'Balakhany X'])]\n",
    "    vsh_grcube = vsh_cube_log[['wellName', 'DEPT','VSH_GRcube', 'FORMATION_up']]\n",
    "    vsh_grcube = vsh_grcube.rename(columns={'wellName':'well', 'DEPT':'MD'})\n",
    "    return vsh_grcube\n",
    "vsh_grcube = gr_cube_upload()\n",
    "df_bal_net2_kh['MD'] = df_bal_net2_kh.MD.round(1)\n",
    "df_bal_net2_kh_cube = df_bal_net2_kh.set_index(['well','MD', 'FORMATION_up']).join(vsh_grcube.set_index(['well','MD', 'FORMATION_up'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsh_gr_cube_recalc(dataset):\n",
    "    def interpolate_by_depth_fm(dataset_logs, formation_name, step):\n",
    "        def interpolate_by_depth(one_well, formation_name, step):\n",
    "            one_well = one_well.sort_values(by='TST')\n",
    "            well_name = one_well[\"well\"].iloc[0]\n",
    "            data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "            starting_tst = one_well[\"TST\"].iloc[0]\n",
    "            new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "            interp_X = interp1d(one_well['TST'], one_well['X_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_Y = interp1d(one_well['TST'], one_well['Y_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_PHIT = interp1d(one_well['TST'], one_well['PHIT'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_TVD = interp1d(one_well['TST'], one_well['TVD_SCS'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_NET_clp2 = interp1d(one_well['TST'], one_well['NET_clp2'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_LPERM = interp1d(one_well['TST'], one_well['LPERM'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_KHtst = interp1d(one_well['TST'], one_well['KHtst'], kind='linear', fill_value=\"extrapolate\")\n",
    "            interp_VSH_GRcube = interp1d(one_well['TST'], one_well['VSH_GRcube'], kind='linear', fill_value=\"extrapolate\")\n",
    "            # Create a new DataFrame with the interpolated values for new TVD_SCS\n",
    "            new_data = {\n",
    "                'well': [well_name for _ in range(len(new_TST_values))],\n",
    "                'FORMATION_up': [formation_name for _ in range(len(new_TST_values))],\n",
    "                'tst_index': [_ for _ in range(len(new_TST_values))],\n",
    "                'TST': new_TST_values,\n",
    "                'X_traj': interp_X(new_TST_values),\n",
    "                'Y_traj': interp_Y(new_TST_values),\n",
    "                'PHIT': interp_PHIT(new_TST_values),\n",
    "                'TVD_SCS': interp_TVD(new_TST_values),\n",
    "                'NET_clp2': interp_NET_clp2(new_TST_values),\n",
    "                'LPERM': interp_LPERM(new_TST_values),\n",
    "                'KHtst': interp_KHtst(new_TST_values),\n",
    "                'VSH_GRcube':interp_VSH_GRcube(new_TST_values)\n",
    "            }\n",
    "            new_df = pd.DataFrame(new_data)\n",
    "            return new_df\n",
    "        df_lst = []\n",
    "        print(f'Start interpolation of {formation_name}')\n",
    "        for wellnames in tqdm(dataset_logs.well.unique()):\n",
    "            well_sel = dataset_logs[dataset_logs.well == wellnames]\n",
    "            well_interp = interpolate_by_depth(well_sel, formation_name, step)\n",
    "            df_lst.append(well_interp)\n",
    "        result = pd.concat(df_lst)\n",
    "        return result\n",
    "    well_bal8 = dataset[(dataset.FORMATION_up == 'Balakhany VIII')]\n",
    "    well_bal10 = dataset[(dataset.FORMATION_up == 'Balakhany X')]\n",
    "    well_bal8_interp = interpolate_by_depth_fm(well_bal8, 'Balakhany VIII', 0.1)\n",
    "    well_bal10_interp = interpolate_by_depth_fm(well_bal10, 'Balakhany X', 0.1)\n",
    "    well_bal8_interp_rn = well_bal8_interp.rename(columns={'PHIT':'PHIT_orig'})\n",
    "    well_bal10_interp_rn = well_bal10_interp.rename(columns={'PHIT':'PHIT_orig'})\n",
    "\n",
    "    def phit_rolling_averaging(input_dataset, samples_per_window):\n",
    "        df_lst = []\n",
    "        avg_report = []\n",
    "        fmname = input_dataset['FORMATION_up'].iloc[0] \n",
    "        print(f'Start rolling averaging of {fmname}')\n",
    "        for wellname in tqdm(input_dataset.well.unique()):\n",
    "            dataset = input_dataset[input_dataset.well == wellname]\n",
    "            window_size = int(len(dataset) / samples_per_window)\n",
    "            dataset['PHIT'] = dataset['PHIT_orig'].rolling(window=window_size, center=True).mean()\n",
    "            dataset =  dataset.dropna(subset=['PHIT'])\n",
    "            df_lst.append(dataset)\n",
    "            avg_report.append((wellname, len(dataset), window_size, samples_per_window))\n",
    "        result = pd.concat(df_lst)\n",
    "        avg_report_df = pd.DataFrame(avg_report, columns=['well','lenght_ds','window_size','samples_per_window'])\n",
    "        return result, avg_report_df\n",
    "    samples_per_window = 100\n",
    "    well_bal8_interp_phavg, avg_report_df8 = phit_rolling_averaging(well_bal8_interp_rn, samples_per_window)\n",
    "    well_bal10_interp_phavg, avg_report_df10 = phit_rolling_averaging(well_bal10_interp_rn, samples_per_window)\n",
    "    well_bal8_interp_phavg['PHIT_clp'] = well_bal8_interp_phavg['PHIT']\n",
    "    well_bal10_interp_phavg['PHIT_clp'] = well_bal10_interp_phavg['PHIT']\n",
    "    well_bal8_interp_phavg['LPERM_clp'] = well_bal8_interp_phavg['LPERM']\n",
    "    well_bal10_interp_phavg['LPERM_clp'] = well_bal10_interp_phavg['LPERM']\n",
    "    well_bal8_interp_phavg.loc[well_bal8_interp_phavg.NET_clp2 == 0, 'PHIT_clp'] = 0.12\n",
    "    well_bal10_interp_phavg.loc[well_bal10_interp_phavg.NET_clp2 == 0, 'PHIT_clp'] = 0.12\n",
    "    well_bal8_interp_phavg.loc[well_bal8_interp_phavg.NET_clp2 == 0, 'LPERM_clp'] = 0.1\n",
    "    well_bal10_interp_phavg.loc[well_bal10_interp_phavg.NET_clp2 == 0, 'LPERM_clp'] = 0.1\n",
    "    return well_bal8_interp_phavg, well_bal10_interp_phavg\n",
    "well_bal8_interp_phavg, well_bal10_interp_phavg = vsh_gr_cube_recalc(df_bal_net2_kh_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_letter_def(dataset):\n",
    "    wells_letter = [wellname[0] for wellname in dataset.well.unique()]\n",
    "    return set(wells_letter)\n",
    "well_letter_def(well_bal8_interp_phavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_plots_phit_vsh_matrix(dataset, platform, variable, flag, max_var, comment):\n",
    "    \"\"\"\n",
    "    flag = 'phit' or 'perm'\n",
    "    \"\"\"\n",
    "    rows = 4\n",
    "    columns = 9\n",
    "    wells_letter = [wellname for wellname in dataset.well.unique() if wellname.startswith(platform)]\n",
    "    fig, ax = plt.subplots(rows,columns, figsize=(16,rows*3))\n",
    "    counter = 0\n",
    "    y_real_list = []\n",
    "    for j in range(0, rows):\n",
    "        for i in range(0, columns):\n",
    "            if counter < len(wells_letter):\n",
    "                data = dataset[dataset.well==wells_letter[counter]]\n",
    "                y_real_list.append(len(data))\n",
    "                counter +=1\n",
    "    max_ind = max(y_real_list)\n",
    "    counter = 0\n",
    "    for j in range(0, rows):\n",
    "        for i in range(0, columns):\n",
    "            if counter < len(wells_letter):\n",
    "                well_data = dataset[dataset.well==wells_letter[counter]]\n",
    "                ind = well_data[variable]\n",
    "                y_real = [k for k in range(len(ind))]\n",
    "                y_desired = [k for k in range(max_ind)]\n",
    "                y_diff = len(y_desired) - len(y_real)\n",
    "                values_to_add = [0.12 for k in range(y_diff)]\n",
    "                x = well_data[variable]\n",
    "                x_gr = well_data['VSH_GRcube']\n",
    "                x_new = pd.concat([x, pd.Series(values_to_add)])\n",
    "                x_gr_new = pd.concat([x_gr, pd.Series(values_to_add)])          \n",
    "                if flag == 'phit':\n",
    "                    ax[j,i].plot(x_new, y_desired, color='green', lw=1.5, alpha=1, zorder=1)\n",
    "                    ax[j,i].set_xlim(0.1, 0.35)\n",
    "                    # twin = ax[j,i].twiny()\n",
    "                    # twin.plot(x_gr_new, y_desired, color='green', lw=2, alpha=0.5, zorder=0)\n",
    "                    # twin.set_xlim(0, 1)\n",
    "                if flag == 'perm':\n",
    "                    ax[j,i].plot(x_new, y_desired, color='purple', lw=2, alpha=0.75)\n",
    "                    ax[j,i].set_xscale('log')\n",
    "                    ax[j,i].set_xlim(0.1, max_var)\n",
    "                ax[j,i].set_title(wells_letter[counter] + comment)\n",
    "                ax[j,i].invert_yaxis()\n",
    "                ax[j,i].grid()\n",
    "                counter +=1\n",
    "\n",
    "    return plt.tight_layout()\n",
    "# for letter in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J']:\n",
    "for letter in ['A','B']:\n",
    "    well_plots_phit_vsh_matrix(well_bal8_interp_phavg, letter, 'PHIT_clp', 'phit', 0.35, ' bal8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering top_phi_bot layering v2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_data_calculation(dataset):\n",
    "    df_net2_bal8 = dataset[[    'well', 'MD', 'TST', 'TVD_SCS','NET_clp2', 'FORMATION_up', 'FORMATION', \n",
    "                                'LPERM', 'PHIT', 'VSH', 'KHtst','PHITHtst', 'VSHHtst', 'X_mean','Y_mean','field']]\n",
    "    df_net2_bal8 = df_net2_bal8[df_net2_bal8.FORMATION_up=='Balakhany VIII']\n",
    "    df_net2_bal10 = dataset[[   'well', 'MD', 'TST', 'TVD_SCS','NET_clp2', 'FORMATION_up', 'FORMATION', \n",
    "                                'LPERM', 'PHIT', 'VSH', 'KHtst','PHITHtst','VSHHtst', 'X_mean','Y_mean','field']]\n",
    "    df_net2_bal10 = df_net2_bal10[df_net2_bal10.FORMATION_up=='Balakhany X']\n",
    "    # Calculation NTD for Bal8 and Bal10 based on NET_clp2\n",
    "    print('Calculation NTD for Bal8 and Bal10 based on NET_clp2')\n",
    "    def ntd_calculation_brief(dataset,well,desired_fm, net_var):\n",
    "        data = dataset[(dataset.well==well) & (dataset.FORMATION_up==desired_fm)]\n",
    "        data.iloc[0, 3] = 0\n",
    "        data.iloc[-1, 3] = 0\n",
    "        tst_top = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i-1][net_var]==0)]\n",
    "        tst_bot = [data.iloc[i]['TST'] for i in range(len(data)-1)\n",
    "                    if (data.iloc[i][net_var] == 1 and data.iloc[i+1][net_var]==0)]\n",
    "        tops = zip(tst_top, tst_bot)\n",
    "        df_htst = pd.DataFrame(tops, columns=['tst_top', 'tst_bot'])\n",
    "        df_htst['FORMATION_up'] = desired_fm\n",
    "        df_htst['well'] = well\n",
    "        df_htst['h_tst'] = df_htst.tst_bot - df_htst.tst_top\n",
    "        df_htst = df_htst[['well','FORMATION_up','tst_top','tst_bot','h_tst']]\n",
    "        return df_htst\n",
    "    df_recalc_list8 = []\n",
    "    for well in tqdm(df_net2_bal8.well.unique()):\n",
    "        df = ntd_calculation_brief(df_net2_bal8, well, 'Balakhany VIII', 'NET_clp2')\n",
    "        df_recalc_list8.append(df)\n",
    "    ntd_net2_8 = pd.concat(df_recalc_list8)\n",
    "    ntd_net2_8.drop_duplicates(inplace=True)\n",
    "    df_recalc_list10 = []\n",
    "    for well in tqdm(df_net2_bal10.well.unique()):\n",
    "        df = ntd_calculation_brief(df_net2_bal10, well, 'Balakhany X', 'NET_clp2')\n",
    "        df_recalc_list10.append(df)\n",
    "    ntd_net2_10 = pd.concat(df_recalc_list10)\n",
    "    ntd_net2_10.drop_duplicates(inplace=True)\n",
    "\n",
    "    print('Calculation values for NTD Bal8 and Bal10')\n",
    "    def ntd_properties_dataframe(dataset_ntd, dataset_logs, fmname):\n",
    "        well_data = []\n",
    "        well_formation = fmname\n",
    "        df_lst = []\n",
    "        for well in tqdm(dataset_ntd.well.unique()[:]):\n",
    "            ntd_well_avgprop = dataset_ntd[(dataset_ntd.well ==well)]\n",
    "            well_avgprop_sel = dataset_logs[(dataset_logs.well==well)]\n",
    "            fm_top = dataset_logs[(dataset_logs.well==well)]['TST'].iloc[0]\n",
    "            fm_bot = dataset_logs[(dataset_logs.well==well)]['TST'].iloc[-1]\n",
    "            well_phit = []\n",
    "            well_vsh = []\n",
    "            well_gperm = []\n",
    "            well_top = []\n",
    "            well_bot = []\n",
    "            well_h = []\n",
    "            well_fm_top = []\n",
    "            well_fm_bot = []\n",
    "            well_name = []\n",
    "            well_fm = []\n",
    "            well_khtst = []\n",
    "            for layers in range(len(ntd_well_avgprop.well)):\n",
    "                ntd_top = ntd_well_avgprop.iloc[layers, 2].round(3)\n",
    "                ntd_bot = ntd_well_avgprop.iloc[layers, 3].round(3)\n",
    "                ntd_h = ntd_well_avgprop.iloc[layers, 4].round(3)\n",
    "                phit_lst = []\n",
    "                vsh_lst = []\n",
    "                perm_lst = []\n",
    "                khtst_lst = []\n",
    "                for depth in range(len(well_avgprop_sel.TST)):\n",
    "                    well_avgprop_tst = well_avgprop_sel['TST'].iloc[depth].round(3)\n",
    "                    if well_avgprop_tst >= ntd_top and well_avgprop_tst <= ntd_bot:\n",
    "                        phit_lst.append(well_avgprop_sel['PHIT'].iloc[depth])\n",
    "                        vsh_lst.append(well_avgprop_sel['VSH'].iloc[depth])\n",
    "                        perm_lst.append(well_avgprop_sel['LPERM'].iloc[depth])\n",
    "                        khtst_lst.append(well_avgprop_sel['KHtst'].iloc[depth])\n",
    "                well_name.append(well)\n",
    "                well_fm.append(well_formation)\n",
    "                well_phit.append(mean(phit_lst))\n",
    "                well_vsh.append(mean(vsh_lst))\n",
    "                well_gperm.append(gmean(perm_lst))\n",
    "                well_khtst.append(khtst_lst[0] - khtst_lst[-1])\n",
    "                well_h.append(ntd_h)\n",
    "                well_top.append(ntd_top)\n",
    "                well_bot.append(ntd_bot)\n",
    "                well_fm_top.append(fm_top)\n",
    "                well_fm_bot.append(fm_bot)\n",
    "                well_data = zip(well_name,well_fm,well_phit, well_vsh, well_gperm, well_khtst, well_h, well_top, well_bot, well_fm_top, well_fm_bot)\n",
    "                well_df = pd.DataFrame(well_data, columns=[ 'well','FORMATION_up',        \n",
    "                                                            'phit_avg',\n",
    "                                                            'vsh_avg', \n",
    "                                                            'perm_avg',\n",
    "                                                            'khtst',\n",
    "                                                            'htst',\n",
    "                                                            'top_tst',\n",
    "                                                            'bot_tst',\n",
    "                                                            'fm_top_tst',\n",
    "                                                            'fm_bot_tst'])\n",
    "                well_df['not_htst'] = well_df['top_tst'].shift(-1)-well_df['bot_tst']\n",
    "                well_df = well_df[['well', 'FORMATION_up', 'phit_avg', 'vsh_avg', 'perm_avg', 'khtst','htst', 'not_htst','top_tst', 'bot_tst', 'fm_top_tst', 'fm_bot_tst']]\n",
    "            df_lst.append(well_df)\n",
    "        result = pd.concat(df_lst)\n",
    "        return result\n",
    "    ntd_val_bal8 = ntd_properties_dataframe(ntd_net2_8, df_net2_bal8, 'Balakhany VIII')\n",
    "    ntd_val_bal10 = ntd_properties_dataframe(ntd_net2_10, df_net2_bal10, 'Balakhany X')\n",
    "    ntd_val_final = pd.concat([ntd_val_bal8, ntd_val_bal10])\n",
    "    return ntd_val_final\n",
    "ntd_val_final = clustering_data_calculation(df_bal_net2_kh)\n",
    "ntd_val_final8 = ntd_val_final[ntd_val_final.FORMATION_up == 'Balakhany VIII']\n",
    "ntd_val_final10 = ntd_val_final[ntd_val_final.FORMATION_up == 'Balakhany X']\n",
    "\n",
    "def nothtst_nan_fill(dataset_ntd, fmname):\n",
    "    def nan_change_diff_fmbottom(dataset, wellname, fmname):\n",
    "        row_change = dataset[(dataset.well == wellname) & (dataset.FORMATION_up == fmname) & (dataset.not_htst.isna())]\n",
    "        row_change['not_htst'] = row_change['fm_bot_tst'] - row_change['bot_tst']\n",
    "        return row_change\n",
    "    df_list = []\n",
    "    for wellname in dataset_ntd.well.unique():\n",
    "        df = nan_change_diff_fmbottom(dataset_ntd, wellname, fmname)\n",
    "        df_list.append(df)\n",
    "    res_df_list = pd.concat(df_list)\n",
    "    result = pd.concat([dataset_ntd, res_df_list])\n",
    "    result = result.sort_values(by=['well','top_tst'])\n",
    "    result_final = result.dropna(subset=['not_htst'], axis=0)\n",
    "    return result_final\n",
    "ntd_val_final8_clean = nothtst_nan_fill(ntd_val_final8, 'Balakhany VIII')\n",
    "ntd_val_final10_clean = nothtst_nan_fill(ntd_val_final10, 'Balakhany X')\n",
    "\n",
    "def top_phit_bot_clustering(dataset):\n",
    "    print('Top & bot calculation')\n",
    "    def top_phit_bot_collection_run(dataset):\n",
    "        def top_phit_bot_collection(dataset, wellname):\n",
    "            data = dataset[dataset.well == wellname]\n",
    "            data['top_htst'] = data['top_tst'] - data['fm_top_tst']\n",
    "            data['top_htst'].iloc[1:] = data['not_htst'].iloc[:-1]\n",
    "            data['bot_htst'] = data['not_htst']\n",
    "            data = data[['well', 'FORMATION_up', 'phit_avg', 'vsh_avg', 'khtst',\n",
    "                         'top_htst','htst','bot_htst', 'fm_top_tst', 'fm_bot_tst']]\n",
    "            return data\n",
    "        df_lst = []\n",
    "        for wellname in tqdm(dataset.well.unique()):\n",
    "            res_df = top_phit_bot_collection(dataset, wellname)\n",
    "            df_lst.append(res_df)\n",
    "        top_phi_bot_cluster = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return top_phi_bot_cluster\n",
    "    top_phi_bot_cluster = top_phit_bot_collection_run(dataset)\n",
    "\n",
    "    def top_phit_bot_ntg_run(dataset):\n",
    "        def top_phit_bot_ntg(dataset, wellname):\n",
    "            ntg = []\n",
    "            data = dataset[dataset.well == wellname].reset_index(drop=True)\n",
    "            for ind, row in data.iterrows():\n",
    "                if ind == 0:\n",
    "                    ntg.append(row['htst']/(row['bot_htst'] + row['htst']))\n",
    "                if ind != 0:\n",
    "                    ntg.append(row['htst']/(row['bot_htst'] + row['htst'] + row['top_htst']))\n",
    "                if ind == len(data):\n",
    "                    ntg.append(row['htst']/(row['top_htst'] + row['htst']))\n",
    "            result = pd.concat([data, pd.DataFrame({'ntg':ntg})], axis=1)\n",
    "            return result\n",
    "        df_lst = []\n",
    "        for wellname in dataset.well.unique():\n",
    "            df = top_phit_bot_ntg(dataset, wellname)\n",
    "            df_lst.append(df)\n",
    "        top_phi_bot_cluster_ntg = pd.concat(df_lst).reset_index(drop=True)\n",
    "        return top_phi_bot_cluster_ntg\n",
    "    top_phi_bot_cluster_ntg = top_phit_bot_ntg_run(top_phi_bot_cluster)\n",
    "    \n",
    "    return top_phi_bot_cluster_ntg\n",
    "top_phi_bot_cluster8 = top_phit_bot_clustering(ntd_val_final8_clean)\n",
    "top_phi_bot_cluster10 = top_phit_bot_clustering(ntd_val_final10_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clustering(dataset, feature_list, scaler, cluster_num):\n",
    "    \"\"\"\n",
    "    MinMaxScaler(), StandardScaler()\n",
    "    \"\"\"\n",
    "    data = dataset[feature_list]\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=cluster_num, random_state=42)\n",
    "    kmeans_labels = kmeans.fit_predict(normalized_data)\n",
    "    kmeans_labels = pd.DataFrame(kmeans_labels, columns=['kmeans'])\n",
    "\n",
    "    gmm = GaussianMixture(n_components=cluster_num, random_state=42)\n",
    "    gmm.fit(normalized_data)\n",
    "    gmm_labels = gmm.predict(normalized_data)\n",
    "    gmm_labels = pd.DataFrame(gmm_labels, columns=['gmm'])\n",
    "\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=cluster_num)\n",
    "    agglomerative_labels = agglomerative.fit_predict(normalized_data)\n",
    "    agglomerative_labels = pd.DataFrame(agglomerative_labels, columns=['agglomer'])\n",
    "    result = pd.concat([top_phi_bot_cluster8, kmeans_labels, gmm_labels, agglomerative_labels], axis=1)\n",
    "    return result\n",
    "data_clustered8 = data_clustering(top_phi_bot_cluster8, ['phit_avg', 'htst'], StandardScaler(), 3)\n",
    "data_clustered8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_clustering(dataset, clustering, comment):\n",
    "    data = dataset[dataset.phit_avg !=0]\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "    custom_palette = {2: 'red', 1: 'green', 0: 'blue'}\n",
    "    sns.histplot(data=data, x='phit_avg', hue=clustering, ax=ax[0], kde=True,  palette=custom_palette)\n",
    "    ax[0].grid(True, axis='x'), ax[0].set_xticks(np.arange(0.12, 0.32, 0.02)), ax[0].tick_params(axis='both', which='major', labelsize=8)\n",
    "    sns.histplot(data=data[data.htst < 30], x='htst', hue=clustering, ax=ax[1], kde=True,  palette=custom_palette)\n",
    "    ax[1].grid(True, axis='x'), ax[1].set_xticks(np.arange(0, 30, 3)), ax[1].tick_params(axis='both', which='major', labelsize=8)\n",
    "    sns.histplot(data=data, x='ntg', hue=clustering, ax=ax[2], kde=True,  palette=custom_palette)\n",
    "    ax[2].grid(True, axis='x'), ax[2].set_xticks(np.arange(0, 1, 0.1)), ax[2].tick_params(axis='both', which='major', labelsize=8)\n",
    "    sns.histplot(data=data, x='vsh_avg', hue=clustering, ax=ax[3], kde=True,  palette=custom_palette)\n",
    "    ax[3].grid(True, axis='x'), ax[3].set_xticks(np.arange(0, 0.6, 0.1)), ax[3].tick_params(axis='both', which='major', labelsize=8)\n",
    "    fig.suptitle(comment)\n",
    "histo_clustering(data_clustered8, 'kmeans', 'Kmeans Bal VIII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_collecting_clusters_top_phi_bot_v2(dataset, clustering, fm):\n",
    "    df_lst = []\n",
    "    for wellname in dataset.well.unique()[:]:\n",
    "        data = dataset[dataset.well == wellname]\n",
    "        well_lst = []\n",
    "        phit_lst = []\n",
    "        htst_lst = []\n",
    "        bot_lst = []\n",
    "        ntg_lst = []\n",
    "        vsh_lst = []\n",
    "        cluster_lst = []\n",
    "        for ind, row in data.iterrows():\n",
    "            well_lst.append(wellname)\n",
    "            well_lst.append(wellname)\n",
    "\n",
    "            phit_lst.append(0)\n",
    "            phit_lst.append(row['phit_avg'])\n",
    "\n",
    "            cluster_lst.append(np.nan)\n",
    "            cluster_lst.append(row[clustering])\n",
    "\n",
    "            htst_lst.append(row['top_htst'])\n",
    "            htst_lst.append(row['htst'])\n",
    "            \n",
    "            bot_lst.append(row['bot_htst'])\n",
    "\n",
    "            ntg_lst.append(0)\n",
    "            ntg_lst.append(row['ntg'])\n",
    "\n",
    "            vsh_lst.append(0)\n",
    "            vsh_lst.append(row['vsh_avg'])\n",
    "\n",
    "        phit_lst.append(0)\n",
    "        cluster_lst.append(np.nan)\n",
    "        htst_lst.append(data['bot_htst'].iloc[-1])\n",
    "        well_lst.append(wellname)\n",
    "        well_collect_cluster_short = pd.DataFrame(zip(well_lst, phit_lst, htst_lst, ntg_lst, vsh_lst, cluster_lst ), columns=[  'well','phit', 'htst', \n",
    "                                                                                                                                'ntg', 'vsh', 'cluster'])\n",
    "        well_last_row = pd.DataFrame({'well':[well_lst[-1]], 'phit':[0], 'htst': [bot_lst[-1]], 'ntg':[0], 'vsh':[0], 'cluster':[cluster_lst[-1]]})\n",
    "        well_collect_cluster = pd.concat([well_collect_cluster_short, well_last_row]).reset_index(drop=True)\n",
    "        well_collect_cluster['depth'] = well_collect_cluster['htst'].cumsum()\n",
    "        df_lst.append(well_collect_cluster)\n",
    "    result = pd.concat(df_lst)\n",
    "    result['FORMATION_up'] = fm\n",
    "    return result\n",
    "tpb8_kmeans_v3 = well_collecting_clusters_top_phi_bot_v2(data_clustered8, 'kmeans', 'Balakhany VIII')\n",
    "\n",
    "def coloring_clusters_matrix_tpb3(dataset, letters_list, rows, columns, clustering, output_flag):\n",
    "    \"\"\"\n",
    "    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J']\n",
    "    \"\"\"\n",
    "    def clusters_rectangle(data, k, color):\n",
    "        # cluster_xy = data['depth'].iloc[k-2]\n",
    "        cluster_xy = data['depth'].iloc[k-1]\n",
    "        # cluster_h = data['depth'].iloc[k+1] - data['depth'].iloc[k-2]\n",
    "        cluster_h = data['depth'].iloc[k] - data['depth'].iloc[k-1]\n",
    "        rectangle = patches.Rectangle((0, cluster_xy) , 1, cluster_h, edgecolor=color, facecolor=color, alpha=0.25)\n",
    "        ax[j,i].add_patch(rectangle)\n",
    "    for letter in letters_list:\n",
    "        wells_letter = [wellname for wellname in dataset.well.unique() if wellname.startswith(letter)]\n",
    "        fig, ax = plt.subplots(rows,columns, figsize=(16,rows*2.5))\n",
    "        counter = 0\n",
    "        for j in range(0, rows):\n",
    "            for i in range(0, columns):\n",
    "                if counter < len(wells_letter):\n",
    "                    wellname = wells_letter[counter]\n",
    "                    welldata = dataset[dataset.well==wellname]\n",
    "                    df_top = pd.DataFrame({'well':[wellname], 'phit':[0], 'htst':[0], 'cluster':welldata['cluster'].iloc[0],'depth':[0]})\n",
    "                    welldata = pd.concat([df_top, welldata]).reset_index().drop('index', axis=1)\n",
    "                    ax[j,i].plot(welldata['phit'], welldata['depth'], drawstyle='steps-post', color='black', alpha=1, lw=0.75)\n",
    "                    ax[j,i].set_xlim(0, 0.35)\n",
    "                    ax[j,i].invert_yaxis()\n",
    "                    ax[j,i].set_title(wellname)\n",
    "                    ax[j,i].tick_params(axis='both', which='major', labelsize=10)\n",
    "                    ax[j,i].grid()\n",
    "                    for k in range(len(welldata)):\n",
    "                        if welldata['phit'].iloc[k] > 0 and welldata['cluster'].iloc[k] == 0:\n",
    "                            clusters_rectangle(welldata, k, 'blue')\n",
    "                        if welldata['phit'].iloc[k] > 0 and welldata['cluster'].iloc[k] == 1:\n",
    "                            clusters_rectangle(welldata, k, 'green')\n",
    "                        if welldata['phit'].iloc[k] > 0 and welldata['cluster'].iloc[k] == 2:\n",
    "                            clusters_rectangle(welldata, k, 'red')\n",
    "                    fig.suptitle(clustering)\n",
    "                    fig.tight_layout()\n",
    "                    counter +=1\n",
    "        if output_flag == 'print':\n",
    "            plt.savefig('.\\plots\\\\clustering_wells_tpb\\\\' + clustering + '_' + str(letter) +'.png')\n",
    "        else:\n",
    "            pass\n",
    "coloring_clusters_matrix_tpb3(tpb8_kmeans_v3, ['B'], 4, 9, 'kmeans bal8', 'dontprint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_data_to_map(dataset, dataset_coord, comment):\n",
    "    def dataset_groupby(dataset):\n",
    "        result = dataset.groupby(['well','cluster'])['htst'].sum().reset_index()\n",
    "        return result\n",
    "    tpb_test_v3_piechart = dataset_groupby(dataset)\n",
    "\n",
    "    def cluster_transpose(dataset, wellname):\n",
    "        result = dataset[dataset.well==wellname]\n",
    "        result.loc[result.cluster == 0, 'cluster_0'] = result.htst\n",
    "        result.loc[result.cluster == 1, 'cluster_1'] = result.htst\n",
    "        result.loc[result.cluster == 2, 'cluster_2'] = result.htst\n",
    "        result.fillna(0)\n",
    "        result = result.groupby('well').sum().reset_index()\n",
    "        result = result[['well', 'cluster_0', 'cluster_1','cluster_2']]\n",
    "        return result\n",
    "    df_lst = []\n",
    "    for wellname in tpb_test_v3_piechart.well.unique():\n",
    "        df = cluster_transpose(tpb_test_v3_piechart, wellname)\n",
    "        df_lst.append(df)\n",
    "    data_transpose = pd.concat(df_lst).reset_index(drop=True)\n",
    "\n",
    "    def coordinates_calc(dataset_coord, fm):\n",
    "        dataset_coord = dataset_coord[dataset_coord.FORMATION_up == fm]\n",
    "        result = dataset_coord.groupby('well')[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "        return result \n",
    "    coord = coordinates_calc(dataset_coord, 'Balakhany VIII')\n",
    "    data_transpose_coord = data_transpose.set_index('well').join(coord.set_index('well'), rsuffix='_coord').reset_index()\n",
    "\n",
    "    def piechart_map(dataset_map):\n",
    "        fig, ax = plt.subplots(figsize=(13,10))\n",
    "        ax.scatter(bal8_1510['X']/1000, bal8_1510['Y']/1000, c=bal8_1510['geobody'])\n",
    "        for ind, row in dataset_map.iterrows():\n",
    "                ax.pie([row['cluster_0'], row['cluster_1'], row['cluster_2']], \n",
    "                        radius=0.3, center=(row['X_mean']/1000, row['Y_mean']/1000), wedgeprops={\"linewidth\": 0.5, \"edgecolor\": \"gray\", \"alpha\":0.75},\n",
    "                        colors=['blue', 'green', 'red'], frame=True)\n",
    "        # plt.grid()\n",
    "        plt.title(comment)     \n",
    "    piechart_map(data_transpose_coord)\n",
    "    return data_transpose_coord\n",
    "cluster_kmeans = cluster_data_to_map(tpb8_kmeans_v3, df_bal_net2_kh, 'Well Bal8 clustering by Kmeans & Bal8 1510 geobodies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of clusters thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_normalization(dataset, dataset_coord, fm):\n",
    "    df_lst = []\n",
    "    for wellname in dataset.well.unique():\n",
    "        data = dataset[dataset.well == wellname]\n",
    "        h_0 = data[data.cluster==0].htst.sum()\n",
    "        h_1 = data[data.cluster==1].htst.sum()\n",
    "        h_2 = data[data.cluster==2].htst.sum()\n",
    "\n",
    "        total_thick = data.depth.iloc[-1]\n",
    "        h_0 = h_0 / total_thick\n",
    "        h_1 = h_1 / total_thick\n",
    "        h_2 = h_2 / total_thick \n",
    "\n",
    "        welldata = pd.DataFrame({'well':[wellname], 'FORMATION_up':fm, 'cluster_0':[h_0], 'cluster_1':[h_1], 'cluster_2':[h_2]})\n",
    "        df_lst.append(welldata)\n",
    "    well_df = pd.concat(df_lst).reset_index(drop=True)\n",
    "    coord_xy_init = dataset_coord[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "    coord_xy = coord_xy_init[coord_xy_init['FORMATION_up'] == fm]\n",
    "    result = well_df.set_index('well').join(coord_xy.drop('FORMATION_up', axis=1).set_index('well')).reset_index()\n",
    "    return result\n",
    "cluster_norm = clustering_normalization(tpb8_kmeans_v3, df_bal_net2_kh, 'Balakhany VIII').drop('FORMATION_up', axis=1)\n",
    "# cluster_norm.to_csv(r'C:\\jupyter\\SPP\\output\\petrel\\kmeans_normalize.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gmm map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpb_gmm_v3 = well_collecting_clusters_top_phi_bot_v2(result, 'gmm')\n",
    "\n",
    "def cluster_data_to_map(dataset, dataset_coord, comment):\n",
    "    def dataset_groupby(dataset):\n",
    "        result = dataset.groupby(['well','cluster'])['htst'].sum().reset_index()\n",
    "        return result\n",
    "    tpb_test_v3_piechart = dataset_groupby(dataset)\n",
    "\n",
    "    def cluster_transpose(dataset, wellname):\n",
    "        result = dataset[dataset.well==wellname]\n",
    "        result.loc[result.cluster == 0, 'cluster_0'] = result.htst\n",
    "        result.loc[result.cluster == 1, 'cluster_1'] = result.htst\n",
    "        result.loc[result.cluster == 2, 'cluster_2'] = result.htst\n",
    "        result.fillna(0)\n",
    "        result = result.groupby('well').sum().reset_index()\n",
    "        result = result[['well', 'cluster_0', 'cluster_1','cluster_2']]\n",
    "        return result\n",
    "    df_lst = []\n",
    "    for wellname in tpb_test_v3_piechart.well.unique():\n",
    "        df = cluster_transpose(tpb_test_v3_piechart, wellname)\n",
    "        df_lst.append(df)\n",
    "    data_transpose = pd.concat(df_lst).reset_index(drop=True)\n",
    "\n",
    "    def coordinates_calc(dataset_coord, fm):\n",
    "        dataset_coord = dataset_coord[dataset_coord.FORMATION_up == fm]\n",
    "        result = dataset_coord.groupby('well')[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "        return result \n",
    "    coord = coordinates_calc(dataset_coord, 'Balakhany VIII')\n",
    "    data_transpose_coord = data_transpose.set_index('well').join(coord.set_index('well'), rsuffix='_coord').reset_index()\n",
    "\n",
    "    def piechart_map(dataset_map):\n",
    "        fig, ax = plt.subplots(figsize=(13,13))\n",
    "        for ind, row in dataset_map.iterrows():\n",
    "                ax.pie([row['cluster_0'], row['cluster_1'], row['cluster_2']], \n",
    "                        radius=0.3, center=(row['X_mean']/1000, row['Y_mean']/1000), wedgeprops={\"linewidth\": 0.5, \"edgecolor\": \"gray\", \"alpha\":0.75},\n",
    "                        colors=['blue', 'green', 'red'], frame=True)\n",
    "        plt.grid()\n",
    "        plt.title(comment)\n",
    "    piechart_map(data_transpose_coord)\n",
    "\n",
    "    return data_transpose_coord\n",
    "histo_clustering(result, 'gmm', 'Kmeans')\n",
    "cluster_gmm = cluster_data_to_map(tpb_gmm_v3, df_bal_net2_kh, 'Gmm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow for prediction khtst from phit_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Archiv models\n",
    "# model3 = model_preiction_split(dataset8, SVR(), 0.05, 'dont_display')\n",
    "# model6 = model_preiction_split(dataset8, SGDRegressor(random_state=42), 0.05, 'dont_display')\n",
    "# model7 = model_preiction_split(dataset8, GaussianProcessRegressor(random_state=42), 0.05, 'dont_display')\n",
    "# model8 = model_preiction_split(dataset8, DecisionTreeRegressor(random_state=42), 0.05, 'dont_display')\n",
    "# model9 = model_preiction_split(dataset8, GradientBoostingRegressor(random_state=42), 0.05, 'dont_display')\n",
    "# model11 = model_preiction_split(dataset8, MLPRegressor(random_state=1, max_iter=1000), 0.05, 'dont_display')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_clustering(data_clustered8, 'kmeans', 'Kmeans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments with offset wells on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_well_traj_map(dataset, fmname, mult, wellname):\n",
    "    def well_traj_data_calculation(dataset):\n",
    "        map_data = dataset.dropna(subset=['KHtst'])\n",
    "        map_data_top = map_data.groupby(['well','FORMATION_up'])[['X_traj','Y_traj']].apply(lambda x: x.iloc[0:-100:100]).reset_index()\n",
    "        map_data_bot = map_data.groupby(['well','FORMATION_up'])[['X_traj','Y_traj']].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "        map_data_middle = map_data.groupby(['well','FORMATION_up'])[['X_mean', 'Y_mean', 'KHtst', 'TVD_SCS', 'Status']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "        map_trajectory_display = pd.concat([map_data_top, map_data_bot]).sort_values(by=['well','FORMATION_up']).drop('level_2', axis=1)\n",
    "        return map_trajectory_display, map_data_middle\n",
    "    map_trajectory_display, map_data_middle = well_traj_data_calculation(dataset)\n",
    "    def well_offset_coord(wellname, fm):\n",
    "        def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "                \n",
    "                def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                    coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                    dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                    result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                    coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                    return coordinates, result\n",
    "                coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "                coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "                def well_distance_calculation(coordinates, fm):\n",
    "                    coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                    df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                    well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                    result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                    return result\n",
    "                well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "                def offset_well_names_dist(dataset, offset_qty):\n",
    "                    df_lst = []\n",
    "                    for ind in range(len(dataset.well.unique())):\n",
    "                        off_well_series = dataset.iloc[ind]\n",
    "                        off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                        off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                        off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                        dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                        well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                        col_names = []\n",
    "                        for i in range(len(off_well_selected.columns[:-1])):\n",
    "                            col = off_well_selected.columns[i]\n",
    "                            col_names.append(col)\n",
    "                            off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                        off_well_names = pd.DataFrame(col_names).T\n",
    "                        col_names = []\n",
    "                        for i in range(len(off_well_names.columns)):\n",
    "                            col = off_well_names.columns[i]\n",
    "                            col_names.append(col)\n",
    "                            off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                        \n",
    "                        concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                        df_lst.append(concat_well_data)\n",
    "                    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                    return result\n",
    "                well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "                return well_dist_data8\n",
    "        well_offset_df = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list = [0,1,2])\n",
    "\n",
    "        coord_xy = df_bal_net2_kh[['well','FORMATION_up','X_mean','Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "        coord_xy_fm = coord_xy[coord_xy['FORMATION_up'] == fm].reset_index(drop=True)\n",
    "\n",
    "        data = well_offset_df[well_offset_df.well == wellname]\n",
    "        df_coord = []\n",
    "        for col in data.columns:\n",
    "            if 'well_' in col:\n",
    "                coord = coord_xy_fm[coord_xy_fm.well == data[col].iloc[0]]\n",
    "                df_coord.append(coord)\n",
    "        result = pd.concat(df_coord)\n",
    "        return result\n",
    "    well_offset_df = well_offset_coord(wellname, fmname)   \n",
    "    def display_map(trajectory, map_data_middle, well_offset, fmname, mult, path, comment, print_flag):\n",
    "        target_wellname = map_data_middle[(map_data_middle.well == wellname) & (map_data_middle.FORMATION_up == fmname)]\n",
    "        trajectory = trajectory[trajectory.FORMATION_up == fmname]\n",
    "        map_data_middle = map_data_middle[map_data_middle.FORMATION_up == fmname]\n",
    "        map_data_middle['KHtst'] = map_data_middle['KHtst'].round(0)\n",
    "        traj = go.Scatter(  x=trajectory.X_traj, y=trajectory.Y_traj, \n",
    "                            mode='markers',\n",
    "                            marker=dict(color='black', size=1),\n",
    "                            customdata = trajectory[['well']],\n",
    "                            hovertemplate=\"\".join([\"well:%{customdata[0]}<extra></extra>\"])\n",
    "                            )\n",
    "        wells = go.Scatter( x=map_data_middle.X_mean, y=map_data_middle.Y_mean, \n",
    "                            mode='markers',\n",
    "                            # marker=dict(symbol='diamond', color='red', size=7, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            marker=dict(color=map_data_middle.KHtst, size=map_data_middle.KHtst*mult, colorscale='RdYlGn',  showscale=True,\n",
    "                                        line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            customdata = map_data_middle[['well', 'KHtst']],\n",
    "                            hovertemplate=\"\".join([\"well:%{customdata[0]},kh:%{customdata[1]}<extra></extra>\"]))\n",
    "        \n",
    "        offset = go.Scatter( x=well_offset.X_mean, y=well_offset.Y_mean, mode='markers',\n",
    "                            marker=dict(color='rgba(0,0,0,0)', size=10, line=dict(color='red', width=1.5)))\n",
    "        target_well = go.Scatter( x=target_wellname.X_mean, y=target_wellname.Y_mean, mode='markers',\n",
    "                    marker=dict(color='rgba(0,0,0,0)', size=10, line=dict(color='green', width=1.5)))\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(traj)\n",
    "        fig.add_trace(wells)\n",
    "        fig.add_trace(offset)\n",
    "        fig.add_trace(target_well)\n",
    "        fig.update_layout(  title_text= ('Map of traj and well mean points'+ ' ' + fmname + ' Size of bubbles is KHtst.'),\n",
    "                            autosize=True, width=700, height=400, margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "        if print_flag == 'print':\n",
    "            go_offline.plot(fig, filename=path + comment, validate=True, auto_open=False)\n",
    "        else:\n",
    "            pass\n",
    "        return fig.show()\n",
    "    display_map(map_trajectory_display, map_data_middle, well_offset_df, fmname, mult, 'plots/', 'Balakhany8_KHtst', 'dont_print')\n",
    "    \n",
    "    return map_trajectory_display, map_data_middle\n",
    "\n",
    "# B34, E16Y, A01W, E05Z, D06, B13ST2, C18, A07Z, A11Z, A04\n",
    "wellname_list = ['B34', 'E16Y', 'A01W', 'E05Z', 'D06', 'B13ST2', 'C18', 'A07Z', 'A11Z', 'A04']\n",
    "for wellname in wellname_list:\n",
    "    map_trajectory_display, map_data_middle = display_well_traj_map(df_bal_net2_kh, 'Balakhany VIII', 0.00125, wellname)\n",
    "    def numerical_data_display(dataset_offset, wellname):\n",
    "        result = dataset_offset[dataset_offset.well == wellname][['well','FORMATION_up',\n",
    "                                                                'phit_wavg_target',\n",
    "                                                                'dist_1','dist_2','dist_3', 'phit_wavg_1', 'phit_wavg_2', 'phit_wavg_3']]\n",
    "        return result\n",
    "    print(numerical_data_display(test_full['khtst_data'], wellname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLuster 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test_full['phit_pred']\n",
    "# test['diff'] = abs(test.y_orig - test.y_pred)*100\n",
    "# test.sort_values(by='diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def khtst_workflow(cluster_list):\n",
    "\n",
    "    def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "            \n",
    "            def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                return coordinates, result\n",
    "            coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "            coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "            def well_distance_calculation(coordinates, fm):\n",
    "                coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                return result\n",
    "            well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "            def offset_well_names_dist(dataset, offset_qty):\n",
    "                df_lst = []\n",
    "                for ind in range(len(dataset.well.unique())):\n",
    "                    off_well_series = dataset.iloc[ind]\n",
    "                    off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                    off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                    off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                    dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                    well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_selected.columns[:-1])):\n",
    "                        col = off_well_selected.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                    off_well_names = pd.DataFrame(col_names).T\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_names.columns)):\n",
    "                        col = off_well_names.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                    \n",
    "                    concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                    df_lst.append(concat_well_data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "            def offset_wells_features_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    data = dataset_dist[dataset_dist.well == wellname]\n",
    "                    cc = 0\n",
    "                    for j in data.columns:\n",
    "                        if 'well_' in j:\n",
    "                            cc += 1\n",
    "                            offset_wellname = data[j].values[0]\n",
    "                            data_cluster = dataset_clusters[(dataset_clusters.well == offset_wellname) & \n",
    "                                                                (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                            var_name = 'phit_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['phit_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'vsh_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['vsh_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'htst_sum_' + str(cc)\n",
    "                            data[var_name] = data_cluster['htst'].sum()                \n",
    "                    df_lst.append(data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                result['FORMATION_up'] = fm\n",
    "                return result\n",
    "            well_features8 = offset_wells_features_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "\n",
    "            def target_wells_variable_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    df = pd.DataFrame({'well': [wellname], 'FORMATION_up': [fm], 'phit_wavg_target': [0]})\n",
    "                    data = dataset_clusters[(dataset_clusters.well == wellname) & \n",
    "                                            (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                    df['phit_wavg_target'] = ((data['phit_avg'] * data['htst']).sum()) / (data['htst'].sum())\n",
    "                    df_lst.append(df)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_target8 = target_wells_variable_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "            \n",
    "            dataset8 = well_target8.set_index(['well','FORMATION_up']).join(well_features8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "            result = {'dataset8':dataset8, 'cluster_xy':dataset_cluster_xy, 'well_dist8':well_dist_data8, 'coordinates':coordinates,\n",
    "                    'target8':well_target8, 'feature8':well_features8, 'dist_crosstable8':well_dist_crosstable_8}\n",
    "            return result\n",
    "    input_ph8 = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list)['dataset8']\n",
    "    print(f'Dataset features {textwrap.fill(str(list(input_ph8.columns)), width=150)}')\n",
    "\n",
    "    def run_phit_pred_split(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            # model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print('features dataset: \\n', list(X_train.columns))\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('test \"in\":', '{:.2f}'.format(result['testqc'].round(2)),'\\t', model_name)\n",
    "            return result\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')   \n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_ph = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_ph = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_ph = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_ph = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_ph = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        xplot_qc2(model1_ph['result'], model1_ph['trainqc'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_ph['result'], model2_ph['trainqc'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_ph['result'], model3_ph['trainqc'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc2(model4_ph['result'], model4_ph['trainqc'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_ph['result'], model5_ph['trainqc'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_ph['result'], model6_ph['trainqc'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model_split = run_phit_pred_split(input_ph8, cluster_list, tolerance=0.05)['result']\n",
    "\n",
    "    def run_phit_pred_1_to_all(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_1_to_all(dataset, selected_model, target, tolerance, model_name):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "            print(model_name)\n",
    "            df_lst = []\n",
    "            for wellname in tqdm(dataset.well.unique()[:]):\n",
    "                train = dataset[dataset.well != wellname]\n",
    "                X_train_init = train.drop(target, axis=1)\n",
    "                y_train_init = train[['well','FORMATION_up', target]]\n",
    "                X_train = X_train_init.drop(drop_lst_X, axis=1)\n",
    "                y_train = y_train_init.drop(drop_lst_y, axis=1)\n",
    "                model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                test = dataset[dataset.well == wellname]\n",
    "                y_test_wnames = test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "                X_test_init = test.drop(target, axis=1)\n",
    "                y_test_init = test[['well','FORMATION_up', target]]\n",
    "                X_test = X_test_init.drop(drop_lst_X, axis=1)\n",
    "                y_test = y_test_init.drop(drop_lst_y, axis=1).values[0]\n",
    "                y_pred = model.predict(X_test)\n",
    "                test = pd.DataFrame(zip(y_test, y_pred), columns=['y_orig', 'y_pred'])\n",
    "                test = pd.concat([y_test_wnames, test], axis=1)\n",
    "                df_lst.append(test)\n",
    "                \n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['up'] = result['y_orig']*(1 + tolerance)\n",
    "            result['down'] = result['y_orig']*(1 - tolerance)\n",
    "            result['qc'] = 'out'\n",
    "            result.loc[(result['y_pred'] <= result.up) & (result['y_pred'] >= result.down), 'qc'] = 'in'\n",
    "            resultqc = result.qc.value_counts(normalize=True)\n",
    "\n",
    "            phit_pred = result[['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "            dataset_pred = dataset.set_index(['well','FORMATION_up']).join(phit_pred.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "            result_dict = {'result':result, 'res_full':dataset_pred, 'testqc':resultqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            return result_dict\n",
    "        def xplot_qc_1_to_all(data, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_test = data\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_test = go.Scatter( x=ds_test['y_orig'], y=ds_test['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_test[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=1, subplot_titles=(f'test qc {qc_test}',))\n",
    "            fig.add_trace(scatter_test,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.update_layout(  title_text= (comment), width=350, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_1_to_all(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance,'RandomForestRegressor')\n",
    "        # model2_ph = model_prediction_1_to_all(dataset, BayesianRidge(), target, 0.05, 'BayesianRidge')\n",
    "        # model3_ph = model_prediction_1_to_all(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, 0.05, 'XGBRegressor')\n",
    "        # model4_ph = model_prediction_1_to_all(dataset, CatBoostRegressor(random_state=42, verbose=False), target, 0.05,'CatBoostRegressor')\n",
    "        # model5_ph = model_prediction_1_to_all(dataset, AdaBoostRegressor(random_state=42), target, 0.05, 'AdaBoostRegressor')\n",
    "        # model6_ph = model_prediction_1_to_all(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, 0.05, 'LGBMRegressor')\n",
    "\n",
    "        xplot_qc_1_to_all(model1_ph['result'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model2_ph['result'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model3_ph['result'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model4_ph['result'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model5_ph['result'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model6_ph['result'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model = run_phit_pred_1_to_all(input_ph8, cluster_list, tolerance=0.05)\n",
    "\n",
    "    def concat_prediction_to_khtst_df(data_pred, data_khtst, data_main, cluster_algo):\n",
    "        phit_pred8 = data_pred['result'][['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "        khtst8 = data_khtst[data_khtst[cluster_algo].isin(cluster_list)].groupby(['well','FORMATION_up'])['khtst'].sum().reset_index()\n",
    "\n",
    "        khtst8_phit_pred8 = khtst8.set_index(['well','FORMATION_up']).join(phit_pred8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "        phitpred_khtst = khtst8_phit_pred8.set_index(['well','FORMATION_up']).join(data_main.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "        phitpred_khtst.insert(19, 'phit_pred', phitpred_khtst.pop('phit_pred'))\n",
    "        phitpred_khtst.insert(19, 'phit_wavg_target', phitpred_khtst.pop('phit_wavg_target'))\n",
    "        phitpred_khtst.insert(19, 'khtst', phitpred_khtst.pop('khtst'))\n",
    "        return phitpred_khtst\n",
    "    phitpred_khtst = concat_prediction_to_khtst_df(model, data_clustered8, input_ph8, 'kmeans')\n",
    "    print(f'Concat dataset features {textwrap.fill(str(list(phitpred_khtst.columns)), width=150)}')\n",
    "\n",
    "    print('\\nPrediction KHtst: ')\n",
    "    def run_khtst_pred_split(dataset, cluster_list, tolerance):\n",
    "\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            \"\"\"\n",
    "            'well', 'FORMATION_up', 'well_1', 'well_2', 'well_3', 'dist_1',\n",
    "            'dist_2', 'dist_3', 'phit_wavg_1', 'vsh_wavg_1', 'htst_sum_1',\n",
    "            'phit_wavg_2', 'vsh_wavg_2', 'htst_sum_2', 'phit_wavg_3', 'vsh_wavg_3',\n",
    "            'htst_sum_3', 'phit_pred', 'phit_wavg_target', 'khtst'\n",
    "            \"\"\"\n",
    "            drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3', 'dist_1', 'dist_2','dist_3', 'phit_wavg_target']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            # model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print(f'features dataset: {list(X_train.columns)}')\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            return result\n",
    "\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')\n",
    "        target = 'khtst'\n",
    "        model1_kh = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_kh = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_kh = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_kh = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_kh = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_kh = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        # xplot_qc2(model1_kh['result'], model1_kh['trainqc'], model1_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_kh['result'], model2_kh['trainqc'], model2_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_kh['result'], model3_kh['trainqc'], model3_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        xplot_qc2(model4_kh['result'], model4_kh['trainqc'], model4_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_kh['result'], model5_kh['trainqc'], model5_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_kh['result'], model6_kh['trainqc'], model6_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model4_kh\n",
    "    model_khtst = run_khtst_pred_split(phitpred_khtst, cluster_list, 0.25)\n",
    "    result = {'khtst_pred':model_khtst['result'], 'khtst_data':phitpred_khtst, 'phit_pred':model['result']}\n",
    "    return result\n",
    "test_full = khtst_workflow(cluster_list = [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_special(dataset, xsize, ysize, flag=1):\n",
    "    if flag == 1:\n",
    "        def corrfunc(x, y, **kws):\n",
    "            r, _ = stats.pearsonr(x, y)\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                        xy=(.1, .9), xycoords=ax.transAxes)\n",
    "        sns.set_context(rc={'axes.labelsize':10, 'lines.linewidth': 0.75})\n",
    "        g = sns.PairGrid(dataset)\n",
    "        g.fig.set_size_inches(xsize,ysize)\n",
    "        g.set(xticklabels=[], yticklabels=[]) \n",
    "        g.map_upper(plt.scatter, s=10, alpha=0.5)\n",
    "        g.map_diag(sns.distplot, kde=False)\n",
    "        g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g.map_lower(corrfunc)\n",
    "    else:\n",
    "        pass\n",
    "drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3',\n",
    "                                        'dist_1', 'dist_2', 'dist_3', 'vsh_wavg_1', 'htst_sum_1', 'vsh_wavg_2', 'htst_sum_2', 'vsh_wavg_3', 'htst_sum_3',]\n",
    "pairplot_special(test_full['khtst_data'].drop(drop_lst_X, axis=1), 7, 7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def khtst_workflow(cluster_list):\n",
    "\n",
    "    def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "            \n",
    "            def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                return coordinates, result\n",
    "            coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "            coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "            def well_distance_calculation(coordinates, fm):\n",
    "                coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                return result\n",
    "            well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "            def offset_well_names_dist(dataset, offset_qty):\n",
    "                df_lst = []\n",
    "                for ind in range(len(dataset.well.unique())):\n",
    "                    off_well_series = dataset.iloc[ind]\n",
    "                    off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                    off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                    off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                    dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                    well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_selected.columns[:-1])):\n",
    "                        col = off_well_selected.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                    off_well_names = pd.DataFrame(col_names).T\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_names.columns)):\n",
    "                        col = off_well_names.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                    \n",
    "                    concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                    df_lst.append(concat_well_data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "            def offset_wells_features_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    data = dataset_dist[dataset_dist.well == wellname]\n",
    "                    cc = 0\n",
    "                    for j in data.columns:\n",
    "                        if 'well_' in j:\n",
    "                            cc += 1\n",
    "                            offset_wellname = data[j].values[0]\n",
    "                            data_cluster = dataset_clusters[(dataset_clusters.well == offset_wellname) & \n",
    "                                                                (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                            var_name = 'phit_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['phit_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'vsh_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['vsh_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'htst_sum_' + str(cc)\n",
    "                            data[var_name] = data_cluster['htst'].sum()                \n",
    "                    df_lst.append(data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                result['FORMATION_up'] = fm\n",
    "                return result\n",
    "            well_features8 = offset_wells_features_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "\n",
    "            def target_wells_variable_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    df = pd.DataFrame({'well': [wellname], 'FORMATION_up': [fm], 'phit_wavg_target': [0]})\n",
    "                    data = dataset_clusters[(dataset_clusters.well == wellname) & \n",
    "                                            (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                    df['phit_wavg_target'] = ((data['phit_avg'] * data['htst']).sum()) / (data['htst'].sum())\n",
    "                    df_lst.append(df)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_target8 = target_wells_variable_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "            \n",
    "            dataset8 = well_target8.set_index(['well','FORMATION_up']).join(well_features8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "            result = {'dataset8':dataset8, 'cluster_xy':dataset_cluster_xy, 'well_dist8':well_dist_data8, 'coordinates':coordinates,\n",
    "                    'target8':well_target8, 'feature8':well_features8, 'dist_crosstable8':well_dist_crosstable_8}\n",
    "            return result\n",
    "    input_ph8 = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list)['dataset8']\n",
    "    print(f'Dataset features {textwrap.fill(str(list(input_ph8.columns)), width=150)}')\n",
    "\n",
    "    def run_phit_pred_split(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            # model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print('features dataset: \\n', list(X_train.columns))\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('test \"in\":', '{:.2f}'.format(result['testqc'].round(2)),'\\t', model_name)\n",
    "            return result\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')   \n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_ph = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_ph = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_ph = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_ph = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_ph = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        xplot_qc2(model1_ph['result'], model1_ph['trainqc'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_ph['result'], model2_ph['trainqc'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_ph['result'], model3_ph['trainqc'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc2(model4_ph['result'], model4_ph['trainqc'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_ph['result'], model5_ph['trainqc'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_ph['result'], model6_ph['trainqc'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model_split = run_phit_pred_split(input_ph8, cluster_list, tolerance=0.05)['result']\n",
    "\n",
    "    def run_phit_pred_1_to_all(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_1_to_all(dataset, selected_model, target, tolerance, model_name):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "            print(model_name)\n",
    "            df_lst = []\n",
    "            for wellname in tqdm(dataset.well.unique()[:]):\n",
    "                train = dataset[dataset.well != wellname]\n",
    "                X_train_init = train.drop(target, axis=1)\n",
    "                y_train_init = train[['well','FORMATION_up', target]]\n",
    "                X_train = X_train_init.drop(drop_lst_X, axis=1)\n",
    "                y_train = y_train_init.drop(drop_lst_y, axis=1)\n",
    "                model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                test = dataset[dataset.well == wellname]\n",
    "                y_test_wnames = test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "                X_test_init = test.drop(target, axis=1)\n",
    "                y_test_init = test[['well','FORMATION_up', target]]\n",
    "                X_test = X_test_init.drop(drop_lst_X, axis=1)\n",
    "                y_test = y_test_init.drop(drop_lst_y, axis=1).values[0]\n",
    "                y_pred = model.predict(X_test)\n",
    "                test = pd.DataFrame(zip(y_test, y_pred), columns=['y_orig', 'y_pred'])\n",
    "                test = pd.concat([y_test_wnames, test], axis=1)\n",
    "                df_lst.append(test)\n",
    "                \n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['up'] = result['y_orig']*(1 + tolerance)\n",
    "            result['down'] = result['y_orig']*(1 - tolerance)\n",
    "            result['qc'] = 'out'\n",
    "            result.loc[(result['y_pred'] <= result.up) & (result['y_pred'] >= result.down), 'qc'] = 'in'\n",
    "            resultqc = result.qc.value_counts(normalize=True)\n",
    "\n",
    "            phit_pred = result[['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "            dataset_pred = dataset.set_index(['well','FORMATION_up']).join(phit_pred.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "            result_dict = {'result':result, 'res_full':dataset_pred, 'testqc':resultqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            return result_dict\n",
    "        def xplot_qc_1_to_all(data, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_test = data\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_test = go.Scatter( x=ds_test['y_orig'], y=ds_test['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_test[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=1, subplot_titles=(f'test qc {qc_test}',))\n",
    "            fig.add_trace(scatter_test,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.update_layout(  title_text= (comment), width=350, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_1_to_all(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance,'RandomForestRegressor')\n",
    "        # model2_ph = model_prediction_1_to_all(dataset, BayesianRidge(), target, 0.05, 'BayesianRidge')\n",
    "        # model3_ph = model_prediction_1_to_all(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, 0.05, 'XGBRegressor')\n",
    "        # model4_ph = model_prediction_1_to_all(dataset, CatBoostRegressor(random_state=42, verbose=False), target, 0.05,'CatBoostRegressor')\n",
    "        # model5_ph = model_prediction_1_to_all(dataset, AdaBoostRegressor(random_state=42), target, 0.05, 'AdaBoostRegressor')\n",
    "        # model6_ph = model_prediction_1_to_all(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, 0.05, 'LGBMRegressor')\n",
    "\n",
    "        xplot_qc_1_to_all(model1_ph['result'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model2_ph['result'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model3_ph['result'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model4_ph['result'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model5_ph['result'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model6_ph['result'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model = run_phit_pred_1_to_all(input_ph8, cluster_list, tolerance=0.05)\n",
    "\n",
    "    def concat_prediction_to_khtst_df(data_pred, data_khtst, data_main, cluster_algo):\n",
    "        phit_pred8 = data_pred['result'][['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "        khtst8 = data_khtst[data_khtst[cluster_algo].isin(cluster_list)].groupby(['well','FORMATION_up'])['khtst'].sum().reset_index()\n",
    "\n",
    "        khtst8_phit_pred8 = khtst8.set_index(['well','FORMATION_up']).join(phit_pred8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "        phitpred_khtst = khtst8_phit_pred8.set_index(['well','FORMATION_up']).join(data_main.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "        phitpred_khtst.insert(19, 'phit_pred', phitpred_khtst.pop('phit_pred'))\n",
    "        phitpred_khtst.insert(19, 'phit_wavg_target', phitpred_khtst.pop('phit_wavg_target'))\n",
    "        phitpred_khtst.insert(19, 'khtst', phitpred_khtst.pop('khtst'))\n",
    "        return phitpred_khtst\n",
    "    phitpred_khtst = concat_prediction_to_khtst_df(model, data_clustered8, input_ph8, 'kmeans')\n",
    "    print(f'Concat dataset features {textwrap.fill(str(list(phitpred_khtst.columns)), width=150)}')\n",
    "\n",
    "    print('\\nPrediction KHtst: ')\n",
    "    def run_khtst_pred_split(dataset, cluster_list, tolerance):\n",
    "\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            \"\"\"\n",
    "            'well', 'FORMATION_up', 'well_1', 'well_2', 'well_3', 'dist_1',\n",
    "            'dist_2', 'dist_3', 'phit_wavg_1', 'vsh_wavg_1', 'htst_sum_1',\n",
    "            'phit_wavg_2', 'vsh_wavg_2', 'htst_sum_2', 'phit_wavg_3', 'vsh_wavg_3',\n",
    "            'htst_sum_3', 'phit_pred', 'phit_wavg_target', 'khtst'\n",
    "            \"\"\"\n",
    "            drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3', 'dist_1', 'dist_2','dist_3', 'phit_wavg_target']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            # model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print(f'features dataset: {list(X_train.columns)}')\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            return result\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')\n",
    "        target = 'khtst'\n",
    "        model1_kh = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_kh = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_kh = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_kh = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_kh = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_kh = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        # xplot_qc2(model1_kh['result'], model1_kh['trainqc'], model1_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_kh['result'], model2_kh['trainqc'], model2_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_kh['result'], model3_kh['trainqc'], model3_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        xplot_qc2(model4_kh['result'], model4_kh['trainqc'], model4_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_kh['result'], model5_kh['trainqc'], model5_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_kh['result'], model6_kh['trainqc'], model6_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model4_kh\n",
    "    model_khtst = run_khtst_pred_split(phitpred_khtst, cluster_list, 0.25)\n",
    "    result = {'khtst_pred':model_khtst, 'khtst_data':phitpred_khtst, 'phit_pred':model['result']}\n",
    "    return result\n",
    "test_0 = khtst_workflow(cluster_list = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_special(dataset, xsize, ysize, flag=1):\n",
    "    if flag == 1:\n",
    "        def corrfunc(x, y, **kws):\n",
    "            r, _ = stats.pearsonr(x, y)\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                        xy=(.1, .9), xycoords=ax.transAxes)\n",
    "        sns.set_context(rc={'axes.labelsize':10, 'lines.linewidth': 0.75})\n",
    "        g = sns.PairGrid(dataset)\n",
    "        g.fig.set_size_inches(xsize,ysize)\n",
    "        g.set(xticklabels=[], yticklabels=[]) \n",
    "        g.map_upper(plt.scatter, s=10, alpha=0.5)\n",
    "        g.map_diag(sns.distplot, kde=False)\n",
    "        g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g.map_lower(corrfunc)\n",
    "    else:\n",
    "        pass\n",
    "drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3',\n",
    "                                        'dist_1', 'dist_2', 'dist_3', 'vsh_wavg_1', 'htst_sum_1', 'vsh_wavg_2', 'htst_sum_2', 'vsh_wavg_3', 'htst_sum_3', 'cluster']\n",
    "pairplot_special(test_0['khtst_data'].drop(drop_lst_X, axis=1), 7, 7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def khtst_workflow(cluster_list):\n",
    "\n",
    "    def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "            \n",
    "            def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                return coordinates, result\n",
    "            coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "            coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "            def well_distance_calculation(coordinates, fm):\n",
    "                coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                return result\n",
    "            well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "            def offset_well_names_dist(dataset, offset_qty):\n",
    "                df_lst = []\n",
    "                for ind in range(len(dataset.well.unique())):\n",
    "                    off_well_series = dataset.iloc[ind]\n",
    "                    off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                    off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                    off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                    dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                    well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_selected.columns[:-1])):\n",
    "                        col = off_well_selected.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                    off_well_names = pd.DataFrame(col_names).T\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_names.columns)):\n",
    "                        col = off_well_names.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                    \n",
    "                    concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                    df_lst.append(concat_well_data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "            def offset_wells_features_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    data = dataset_dist[dataset_dist.well == wellname]\n",
    "                    cc = 0\n",
    "                    for j in data.columns:\n",
    "                        if 'well_' in j:\n",
    "                            cc += 1\n",
    "                            offset_wellname = data[j].values[0]\n",
    "                            data_cluster = dataset_clusters[(dataset_clusters.well == offset_wellname) & \n",
    "                                                                (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                            var_name = 'phit_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['phit_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'vsh_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['vsh_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'htst_sum_' + str(cc)\n",
    "                            data[var_name] = data_cluster['htst'].sum()                \n",
    "                    df_lst.append(data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                result['FORMATION_up'] = fm\n",
    "                return result\n",
    "            well_features8 = offset_wells_features_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "\n",
    "            def target_wells_variable_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    df = pd.DataFrame({'well': [wellname], 'FORMATION_up': [fm], 'phit_wavg_target': [0]})\n",
    "                    data = dataset_clusters[(dataset_clusters.well == wellname) & \n",
    "                                            (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                    df['phit_wavg_target'] = ((data['phit_avg'] * data['htst']).sum()) / (data['htst'].sum())\n",
    "                    df_lst.append(df)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_target8 = target_wells_variable_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "            \n",
    "            dataset8 = well_target8.set_index(['well','FORMATION_up']).join(well_features8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "            result = {'dataset8':dataset8, 'cluster_xy':dataset_cluster_xy, 'well_dist8':well_dist_data8, 'coordinates':coordinates,\n",
    "                    'target8':well_target8, 'feature8':well_features8, 'dist_crosstable8':well_dist_crosstable_8}\n",
    "            return result\n",
    "    input_ph8 = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list)['dataset8']\n",
    "    print(f'Dataset features {textwrap.fill(str(list(input_ph8.columns)), width=150)}')\n",
    "\n",
    "    def run_phit_pred_split(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            # model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print('features dataset: \\n', list(X_train.columns))\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('test \"in\":', '{:.2f}'.format(result['testqc'].round(2)),'\\t', model_name)\n",
    "            return result\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')   \n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_ph = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_ph = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_ph = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_ph = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_ph = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        xplot_qc2(model1_ph['result'], model1_ph['trainqc'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_ph['result'], model2_ph['trainqc'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_ph['result'], model3_ph['trainqc'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc2(model4_ph['result'], model4_ph['trainqc'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_ph['result'], model5_ph['trainqc'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_ph['result'], model6_ph['trainqc'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model_split = run_phit_pred_split(input_ph8, cluster_list, tolerance=0.05)['result']\n",
    "\n",
    "    def run_phit_pred_1_to_all(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_1_to_all(dataset, selected_model, target, tolerance, model_name):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "            print(model_name)\n",
    "            df_lst = []\n",
    "            for wellname in tqdm(dataset.well.unique()[:]):\n",
    "                train = dataset[dataset.well != wellname]\n",
    "                X_train_init = train.drop(target, axis=1)\n",
    "                y_train_init = train[['well','FORMATION_up', target]]\n",
    "                X_train = X_train_init.drop(drop_lst_X, axis=1)\n",
    "                y_train = y_train_init.drop(drop_lst_y, axis=1)\n",
    "                model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                test = dataset[dataset.well == wellname]\n",
    "                y_test_wnames = test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "                X_test_init = test.drop(target, axis=1)\n",
    "                y_test_init = test[['well','FORMATION_up', target]]\n",
    "                X_test = X_test_init.drop(drop_lst_X, axis=1)\n",
    "                y_test = y_test_init.drop(drop_lst_y, axis=1).values[0]\n",
    "                y_pred = model.predict(X_test)\n",
    "                test = pd.DataFrame(zip(y_test, y_pred), columns=['y_orig', 'y_pred'])\n",
    "                test = pd.concat([y_test_wnames, test], axis=1)\n",
    "                df_lst.append(test)\n",
    "                \n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['up'] = result['y_orig']*(1 + tolerance)\n",
    "            result['down'] = result['y_orig']*(1 - tolerance)\n",
    "            result['qc'] = 'out'\n",
    "            result.loc[(result['y_pred'] <= result.up) & (result['y_pred'] >= result.down), 'qc'] = 'in'\n",
    "            resultqc = result.qc.value_counts(normalize=True)\n",
    "\n",
    "            phit_pred = result[['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "            dataset_pred = dataset.set_index(['well','FORMATION_up']).join(phit_pred.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "            result_dict = {'result':result, 'res_full':dataset_pred, 'testqc':resultqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            return result_dict\n",
    "        def xplot_qc_1_to_all(data, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_test = data\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_test = go.Scatter( x=ds_test['y_orig'], y=ds_test['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_test[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=1, subplot_titles=(f'test qc {qc_test}',))\n",
    "            fig.add_trace(scatter_test,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.update_layout(  title_text= (comment), width=350, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_1_to_all(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance,'RandomForestRegressor')\n",
    "        # model2_ph = model_prediction_1_to_all(dataset, BayesianRidge(), target, 0.05, 'BayesianRidge')\n",
    "        # model3_ph = model_prediction_1_to_all(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, 0.05, 'XGBRegressor')\n",
    "        # model4_ph = model_prediction_1_to_all(dataset, CatBoostRegressor(random_state=42, verbose=False), target, 0.05,'CatBoostRegressor')\n",
    "        # model5_ph = model_prediction_1_to_all(dataset, AdaBoostRegressor(random_state=42), target, 0.05, 'AdaBoostRegressor')\n",
    "        # model6_ph = model_prediction_1_to_all(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, 0.05, 'LGBMRegressor')\n",
    "\n",
    "        xplot_qc_1_to_all(model1_ph['result'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model2_ph['result'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model3_ph['result'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model4_ph['result'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model5_ph['result'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model6_ph['result'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model = run_phit_pred_1_to_all(input_ph8, cluster_list, tolerance=0.05)\n",
    "\n",
    "    def concat_prediction_to_khtst_df(data_pred, data_khtst, data_main, cluster_algo):\n",
    "        phit_pred8 = data_pred['result'][['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "        khtst8 = data_khtst[data_khtst[cluster_algo].isin(cluster_list)].groupby(['well','FORMATION_up'])['khtst'].sum().reset_index()\n",
    "\n",
    "        khtst8_phit_pred8 = khtst8.set_index(['well','FORMATION_up']).join(phit_pred8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "        phitpred_khtst = khtst8_phit_pred8.set_index(['well','FORMATION_up']).join(data_main.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "        phitpred_khtst.insert(19, 'phit_pred', phitpred_khtst.pop('phit_pred'))\n",
    "        phitpred_khtst.insert(19, 'phit_wavg_target', phitpred_khtst.pop('phit_wavg_target'))\n",
    "        phitpred_khtst.insert(19, 'khtst', phitpred_khtst.pop('khtst'))\n",
    "        return phitpred_khtst\n",
    "    phitpred_khtst = concat_prediction_to_khtst_df(model, data_clustered8, input_ph8, 'kmeans')\n",
    "    print(f'Concat dataset features {textwrap.fill(str(list(phitpred_khtst.columns)), width=150)}')\n",
    "\n",
    "    print('\\nPrediction KHtst: ')\n",
    "    def run_khtst_pred_split(dataset, cluster_list, tolerance):\n",
    "\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            \"\"\"\n",
    "            'well', 'FORMATION_up', 'well_1', 'well_2', 'well_3', 'dist_1',\n",
    "            'dist_2', 'dist_3', 'phit_wavg_1', 'vsh_wavg_1', 'htst_sum_1',\n",
    "            'phit_wavg_2', 'vsh_wavg_2', 'htst_sum_2', 'phit_wavg_3', 'vsh_wavg_3',\n",
    "            'htst_sum_3', 'phit_pred', 'phit_wavg_target', 'khtst'\n",
    "            \"\"\"\n",
    "            drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3', 'dist_1', 'dist_2','dist_3', 'phit_wavg_target']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            # model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print(f'features dataset: {list(X_train.columns)}')\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            return result\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')\n",
    "        target = 'khtst'\n",
    "        model1_kh = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_kh = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_kh = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_kh = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_kh = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_kh = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        # xplot_qc2(model1_kh['result'], model1_kh['trainqc'], model1_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_kh['result'], model2_kh['trainqc'], model2_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_kh['result'], model3_kh['trainqc'], model3_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        xplot_qc2(model4_kh['result'], model4_kh['trainqc'], model4_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_kh['result'], model5_kh['trainqc'], model5_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_kh['result'], model6_kh['trainqc'], model6_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model4_kh\n",
    "    model_khtst = run_khtst_pred_split(phitpred_khtst, cluster_list, 0.25)\n",
    "    result = {'khtst_pred':model_khtst, 'khtst_data':phitpred_khtst, 'phit_pred':model['result']}\n",
    "    return result\n",
    "test_1 = khtst_workflow(cluster_list = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_special(dataset, xsize, ysize, flag=1):\n",
    "    if flag == 1:\n",
    "        def corrfunc(x, y, **kws):\n",
    "            r, _ = stats.pearsonr(x, y)\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                        xy=(.1, .9), xycoords=ax.transAxes)\n",
    "        sns.set_context(rc={'axes.labelsize':10, 'lines.linewidth': 0.75})\n",
    "        g = sns.PairGrid(dataset)\n",
    "        g.fig.set_size_inches(xsize,ysize)\n",
    "        g.set(xticklabels=[], yticklabels=[]) \n",
    "        g.map_upper(plt.scatter, s=10, alpha=0.5)\n",
    "        g.map_diag(sns.distplot, kde=False)\n",
    "        g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g.map_lower(corrfunc)\n",
    "    else:\n",
    "        pass\n",
    "drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3',\n",
    "                                        'dist_1', 'dist_2', 'dist_3', 'vsh_wavg_1', 'htst_sum_1', 'vsh_wavg_2', 'htst_sum_2', 'vsh_wavg_3', 'htst_sum_3', 'cluster']\n",
    "pairplot_special(test_1['khtst_data'].drop(drop_lst_X, axis=1), 7, 7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def khtst_workflow(cluster_list):\n",
    "\n",
    "    def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "            \n",
    "            def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                return coordinates, result\n",
    "            coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "            coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "            def well_distance_calculation(coordinates, fm):\n",
    "                coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                return result\n",
    "            well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "            def offset_well_names_dist(dataset, offset_qty):\n",
    "                df_lst = []\n",
    "                for ind in range(len(dataset.well.unique())):\n",
    "                    off_well_series = dataset.iloc[ind]\n",
    "                    off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                    off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                    off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                    dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                    well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_selected.columns[:-1])):\n",
    "                        col = off_well_selected.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                    off_well_names = pd.DataFrame(col_names).T\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_names.columns)):\n",
    "                        col = off_well_names.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                    \n",
    "                    concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                    df_lst.append(concat_well_data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "            def offset_wells_features_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    data = dataset_dist[dataset_dist.well == wellname]\n",
    "                    cc = 0\n",
    "                    for j in data.columns:\n",
    "                        if 'well_' in j:\n",
    "                            cc += 1\n",
    "                            offset_wellname = data[j].values[0]\n",
    "                            data_cluster = dataset_clusters[(dataset_clusters.well == offset_wellname) & \n",
    "                                                                (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                            var_name = 'phit_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['phit_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'vsh_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['vsh_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'htst_sum_' + str(cc)\n",
    "                            data[var_name] = data_cluster['htst'].sum()                \n",
    "                    df_lst.append(data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                result['FORMATION_up'] = fm\n",
    "                return result\n",
    "            well_features8 = offset_wells_features_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "\n",
    "            def target_wells_variable_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    df = pd.DataFrame({'well': [wellname], 'FORMATION_up': [fm], 'phit_wavg_target': [0]})\n",
    "                    data = dataset_clusters[(dataset_clusters.well == wellname) & \n",
    "                                            (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                    df['phit_wavg_target'] = ((data['phit_avg'] * data['htst']).sum()) / (data['htst'].sum())\n",
    "                    df_lst.append(df)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_target8 = target_wells_variable_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "            \n",
    "            dataset8 = well_target8.set_index(['well','FORMATION_up']).join(well_features8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "            result = {'dataset8':dataset8, 'cluster_xy':dataset_cluster_xy, 'well_dist8':well_dist_data8, 'coordinates':coordinates,\n",
    "                    'target8':well_target8, 'feature8':well_features8, 'dist_crosstable8':well_dist_crosstable_8}\n",
    "            return result\n",
    "    input_ph8 = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list)['dataset8']\n",
    "    print(f'Dataset features {textwrap.fill(str(list(input_ph8.columns)), width=150)}')\n",
    "\n",
    "    def run_phit_pred_split(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            # model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print('features dataset: \\n', list(X_train.columns))\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('test \"in\":', '{:.2f}'.format(result['testqc'].round(2)),'\\t', model_name)\n",
    "            return result\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')   \n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_ph = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_ph = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_ph = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_ph = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_ph = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        xplot_qc2(model1_ph['result'], model1_ph['trainqc'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_ph['result'], model2_ph['trainqc'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_ph['result'], model3_ph['trainqc'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc2(model4_ph['result'], model4_ph['trainqc'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_ph['result'], model5_ph['trainqc'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_ph['result'], model6_ph['trainqc'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model_split = run_phit_pred_split(input_ph8, cluster_list, tolerance=0.05)['result']\n",
    "\n",
    "    def run_phit_pred_1_to_all(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_1_to_all(dataset, selected_model, target, tolerance, model_name):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "            print(model_name)\n",
    "            df_lst = []\n",
    "            for wellname in tqdm(dataset.well.unique()[:]):\n",
    "                train = dataset[dataset.well != wellname]\n",
    "                X_train_init = train.drop(target, axis=1)\n",
    "                y_train_init = train[['well','FORMATION_up', target]]\n",
    "                X_train = X_train_init.drop(drop_lst_X, axis=1)\n",
    "                y_train = y_train_init.drop(drop_lst_y, axis=1)\n",
    "                model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                test = dataset[dataset.well == wellname]\n",
    "                y_test_wnames = test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "                X_test_init = test.drop(target, axis=1)\n",
    "                y_test_init = test[['well','FORMATION_up', target]]\n",
    "                X_test = X_test_init.drop(drop_lst_X, axis=1)\n",
    "                y_test = y_test_init.drop(drop_lst_y, axis=1).values[0]\n",
    "                y_pred = model.predict(X_test)\n",
    "                test = pd.DataFrame(zip(y_test, y_pred), columns=['y_orig', 'y_pred'])\n",
    "                test = pd.concat([y_test_wnames, test], axis=1)\n",
    "                df_lst.append(test)\n",
    "                \n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['up'] = result['y_orig']*(1 + tolerance)\n",
    "            result['down'] = result['y_orig']*(1 - tolerance)\n",
    "            result['qc'] = 'out'\n",
    "            result.loc[(result['y_pred'] <= result.up) & (result['y_pred'] >= result.down), 'qc'] = 'in'\n",
    "            resultqc = result.qc.value_counts(normalize=True)\n",
    "\n",
    "            phit_pred = result[['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "            dataset_pred = dataset.set_index(['well','FORMATION_up']).join(phit_pred.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "            result_dict = {'result':result, 'res_full':dataset_pred, 'testqc':resultqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            return result_dict\n",
    "        def xplot_qc_1_to_all(data, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_test = data\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_test = go.Scatter( x=ds_test['y_orig'], y=ds_test['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_test[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=1, subplot_titles=(f'test qc {qc_test}',))\n",
    "            fig.add_trace(scatter_test,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.update_layout(  title_text= (comment), width=350, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_1_to_all(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance,'RandomForestRegressor')\n",
    "        # model2_ph = model_prediction_1_to_all(dataset, BayesianRidge(), target, 0.05, 'BayesianRidge')\n",
    "        # model3_ph = model_prediction_1_to_all(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, 0.05, 'XGBRegressor')\n",
    "        # model4_ph = model_prediction_1_to_all(dataset, CatBoostRegressor(random_state=42, verbose=False), target, 0.05,'CatBoostRegressor')\n",
    "        # model5_ph = model_prediction_1_to_all(dataset, AdaBoostRegressor(random_state=42), target, 0.05, 'AdaBoostRegressor')\n",
    "        # model6_ph = model_prediction_1_to_all(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, 0.05, 'LGBMRegressor')\n",
    "\n",
    "        xplot_qc_1_to_all(model1_ph['result'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model2_ph['result'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model3_ph['result'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model4_ph['result'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model5_ph['result'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model6_ph['result'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model = run_phit_pred_1_to_all(input_ph8, cluster_list, tolerance=0.05)\n",
    "\n",
    "    def concat_prediction_to_khtst_df(data_pred, data_khtst, data_main, cluster_algo):\n",
    "        phit_pred8 = data_pred['result'][['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "        khtst8 = data_khtst[data_khtst[cluster_algo].isin(cluster_list)].groupby(['well','FORMATION_up'])['khtst'].sum().reset_index()\n",
    "\n",
    "        khtst8_phit_pred8 = khtst8.set_index(['well','FORMATION_up']).join(phit_pred8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "        phitpred_khtst = khtst8_phit_pred8.set_index(['well','FORMATION_up']).join(data_main.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "        phitpred_khtst.insert(19, 'phit_pred', phitpred_khtst.pop('phit_pred'))\n",
    "        phitpred_khtst.insert(19, 'phit_wavg_target', phitpred_khtst.pop('phit_wavg_target'))\n",
    "        phitpred_khtst.insert(19, 'khtst', phitpred_khtst.pop('khtst'))\n",
    "        return phitpred_khtst\n",
    "    phitpred_khtst = concat_prediction_to_khtst_df(model, data_clustered8, input_ph8, 'kmeans')\n",
    "    print(f'Concat dataset features {textwrap.fill(str(list(phitpred_khtst.columns)), width=150)}')\n",
    "\n",
    "    print('\\nPrediction KHtst: ')\n",
    "    def run_khtst_pred_split(dataset, cluster_list, tolerance):\n",
    "\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            \"\"\"\n",
    "            'well', 'FORMATION_up', 'well_1', 'well_2', 'well_3', 'dist_1',\n",
    "            'dist_2', 'dist_3', 'phit_wavg_1', 'vsh_wavg_1', 'htst_sum_1',\n",
    "            'phit_wavg_2', 'vsh_wavg_2', 'htst_sum_2', 'phit_wavg_3', 'vsh_wavg_3',\n",
    "            'htst_sum_3', 'phit_pred', 'phit_wavg_target', 'khtst'\n",
    "            \"\"\"\n",
    "            drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3', 'dist_1', 'dist_2','dist_3', 'phit_wavg_target']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            # model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print(f'features dataset: {list(X_train.columns)}')\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            return result\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')\n",
    "        target = 'khtst'\n",
    "        model1_kh = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_kh = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_kh = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_kh = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_kh = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_kh = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        # xplot_qc2(model1_kh['result'], model1_kh['trainqc'], model1_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_kh['result'], model2_kh['trainqc'], model2_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_kh['result'], model3_kh['trainqc'], model3_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        xplot_qc2(model4_kh['result'], model4_kh['trainqc'], model4_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_kh['result'], model5_kh['trainqc'], model5_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_kh['result'], model6_kh['trainqc'], model6_kh['testqc'], 'y_orig', 'y_pred', 27000, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model4_kh\n",
    "    model_khtst = run_khtst_pred_split(phitpred_khtst, cluster_list, 0.25)\n",
    "    result = {'khtst_pred':model_khtst, 'khtst_data':phitpred_khtst, 'phit_pred':model['result']}\n",
    "    return result\n",
    "test_2 = khtst_workflow(cluster_list = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_special(dataset, xsize, ysize, flag=1):\n",
    "    if flag == 1:\n",
    "        def corrfunc(x, y, **kws):\n",
    "            r, _ = stats.pearsonr(x, y)\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                        xy=(.1, .9), xycoords=ax.transAxes)\n",
    "        sns.set_context(rc={'axes.labelsize':10, 'lines.linewidth': 0.75})\n",
    "        g = sns.PairGrid(dataset)\n",
    "        g.fig.set_size_inches(xsize,ysize)\n",
    "        g.set(xticklabels=[], yticklabels=[]) \n",
    "        g.map_upper(plt.scatter, s=10, alpha=0.5)\n",
    "        g.map_diag(sns.distplot, kde=False)\n",
    "        g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n",
    "        g.map_lower(corrfunc)\n",
    "    else:\n",
    "        pass\n",
    "drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3',\n",
    "                                        'dist_1', 'dist_2', 'dist_3', 'vsh_wavg_1', 'htst_sum_1', 'vsh_wavg_2', 'htst_sum_2', 'vsh_wavg_3', 'htst_sum_3','cluster']\n",
    "pairplot_special(test_2['khtst_data'].drop(drop_lst_X, axis=1), 7, 7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box cox to khtst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def khtst_workflow(cluster_list):\n",
    "\n",
    "    def dataset_for_spatial_prediction(dataset_full, dataset_cluster, offset_qty, cluster_algo, cluster_list):\n",
    "            \n",
    "            def joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list):\n",
    "                coordinates = dataset_full.groupby(['well','FORMATION_up'])[['X_mean','Y_mean']].apply(lambda x: x.iloc[0]).reset_index()\n",
    "                dataset_cluster = dataset_cluster[(dataset_cluster[cluster_algo].isin(cluster_list))]\n",
    "                result = dataset_cluster.set_index(['well','FORMATION_up']).join(coordinates.set_index(['well','FORMATION_up'])).reset_index()\n",
    "                coordinates = result[['well','FORMATION_up', 'X_mean', 'Y_mean']].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "                return coordinates, result\n",
    "            coordinates, dataset_cluster_xy = joining_coordinates(dataset_full, dataset_cluster, cluster_algo, cluster_list)\n",
    "            coordinates = coordinates[~coordinates.well.isin(['A14Y'])]\n",
    "\n",
    "            def well_distance_calculation(coordinates, fm):\n",
    "                coordinates_fm = coordinates[coordinates.FORMATION_up == fm]\n",
    "                df_distance_fm = pd.DataFrame(euclidean_distances(coordinates_fm[['X_mean', 'Y_mean']]), columns=list(coordinates_fm.well))\n",
    "                well_name_rows = coordinates_fm.well.reset_index().drop(['index'], axis=1)\n",
    "                result = df_distance_fm.join(well_name_rows).set_index('well').reset_index()\n",
    "                return result\n",
    "            well_dist_crosstable_8 = well_distance_calculation(coordinates, 'Balakhany VIII')\n",
    "\n",
    "            def offset_well_names_dist(dataset, offset_qty):\n",
    "                df_lst = []\n",
    "                for ind in range(len(dataset.well.unique())):\n",
    "                    off_well_series = dataset.iloc[ind]\n",
    "                    off_well_selected = pd.DataFrame(off_well_series)[1:].sort_values(by=ind)[:offset_qty+1].T\n",
    "                    off_well_selected['well'] = off_well_selected.columns[0]\n",
    "                    off_well_selected = off_well_selected.drop(columns= off_well_selected.well, axis=1)\n",
    "\n",
    "                    dist_titles = ['dist_' + str(num+1) for num in range(offset_qty)]\n",
    "                    well_titles = ['well_' + str(num+1) for num in range(offset_qty)]\n",
    "\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_selected.columns[:-1])):\n",
    "                        col = off_well_selected.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_selected = off_well_selected.rename(columns={col:dist_titles[i]})\n",
    "\n",
    "                    off_well_names = pd.DataFrame(col_names).T\n",
    "                    col_names = []\n",
    "                    for i in range(len(off_well_names.columns)):\n",
    "                        col = off_well_names.columns[i]\n",
    "                        col_names.append(col)\n",
    "                        off_well_names = off_well_names.rename(columns={col:well_titles[i]})\n",
    "                    \n",
    "                    concat_well_data = pd.concat([off_well_names.reset_index(drop=True), off_well_selected.reset_index(drop=True)], axis=1)\n",
    "                    df_lst.append(concat_well_data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_dist_data8 = offset_well_names_dist(well_dist_crosstable_8, offset_qty)\n",
    "\n",
    "            def offset_wells_features_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    data = dataset_dist[dataset_dist.well == wellname]\n",
    "                    cc = 0\n",
    "                    for j in data.columns:\n",
    "                        if 'well_' in j:\n",
    "                            cc += 1\n",
    "                            offset_wellname = data[j].values[0]\n",
    "                            data_cluster = dataset_clusters[(dataset_clusters.well == offset_wellname) & \n",
    "                                                                (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                            var_name = 'phit_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['phit_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'vsh_wavg_' + str(cc)\n",
    "                            data[var_name] = ((data_cluster['vsh_avg'] * data_cluster['htst']).sum()) / (data_cluster['htst'].sum())\n",
    "                            var_name = 'htst_sum_' + str(cc)\n",
    "                            data[var_name] = data_cluster['htst'].sum()                \n",
    "                    df_lst.append(data)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                result['FORMATION_up'] = fm\n",
    "                return result\n",
    "            well_features8 = offset_wells_features_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "\n",
    "            def target_wells_variable_calculation(dataset_dist, dataset_clusters, cluster_algo, cluster_list, fm):\n",
    "                df_lst = []\n",
    "                for wellname in dataset_dist.well.unique():\n",
    "                    df = pd.DataFrame({'well': [wellname], 'FORMATION_up': [fm], 'phit_wavg_target': [0]})\n",
    "                    data = dataset_clusters[(dataset_clusters.well == wellname) & \n",
    "                                            (dataset_clusters[cluster_algo].isin(cluster_list))]\n",
    "                    df['phit_wavg_target'] = ((data['phit_avg'] * data['htst']).sum()) / (data['htst'].sum())\n",
    "                    df_lst.append(df)\n",
    "                result = pd.concat(df_lst).reset_index(drop=True)\n",
    "                return result\n",
    "            well_target8 = target_wells_variable_calculation(well_dist_data8, dataset_cluster, cluster_algo, cluster_list, 'Balakhany VIII')\n",
    "            \n",
    "            dataset8 = well_target8.set_index(['well','FORMATION_up']).join(well_features8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "            result = {'dataset8':dataset8, 'cluster_xy':dataset_cluster_xy, 'well_dist8':well_dist_data8, 'coordinates':coordinates,\n",
    "                    'target8':well_target8, 'feature8':well_features8, 'dist_crosstable8':well_dist_crosstable_8}\n",
    "            return result\n",
    "    input_ph8 = dataset_for_spatial_prediction(df_bal_net2_kh, data_clustered8, 3, 'kmeans', cluster_list)['dataset8']\n",
    "    print(f'Dataset features {textwrap.fill(str(list(input_ph8.columns)), width=150)}')\n",
    "\n",
    "    def run_phit_pred_split(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            # model = selected_model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = np.array(y_test).flatten()\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print('features dataset: \\n', list(X_train.columns))\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('test \"in\":', '{:.2f}'.format(result['testqc'].round(2)),'\\t', model_name)\n",
    "            return result\n",
    "        def xplot_qc2(data, qc_train, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_train = data[data.dataset == 'train']\n",
    "            ds_test = data[data.dataset == 'test']\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors_tr = [colors[qc] for qc in ds_train.qc]\n",
    "            qc_colors_ts = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_train = go.Scatter( x=ds_train['y_orig'], y=ds_train['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_tr, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_train[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            scatter_test = go.Scatter(  x=ds_test[y_orig], y=ds_test[y_pred], \n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors_ts, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = data[['well', y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(f'train ds {qc_train}', f'test ds {qc_test}'))\n",
    "            fig.add_trace(scatter_train,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.add_trace(scatter_test,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=2)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=2)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=2)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=2)\n",
    "            fig.update_layout(  title_text= (comment), width=700, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        print(f'Cluster list is: {cluster_list}')   \n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_ph = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_ph = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_ph = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_ph = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_ph = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        # xplot_qc2(model1_ph['result'], model1_ph['trainqc'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc2(model2_ph['result'], model2_ph['trainqc'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc2(model3_ph['result'], model3_ph['trainqc'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc2(model4_ph['result'], model4_ph['trainqc'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model5_ph['result'], model5_ph['trainqc'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc2(model6_ph['result'], model6_ph['trainqc'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model_split = run_phit_pred_split(input_ph8, cluster_list, tolerance=0.05)['result']\n",
    "\n",
    "    def run_phit_pred_1_to_all(dataset, cluster_list, tolerance):\n",
    "        def model_prediction_1_to_all(dataset, selected_model, target, tolerance, model_name):\n",
    "            drop_lst_X = ['well','FORMATION_up', 'well_1', 'well_2', 'well_3']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "            print(model_name)\n",
    "            df_lst = []\n",
    "            for wellname in tqdm(dataset.well.unique()[:]):\n",
    "                train = dataset[dataset.well != wellname]\n",
    "                X_train_init = train.drop(target, axis=1)\n",
    "                y_train_init = train[['well','FORMATION_up', target]]\n",
    "                X_train = X_train_init.drop(drop_lst_X, axis=1)\n",
    "                y_train = y_train_init.drop(drop_lst_y, axis=1)\n",
    "                model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                test = dataset[dataset.well == wellname]\n",
    "                y_test_wnames = test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "                X_test_init = test.drop(target, axis=1)\n",
    "                y_test_init = test[['well','FORMATION_up', target]]\n",
    "                X_test = X_test_init.drop(drop_lst_X, axis=1)\n",
    "                y_test = y_test_init.drop(drop_lst_y, axis=1).values[0]\n",
    "                y_pred = model.predict(X_test)\n",
    "                test = pd.DataFrame(zip(y_test, y_pred), columns=['y_orig', 'y_pred'])\n",
    "                test = pd.concat([y_test_wnames, test], axis=1)\n",
    "                df_lst.append(test)\n",
    "                \n",
    "            result = pd.concat(df_lst).reset_index(drop=True)\n",
    "            result['up'] = result['y_orig']*(1 + tolerance)\n",
    "            result['down'] = result['y_orig']*(1 - tolerance)\n",
    "            result['qc'] = 'out'\n",
    "            result.loc[(result['y_pred'] <= result.up) & (result['y_pred'] >= result.down), 'qc'] = 'in'\n",
    "            resultqc = result.qc.value_counts(normalize=True)\n",
    "\n",
    "            phit_pred = result[['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "            dataset_pred = dataset.set_index(['well','FORMATION_up']).join(phit_pred.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "            result_dict = {'result':result, 'res_full':dataset_pred, 'testqc':resultqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            return result_dict\n",
    "        def xplot_qc_1_to_all(data, qc_test, y_orig, y_pred, max_val, rng, margin, round, comment):\n",
    "            data = data.round({y_orig: round, y_pred: round})\n",
    "            ds_test = data\n",
    "            up_range = rng + 1\n",
    "            dwn_range = 1 - rng\n",
    "            colors = {'in': 'green', 'out': 'red'}\n",
    "            qc_colors = [colors[qc] for qc in ds_test.qc]\n",
    "            scatter_test = go.Scatter( x=ds_test['y_orig'], y=ds_test['y_pred'],\n",
    "                                        mode='markers',\n",
    "                                        marker=dict(color=qc_colors, size=6, opacity=0.75, line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                                        customdata = ds_test[['well',y_orig, y_pred, 'FORMATION_up']],\n",
    "                                        hovertemplate=\"\".join(\n",
    "                                        [\"w:%{customdata[0]},a:%{customdata[1]}, p:%{customdata[2]}, f:%{customdata[3]}<extra></extra>\"])\n",
    "                                        )\n",
    "            line_trace_up = go.Scatter(x=[0, max_val], y=[0 + margin, max_val*up_range + margin], mode='lines+markers', line=dict(color='blue'))\n",
    "            line_trace_dw = go.Scatter(x=[0, max_val], y=[0 - margin, max_val*dwn_range - margin], mode='lines+markers', marker=dict(color='blue'))\n",
    "            fig = make_subplots(rows=1, cols=1, subplot_titles=(f'test qc {qc_test}',))\n",
    "            fig.add_trace(scatter_test,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_up,  row=1, col=1)\n",
    "            fig.add_trace(line_trace_dw,  row=1, col=1)\n",
    "            fig.update_xaxes(title_text='actual', row=1, col=1)\n",
    "            fig.update_yaxes(title_text='predict', row=1, col=1)\n",
    "            fig.update_layout(  title_text= (comment), width=350, height=350, \n",
    "                                margin=dict(l=10,r=10,b=10,t=50), showlegend=False)\n",
    "            return fig.show()\n",
    "\n",
    "        target = 'phit_wavg_target'\n",
    "        model1_ph = model_prediction_1_to_all(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance,'RandomForestRegressor')\n",
    "        # model2_ph = model_prediction_1_to_all(dataset, BayesianRidge(), target, 0.05, 'BayesianRidge')\n",
    "        # model3_ph = model_prediction_1_to_all(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, 0.05, 'XGBRegressor')\n",
    "        # model4_ph = model_prediction_1_to_all(dataset, CatBoostRegressor(random_state=42, verbose=False), target, 0.05,'CatBoostRegressor')\n",
    "        # model5_ph = model_prediction_1_to_all(dataset, AdaBoostRegressor(random_state=42), target, 0.05, 'AdaBoostRegressor')\n",
    "        # model6_ph = model_prediction_1_to_all(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, 0.05, 'LGBMRegressor')\n",
    "\n",
    "        # xplot_qc_1_to_all(model1_ph['result'], model1_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model2_ph['result'], model2_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model3_ph['result'], model3_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model4_ph['result'], model4_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model5_ph['result'], model5_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        # xplot_qc_1_to_all(model6_ph['result'], model6_ph['testqc'], 'y_orig', 'y_pred', 0.3, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_ph\n",
    "    model = run_phit_pred_1_to_all(input_ph8, cluster_list, tolerance=0.05)\n",
    "\n",
    "    def concat_prediction_to_khtst_df(data_pred, data_khtst, data_main, cluster_algo):\n",
    "        phit_pred8 = data_pred['result'][['well','FORMATION_up','y_pred']].rename(columns={'y_pred':'phit_pred'})\n",
    "        khtst8 = data_khtst[data_khtst[cluster_algo].isin(cluster_list)].groupby(['well','FORMATION_up'])['khtst'].sum().reset_index()\n",
    "\n",
    "        khtst8_phit_pred8 = khtst8.set_index(['well','FORMATION_up']).join(phit_pred8.set_index(['well','FORMATION_up'])).reset_index()\n",
    "\n",
    "        phitpred_khtst = khtst8_phit_pred8.set_index(['well','FORMATION_up']).join(data_main.set_index(['well','FORMATION_up']), how='inner').reset_index()\n",
    "\n",
    "        phitpred_khtst.insert(19, 'phit_pred', phitpred_khtst.pop('phit_pred'))\n",
    "        phitpred_khtst.insert(19, 'phit_wavg_target', phitpred_khtst.pop('phit_wavg_target'))\n",
    "        phitpred_khtst.insert(19, 'khtst', phitpred_khtst.pop('khtst'))\n",
    "        return phitpred_khtst\n",
    "    phitpred_khtst = concat_prediction_to_khtst_df(model, data_clustered8, input_ph8, 'kmeans')\n",
    "    print(f'Concat dataset features {textwrap.fill(str(list(phitpred_khtst.columns)), width=150)}')\n",
    "\n",
    "    def boxcox_transform(dataset, var):\n",
    "        result, lam = boxcox(dataset[var])\n",
    "        dataset['khtst_boxcox'] = result\n",
    "        return dataset, lam\n",
    "    phitpred_khtst_boxcox, lam = boxcox_transform(phitpred_khtst, 'khtst')\n",
    "\n",
    "    print('\\nPrediction KHtst: ')\n",
    "    def run_khtst_pred_split(dataset, cluster_list, max_range, tolerance, lam):\n",
    "        def model_prediction_split(dataset, selected_model, target, tolerance, model_name, display_flag='display'):\n",
    "            \"\"\"\n",
    "            'well', 'FORMATION_up', 'well_1', 'well_2', 'well_3', 'dist_1',\n",
    "            'dist_2', 'dist_3', 'phit_wavg_1', 'vsh_wavg_1', 'htst_sum_1',\n",
    "            'phit_wavg_2', 'vsh_wavg_2', 'htst_sum_2', 'phit_wavg_3', 'vsh_wavg_3',\n",
    "            'htst_sum_3', 'phit_pred', 'phit_wavg_target', 'khtst'\n",
    "            \"\"\"\n",
    "            drop_lst_X = ['well','FORMATION_up',    'well_1', 'well_2', 'well_3', 'dist_1', 'dist_2','dist_3', 'phit_wavg_target', 'khtst']\n",
    "            drop_lst_y = ['well','FORMATION_up']\n",
    "\n",
    "            X = dataset.drop(target, axis=1)\n",
    "            y = dataset[['well','FORMATION_up', target]]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)\n",
    "\n",
    "            y_train_wnames = y_train[['well','FORMATION_up']].reset_index(drop=True)\n",
    "            y_test_wnames = y_test[['well','FORMATION_up']].reset_index(drop=True)\n",
    "\n",
    "            X_train = X_train.drop(drop_lst_X, axis=1)\n",
    "            X_test = X_test.drop(drop_lst_X, axis=1)\n",
    "            y_train = y_train.drop(drop_lst_y, axis=1)\n",
    "            y_test = y_test.drop(drop_lst_y, axis=1)\n",
    "\n",
    "            model = Pipeline([(\"scaler\",StandardScaler()),(\"model\", selected_model)])\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_train = inv_boxcox(y_pred_train, lam)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_pred_test = inv_boxcox(y_pred_test, lam)\n",
    "\n",
    "            y_train = inv_boxcox(y_train, lam)\n",
    "            y_train = np.array(y_train).flatten()\n",
    "            y_test = inv_boxcox(y_test, lam)\n",
    "            y_test = np.array(y_test).flatten()\n",
    "\n",
    "            train = pd.DataFrame(zip(y_train,y_pred_train), columns=['y_orig', 'y_pred'])\n",
    "            train = pd.concat([y_train_wnames, train], axis=1)\n",
    "            test = pd.DataFrame(zip(y_test,y_pred_test), columns=['y_orig', 'y_pred'])\n",
    "            test = pd.concat([y_test_wnames, test], axis=1)\n",
    "            \n",
    "\n",
    "            train['up'] = train['y_orig']*(1 + tolerance)\n",
    "            train['down'] = train['y_orig']*(1 - tolerance)\n",
    "            train['qc'] = 'out'\n",
    "            train['dataset'] = 'train'\n",
    "            train.loc[(train['y_pred'] <= train.up) & (train['y_pred'] >= train.down), 'qc'] = 'in'\n",
    "            trainqc = train.qc.value_counts(normalize=True)\n",
    "\n",
    "            test['up'] = test['y_orig']*(1 + tolerance)\n",
    "            test['down'] = test['y_orig']*(1 - tolerance)\n",
    "            test['qc'] = 'out'\n",
    "            test['dataset'] = 'test'\n",
    "            test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "            testqc = test.qc.value_counts(normalize=True)\n",
    "            df = pd.concat([train, test])\n",
    "            df['y_pred'] = df['y_pred'].astype('float')\n",
    "\n",
    "            result = {'result':df, 'testqc':testqc['in'].round(2), 'trainqc':trainqc['in'].round(2), 'train_df':X_train.columns, 'model': model}\n",
    "            if display_flag == 'display':\n",
    "                print(f'features dataset: {list(X_train.columns)}')\n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            else: \n",
    "                print('train \"in\":', '{:.2f}'.format(result['trainqc'].round(2)),\n",
    "                    'test \"in\":', '{:.2f}'.format(result['testqc'].round(2)), \n",
    "                    '\\t', model_name)\n",
    "            return result\n",
    "        print(f'Cluster list is: {cluster_list}')\n",
    "        target = 'khtst_boxcox'\n",
    "        model1_kh = model_prediction_split(dataset, RandomForestRegressor(n_jobs=-1, random_state=42), target, tolerance, 'RandomForestRegressor','display')\n",
    "        model2_kh = model_prediction_split(dataset, BayesianRidge(), target, tolerance, 'BayesianRidge', 'dont_display')\n",
    "        model3_kh = model_prediction_split(dataset, XGBRegressor(n_jobs=-1, random_state=42, verbosity=0), target, tolerance, 'XGBRegressor', 'dont_display')\n",
    "        model4_kh = model_prediction_split(dataset, CatBoostRegressor(random_state=42, verbose=False), target, tolerance, 'CatBoostRegressor', 'dont_display')\n",
    "        model5_kh = model_prediction_split(dataset, AdaBoostRegressor(random_state=42), target, tolerance, 'AdaBoostRegressor', 'dont_display')\n",
    "        model6_kh = model_prediction_split(dataset, LGBMRegressor(n_jobs=-1, random_state=42, verbose=0, verbosity=-1), target, tolerance, 'LGBMRegressor', 'dont_display')\n",
    "\n",
    "        xplot_qc2(model1_kh['result'], model1_kh['trainqc'], model1_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'RandomForestRegressor {cluster_list}')\n",
    "        xplot_qc2(model2_kh['result'], model2_kh['trainqc'], model2_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'BayesianRidge {cluster_list}')\n",
    "        xplot_qc2(model3_kh['result'], model3_kh['trainqc'], model3_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'XGBRegressor {cluster_list}')\n",
    "        xplot_qc2(model4_kh['result'], model4_kh['trainqc'], model4_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'CatBoostRegressor {cluster_list}')\n",
    "        xplot_qc2(model5_kh['result'], model5_kh['trainqc'], model5_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'AdaBoostRegressor {cluster_list}')\n",
    "        xplot_qc2(model6_kh['result'], model6_kh['trainqc'], model6_kh['testqc'], 'y_orig', 'y_pred', max_range, tolerance, 0, 3, f'LGBMRegressor {cluster_list}')\n",
    "        return model1_kh\n",
    "    model_khtst = run_khtst_pred_split(phitpred_khtst_boxcox, cluster_list, 27000, 0.25, lam)\n",
    "    result = {'khtst_pred':model_khtst['result'], 'khtst_data':phitpred_khtst, 'phit_pred':model['result'], 'boxcox':lam}\n",
    "\n",
    "    return result\n",
    "test_full = khtst_workflow(cluster_list = [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = test_0['khtst_data']\n",
    "test1 = test_1['khtst_data']\n",
    "test2 = test_2['khtst_data']\n",
    "test0['cluster'] = 0\n",
    "test1['cluster'] = 1\n",
    "test2['cluster'] = 2\n",
    "result = pd.concat([test0, test1, test2])\n",
    "custom_palette = {0:'blue', 1: 'green', 2: 'red'}\n",
    "sns.histplot(result, x='khtst', hue='cluster', log_scale=(True), kde=True, bins=30, palette=custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ph8 = input_ph8.sample(frac=1, random_state=42)\n",
    "# test = model1_ph['model'].predict(input_ph8.iloc[:,6:])\n",
    "# test_df = pd.DataFrame({'y_pred':test})\n",
    "# input_ph8_v2 = pd.concat([input_ph8, test_df], axis=1)\n",
    "# plt.scatter(input_ph8_v2.phit_wavg_target, input_ph8_v2.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def polynomial_regression(dataset, x_var, y_var, degree):\n",
    "#     x = np.array(dataset[x_var])\n",
    "#     y = np.array(dataset[y_var])\n",
    "    \n",
    "#     # coefficients = np.polyfit(x, y, degree)\n",
    "#     # poly_function = np.poly1d(coefficients)\n",
    "#     # y_pred = poly_function(x)\n",
    "\n",
    "#     x = x[:, np.newaxis]\n",
    "#     coefficients = PolynomialFeatures(degree)\n",
    "#     x_poly = coefficients.fit_transform(x)\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(x_poly, y)\n",
    "#     y_pred = model.predict(x_poly)\n",
    "\n",
    "#     y_test_wnames = dataset[['well','FORMATION_up']]\n",
    "#     test = pd.DataFrame(zip(dataset['khtst'],y_pred), columns=['y_orig', 'y_pred'])\n",
    "#     test = pd.concat([y_test_wnames, test], axis=1)\n",
    "\n",
    "#     test['up'] = test['y_orig']*(1 + tolerance)\n",
    "#     test['down'] = test['y_orig']*(1 - tolerance)\n",
    "#     test['qc'] = 'out'\n",
    "#     test.loc[(test['y_pred'] <= test.up) & (test['y_pred'] >= test.down), 'qc'] = 'in'\n",
    "#     testqc = test.qc.value_counts(normalize=True)['in']\n",
    "#     print(f'precent of \"in\" {testqc:.2f}')\n",
    "\n",
    "#     plt.scatter(x, y, color='blue', label='Data')\n",
    "#     plt.scatter(x, y_pred, color='red', label='Polynomial Fit')\n",
    "#     plt.xlabel(x_var)\n",
    "#     plt.ylabel(y_var)\n",
    "#     plt.title('Polynomial Regression')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     return y_pred, coefficients\n",
    "# y_pred, coefficients = polynomial_regression(phitpred_khtst, 'phit_wavg_target', 'khtst', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking KHtst based on df_bal_net2_kh\n",
    "khtst_rows = df_bal_net2_kh[df_bal_net2_kh.KHtst.notna()].groupby(['well','FORMATION_up']).apply(lambda x: x.iloc[0]).reset_index(drop=True)[\n",
    "                                                                  ['well','FORMATION_up','KHtst']]\n",
    "khtst_rows8 = khtst_rows[khtst_rows.FORMATION_up == 'Balakhany VIII']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check gas oil density & porosity\n",
    "gas_wells = df_bal_net2_kh[(df_bal_net2_kh.FLUIDS == 1) & (df_bal_net2_kh.FORMATION_up == 'Balakhany VIII')]\n",
    "oil_wells = df_bal_net2_kh[(df_bal_net2_kh.FLUIDS == 2) & (df_bal_net2_kh.FORMATION_up == 'Balakhany VIII')]\n",
    "test = pd.concat([gas_wells, oil_wells])[['well','FORMATION_up','FLUIDS','PHIT']]\n",
    "custom_palette = {1: 'red', 2: 'green'}\n",
    "sns.histplot(data=test, x='PHIT', hue='FLUIDS', kde=True,  bins=35, palette=custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification dataset for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\Abnormal_PHIT_VSH_samples.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal.well.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Большинство проблем связано с тем, что запись ГК есть, а ГГКп нет т.е. нет Кп. \n",
    "# Надо исключить из обучающей выборки все скважин CHIRAG  и GCA.\n",
    "# Остальные особенности прокомментированы ниже.\n",
    "# C33 - небольшой брак по ГК в инт 1626-1630, убрак браковые блок\n",
    "# A17ST1 - аномально низкая ГК и Кгл, убрать из выборки целиком\n",
    "# CHIRAG6 - полный брак запики ГГКп, убрать целиком\n",
    "# C03Z - что то непонятное в интервале 1000-1010, надо удалить этот блок из трейнинг сета, 1055-1065 брак записи ГГКп-НК\n",
    "# E39 - небольшой рассинхрон по глубине на 2415-2417.5, обратить внимание\n",
    "# A20 - брак записи ГГКп в инт 320-335, убрак блок\n",
    "# GCA1 - полный брак записи ГГКп, убрать целиком\n",
    "# A12W - коллектор на 300-310 перебит огромным плотняком на 7.5м примерно, блок удалить из обучения\n",
    "# B22 - брак записи ГГКп в инт 1935-1950, удалить блок из выборк\n",
    "# GCA6Y - брак записи ГГКп, убрать целиком\n",
    "# A12V - мощные плотняки в коллекторах в инт 42-57, удалить блок из выборки\n",
    "# C01 - брак записи ГГКп в инт 2310-2330, удалить блок из выборк\n",
    "# G01Y - срывы на запики ГГКп из за чего Кп=0, срывы надо заполнить средними значениями Кп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверить еще раз скважины до A17ST1\n",
    "def abnormnal_display(dataset, wellname):\n",
    "    test = dataset[(dataset.well == wellname)]\n",
    "    fig, ax = plt.subplots(figsize=(2,6))\n",
    "    ax.plot(test.PHIT, test.TST, c='green', linestyle='dashed', lw=2, zorder=1)\n",
    "    ax.vlines(0.13, ymin=min(test.TST), ymax=max(test.TST), color='green', linestyle='dashed', lw=1)\n",
    "    twin = ax.twiny()\n",
    "    twin.plot(test.VSH, test.TST, color='lightgreen', alpha=0.8, zorder=2)\n",
    "    twin.set_xlim(-0.1, 1.1)\n",
    "    ax.set_xlim(0, 0.3)\n",
    "    ax.invert_yaxis()\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_title(wellname)\n",
    "    ax.grid()\n",
    "wellname = 'E39'\n",
    "abnormnal_display(abnormal, wellname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_display_khtst_v2( dataset, wellname, fmname, net_var, comments, ref_depth, fm_flag, depth_step, kh_include, print):\n",
    "    \"\"\"\n",
    "    dataset = df_bal or something else\n",
    "    net_var = NET or FLUIDS_int\n",
    "    comments = put what you want\n",
    "    ref_depth = MD or TST\n",
    "    fm_flag = 1 if you need a FORMATION_up, 0 if just a simple FORMATION\n",
    "    depth_step = step for ticks on the diagramm\n",
    "    kh_include = 1 if we have KHtst in dataset, 0 if there is not KHtst\n",
    "    print = 1 if we want to print the plot\n",
    "    \"\"\"\n",
    "    if fm_flag == 0:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION == fmname)]\n",
    "    if fm_flag == 1:\n",
    "        data = dataset[(dataset.well==wellname) & (dataset.FORMATION_up == fmname)]\n",
    "    depth = data[ref_depth]\n",
    "    grn = data['GR_N']\n",
    "    vsh = data['VSH']\n",
    "    rhob = data['RHOB'] \n",
    "    npss = data['NPSS']\n",
    "    rdeep = data['RDEEP']\n",
    "    phit = data['PHIT'] \n",
    "    net = data[net_var]\n",
    "    perm = data['LPERM']\n",
    "    if kh_include == 1:\n",
    "        kh = data['KHtst']\n",
    "    else:\n",
    "        data['KHtst'] = 0\n",
    "        kh = data['KHtst']\n",
    "    fig, ax = plt.subplots(1,4, figsize=(7,7), sharey=True)\n",
    "    well_bal_tops = df_bal[(df_bal.well == wellname)].groupby('FORMATION')[ref_depth].apply(lambda x: x.iloc[0]).reset_index()\n",
    "    ax[0].yaxis.set_ticks(np.arange(min(depth), max(depth), depth_step))\n",
    "    ax[0].plot(grn, depth, color='lightgreen', lw=3, zorder=10)\n",
    "    ax[0].invert_yaxis() \n",
    "    ax[0].set_xlim(-5, 150) \n",
    "    ax[0].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[0].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "                    xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "    twin0 = ax[0].twiny()\n",
    "    twin0.plot(vsh, depth, color='black', alpha=0.5, zorder=5)\n",
    "    twin0.vlines(0.5, ymin=min(depth), ymax=max(depth), color='black', lw=1, linestyle='dashed')\n",
    "    twin0.set_xlim(-0.1, 1.25)\n",
    "    ax[1].plot(rhob, depth, color='red') \n",
    "    ax[1].invert_yaxis() \n",
    "    ax[1].xaxis.set_ticks(np.arange(1.65, 2.65, 0.3))\n",
    "    ax[1].set_xlim(1.65, 2.65)\n",
    "    ax[1].grid(axis='y'), ax[1].grid(axis='x')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[1].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], \n",
    "        xmin=0, xmax=150, linewidth=2, color='black', lw=2, alpha=0.33)\n",
    "        ax[1].text(1.67, well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0]+0.5*depth_step, i, fontsize = 7, color =\"black\")\n",
    "    twin1 = ax[1].twiny()\n",
    "    twin1.plot(npss, depth, color='blue')\n",
    "    twin1.set_xlim(0.6, 0)\n",
    "    # ax[2].plot(rdeep, depth, color='black'), ax[2].set_xscale('log'), ax[2].set_xlim(0.1, 50), ax[2].invert_yaxis(), ax[2].grid(axis='x', which='both')\n",
    "    ax[2].plot(phit, depth, color='green', linestyle='dashed'), ax[2].set_xlim(0.3, 0), ax[2].grid(axis='x'), ax[2].set_xticks([0, 0.1, 0.2, 0.3]) \n",
    "    ax[2].invert_yaxis()\n",
    "    ax[2].grid(axis='y')\n",
    "    ax[2].vlines(0.13, ymin=min(depth), ymax=max(depth), color='black', linestyle='dashed')\n",
    "    twin2 = ax[2].twiny()\n",
    "    twin2.plot(net, depth, color='orange', linewidth=0.5)\n",
    "    twin2.fill_betweenx(depth,net, color='orange', alpha=0.33)\n",
    "    twin2.set_xlim(0, 1)\n",
    "    twin2.set_ylim(min(depth), max(depth))\n",
    "    ax[3].plot(perm, depth, color='purple', alpha=0.66), ax[3].set_xscale('log'), ax[3].set_xlim(0.1, 1000)\n",
    "    ax[3].invert_yaxis()\n",
    "    ax[3].grid(axis='y')\n",
    "    for i in well_bal_tops[well_bal_tops.FORMATION.str.contains(fmname)].FORMATION:\n",
    "        ax[3].hlines(well_bal_tops[well_bal_tops.FORMATION==i][ref_depth].iloc[0], xmin=0, xmax=1000, linewidth=2, color='black', lw=2, alpha=0.66)\n",
    "    twin4 = ax[3].twiny()\n",
    "    twin4.plot(kh, depth, color='black', alpha=1)\n",
    "    fig.suptitle(wellname + ' ' + fmname + ' ' + ref_depth + ' ' + str(round(max(kh.dropna()),0)) + ' ' + str(comments), fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    if print == 1:\n",
    "        path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\wellplots\\\\'\n",
    "        fig.savefig(path + fmname.replace(' ','') + '_' + wellname + '.png')\n",
    "    else:\n",
    "        pass\n",
    "wellname = 'C15'\n",
    "well_display_khtst_v2(df_bal_net2_kh, wellname, 'Balakhany VIII', 'NET_clp2', 'test', 'TST', 1, 10, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_tst_per_platform(fm):\n",
    "    df_lst = []\n",
    "    for platform in df_bal_net2_kh.field.unique():\n",
    "        data = df_bal_net2_kh[(df_bal_net2_kh.field == platform) & (df_bal_net2_kh.FORMATION_up == fm)]\n",
    "        test = data.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1] - x.iloc[0]).reset_index()\n",
    "        df = pd.DataFrame({'platform':platform, 'TST_mean':test.groupby('FORMATION')['TST'].mean()}).reset_index()\n",
    "        df['TST_mean'] = df['TST_mean'].round(0) \n",
    "        df = df[['platform', 'FORMATION', 'TST_mean']] \n",
    "        df_lst.append(df)\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    return result\n",
    "calculation_tst_per_platform('Balakhany VIII')\n",
    "# calculation_tst_per_platform('Balakhany X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopandas Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf1 = np.loadtxt('C:\\jupyter\\SPP\\input\\surfaces\\PW_H10_Dec22_CACI_5176_M400000_QLSKPrSDM_SCF_balVIIIs_ismat4')\n",
    "# X = surf1[:,0] \n",
    "# Y = surf1[:,1] \n",
    "# Z = surf1[:,2]\n",
    "# plt.scatter(X,Y, c=Z)\n",
    "# plt.colorbar(label='depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_linestringz_polygon(dataset):\n",
    "    geom = [x for x in dataset.geometry]\n",
    "    df_lst = []\n",
    "    for i in range(len(geom)):\n",
    "        all_coords = mapping(geom[i])['coordinates']\n",
    "        lats = [x[1] for x in all_coords]\n",
    "        lons = [x[0] for x in all_coords]\n",
    "        polyg = Polygon(zip(lons, lats))\n",
    "        df = gpd.GeoDataFrame(index=[0], crs='EPSG:2499', geometry=[polyg])\n",
    "        df_lst.append(df)\n",
    "    result = pd.concat(df_lst).reset_index(drop=True)\n",
    "    return result \n",
    "\n",
    "bal8_1510_3 = gpd.read_file(r'C:\\jupyter\\SPP\\input\\surfaces\\petrel\\BalakhanyVIII_1510_base_3.shp').set_crs('EPSG:2499')\n",
    "bal8_20_3 = gpd.read_file(r'C:\\jupyter\\SPP\\input\\surfaces\\petrel\\BalakhanyVIII_20_base_3.shp').set_crs('EPSG:2499')\n",
    "bal8_30_3 = gpd.read_file(r'C:\\jupyter\\SPP\\input\\surfaces\\petrel\\BalakhanyVIII_30_base_3.shp').set_crs('EPSG:2499')\n",
    "bal8_1510_3_polygon = convert_linestringz_polygon(bal8_1510_3)\n",
    "bal8_20_3_polygon = convert_linestringz_polygon(bal8_20_3)\n",
    "bal8_30_3_polygon = convert_linestringz_polygon(bal8_30_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CHIRAG', 'CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI', 'DWG', 'DDGG', 'WEST CHIRAG'\n",
    "def polygon_by_field(dataset, field, buffer):\n",
    "    data = dataset[dataset.FORMATION_up == 'Balakhany VIII'][['well','X_mean','Y_mean','field']]\n",
    "    data = data[data.field == field]\n",
    "    data = data.drop('field', axis=1).groupby('well').mean().reset_index()\n",
    "    geometry_fld = [Point(xy) for xy in zip(data['X_mean'], data['Y_mean'])]\n",
    "    data = gpd.GeoDataFrame(data, geometry=geometry_fld).drop(['X_mean','Y_mean'], axis=1)\n",
    "    buffers_fld = data.buffer(buffer)\n",
    "    buffers_fld = gpd.GeoDataFrame(geometry=buffers_fld)\n",
    "    data = data.join(buffers_fld, rsuffix='_polygon')\n",
    "    data = gpd.GeoDataFrame(data, geometry='geometry_polygon').set_crs('EPSG:2499')\n",
    "    field_polygon = gpd.GeoSeries(data['geometry_polygon'].unary_union.convex_hull)\n",
    "    return field_polygon\n",
    "dwg = polygon_by_field(df_bal_net2_kh, 'DWG', 500)\n",
    "chirag = polygon_by_field(df_bal_net2_kh, 'CHIRAG', 500)\n",
    "wchirag = polygon_by_field(df_bal_net2_kh, 'WEST CHIRAG', 500)\n",
    "cazeri = polygon_by_field(df_bal_net2_kh, 'CENTRAL AZERI', 500)\n",
    "wazeri = polygon_by_field(df_bal_net2_kh, 'WEST AZERI', 500)\n",
    "eazeri = polygon_by_field(df_bal_net2_kh, 'EAST AZERI', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_polygons_n_points(dataset, fm):\n",
    "    bdl8_xy = dataset[dataset.FORMATION_up == fm][['well','X_mean','Y_mean']]\n",
    "    bdl8_xy = bdl8_xy.groupby('well').mean().reset_index()\n",
    "    geometry = [Point(xy) for xy in zip(bdl8_xy['X_mean'], bdl8_xy['Y_mean'])]\n",
    "    bdl8_xy_gpd = gpd.GeoDataFrame(bdl8_xy, geometry=geometry).drop(['X_mean','Y_mean'], axis=1)\n",
    "\n",
    "    buffers = bdl8_xy_gpd.buffer(250)\n",
    "    buffers = gpd.GeoDataFrame(geometry=buffers)\n",
    "    bdl8_xy_gpd = bdl8_xy_gpd.join(buffers, rsuffix='_polygon')\n",
    "    bdl8_xy_buff = gpd.GeoDataFrame(bdl8_xy_gpd, geometry='geometry_polygon').drop('geometry', axis=1).set_crs('EPSG:2499')\n",
    "    bdl8_xy_points = gpd.GeoDataFrame(bdl8_xy_gpd, geometry='geometry').drop('geometry_polygon', axis=1).set_crs('EPSG:2499')\n",
    "\n",
    "    fields_polyg_hull = gpd.GeoSeries(bdl8_xy_buff.unary_union.convex_hull)\n",
    "    return bdl8_xy_buff, bdl8_xy_points, fields_polyg_hull\n",
    "bdl8_xy_buff, bdl8_xy_points, fields_polyg_hull = draw_polygons_n_points(df_bal_net2_kh, 'Balakhany VIII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_khtst_by_fu():\n",
    "    well_lst = df_bal_net2_kh[(df_bal_net2_kh.field.isin(['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI'])) & \n",
    "                            (df_bal_net2_kh.FORMATION.str.contains('Balakhany VIII')) & (df_bal_net2_kh.KHtst.notna())]\n",
    "    result_well_lst = well_lst.groupby(['well','FORMATION'])['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    result_well_lst_sum = result_well_lst.groupby('FORMATION')['KHtst'].sum().reset_index()\n",
    "    result_well_lst_sum = result_well_lst_sum.sort_values(by='KHtst', ascending=False)\n",
    "    return result_well_lst_sum\n",
    "calc_khtst_by_fu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_into_bal8_25_3 = gpd.sjoin(bdl8_xy_points, bal8_30_3_polygon, op='within')\n",
    "\n",
    "def gpd_polygons_wells(geobody_polygons, wells_points_df, title):\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    geobody_polygons.plot(ax=ax, color='yellow', label='bal8_1510_3', alpha=0.66)\n",
    "\n",
    "    wells_points_df[['well','geometry']].plot(ax=ax, color='black', marker='*', markersize = 50, alpha=0.5, ec='black')\n",
    "    # bdl8_xy_buff.plot(ax=ax, color='green', label='wells', alpha=0.5)\n",
    "    bdl8_xy_points.plot(ax=ax, markersize = 1, color='black', label='wells', alpha=1)\n",
    "\n",
    "    # fields_polyg_hull.plot(ax=ax, alpha=0.25, label='ACG polygon')\n",
    "    \n",
    "    dwg.plot(ax=ax, alpha=0.25, color = 'orange', label='dwg')\n",
    "    chirag.plot(ax=ax, alpha=0.25, color = 'red', label='chirag')\n",
    "    wchirag.plot(ax=ax, alpha=0.25, color = 'purple', label='chirag')\n",
    "    cazeri.plot(ax=ax, alpha=0.25, color = 'green', label='c azeri')\n",
    "    wazeri.plot(ax=ax, alpha=0.25, color = 'blue', label='w azeri')\n",
    "    eazeri.plot(ax=ax, alpha=0.25, color = 'turquoise', label='e azeri')\n",
    "    # ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "gpd_polygons_wells(bal8_30_3_polygon, well_into_bal8_25_3, 'Polygons of Balakhany VIII 30 body #3 & wells (buffer 250m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wells_in_out_polygon(dataset, wells_points_df, flow_units, title):   \n",
    "    geobody_well_lst = wells_points_df.well.values\n",
    "\n",
    "    well_lst = dataset[(dataset.field.isin(['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI'])) \n",
    "                       & (dataset.FORMATION.isin(flow_units))]\n",
    "    well_in_geob =  well_lst[well_lst.well.isin(geobody_well_lst)]\n",
    "    well_out_geob =  well_lst[~well_lst.well.isin(geobody_well_lst)]\n",
    "\n",
    "    well_in_geob_khtst = well_in_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_in_geob_khtst['geobody'] = 'in'\n",
    "    well_out_geob_khtst = well_out_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_out_geob_khtst['geobody'] = 'out'\n",
    "    concat_df = pd.concat([well_in_geob_khtst, well_out_geob_khtst])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "    custom_palette = {'in': 'red', 'out': 'lightgreen'}\n",
    "    sns.kdeplot(concat_df, x='KHtst', hue='geobody', log_scale=False, palette=custom_palette, ax=ax[0])\n",
    "    sns.boxplot(concat_df, x=\"geobody\", y=\"KHtst\", palette=custom_palette, ax=ax[1])\n",
    "    ax[0].set_title(title)\n",
    "    ax[1].set_title(title)\n",
    "    ax[0].grid(which='both')\n",
    "    return wells_points_df, concat_df\n",
    "well_into_bal8_25_3, concat_df_25 = wells_in_out_polygon(df_bal_net2_kh, well_into_bal8_25_3,['Balakhany VIII 25'],\n",
    "                                                        'bal8_30_3 polygon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_into_bal8_20_3 = gpd.sjoin(bdl8_xy_points, bal8_20_3_polygon, op='within')\n",
    "\n",
    "def gpd_polygons_wells(geobody_polygons, wells_points_df, title):\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    geobody_polygons.plot(ax=ax, color='orange', label='bal8_1510_3', alpha=0.66)\n",
    "\n",
    "    wells_points_df[['well','geometry']].plot(ax=ax, color='black', marker='*', markersize = 50, alpha=0.5, ec='black')\n",
    "    # bdl8_xy_buff.plot(ax=ax, color='green', label='wells', alpha=0.5)\n",
    "    bdl8_xy_points.plot(ax=ax, markersize = 1, color='black', label='wells', alpha=1)\n",
    "\n",
    "    # fields_polyg_hull.plot(ax=ax, alpha=0.25, label='ACG polygon')\n",
    "    \n",
    "    dwg.plot(ax=ax, alpha=0.25, color = 'orange', label='dwg')\n",
    "    chirag.plot(ax=ax, alpha=0.25, color = 'red', label='chirag')\n",
    "    wchirag.plot(ax=ax, alpha=0.25, color = 'purple', label='chirag')\n",
    "    cazeri.plot(ax=ax, alpha=0.25, color = 'green', label='c azeri')\n",
    "    wazeri.plot(ax=ax, alpha=0.25, color = 'blue', label='w azeri')\n",
    "    eazeri.plot(ax=ax, alpha=0.25, color = 'turquoise', label='e azeri')\n",
    "    # ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "gpd_polygons_wells(bal8_20_3_polygon, well_into_bal8_20_3, 'Polygons of Balakhany VIII 20 body #3 & wells (buffer 250m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wells_in_out_polygon(dataset, wells_points_df, flow_units, title):   \n",
    "    geobody_well_lst = wells_points_df.well.values\n",
    "\n",
    "    well_lst = dataset[(dataset.field.isin(['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI'])) \n",
    "                       & (dataset.FORMATION.isin(flow_units))]\n",
    "    well_in_geob =  well_lst[well_lst.well.isin(geobody_well_lst)]\n",
    "    well_out_geob =  well_lst[~well_lst.well.isin(geobody_well_lst)]\n",
    "\n",
    "    well_in_geob_khtst = well_in_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_in_geob_khtst['geobody'] = 'in'\n",
    "    well_out_geob_khtst = well_out_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_out_geob_khtst['geobody'] = 'out'\n",
    "    concat_df = pd.concat([well_in_geob_khtst, well_out_geob_khtst])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "    custom_palette = {'in': 'red', 'out': 'lightgreen'}\n",
    "    sns.kdeplot(concat_df, x='KHtst', hue='geobody', log_scale=False, palette=custom_palette, ax=ax[0])\n",
    "    sns.boxplot(concat_df, x=\"geobody\", y=\"KHtst\", palette=custom_palette, ax=ax[1])\n",
    "    ax[0].set_title(title)\n",
    "    ax[1].set_title(title)\n",
    "    ax[0].grid(which='both')\n",
    "    return wells_points_df\n",
    "well_into_bal8_20_3 = wells_in_out_polygon(df_bal_net2_kh, well_into_bal8_20_3,['Balakhany VIII 20'],'bal8_20_3 polygon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_into_bal8_1510_3 = gpd.sjoin(bdl8_xy_points, bal8_1510_3_polygon, op='within')\n",
    "\n",
    "def gpd_polygons_wells(geobody_polygons, wells_points_df, title):\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    geobody_polygons.plot(ax=ax, color='red', label='bal8_1510_3', alpha=0.66)\n",
    "\n",
    "    wells_points_df[['well','geometry']].plot(ax=ax, color='black', marker='*', markersize = 50, alpha=0.5, ec='black')\n",
    "    # bdl8_xy_buff.plot(ax=ax, color='green', label='wells', alpha=0.5)\n",
    "    bdl8_xy_points.plot(ax=ax, markersize = 1, color='black', label='wells', alpha=1)\n",
    "\n",
    "    # fields_polyg_hull.plot(ax=ax, alpha=0.25, label='ACG polygon')\n",
    "    \n",
    "    dwg.plot(ax=ax, alpha=0.25, color = 'orange', label='dwg')\n",
    "    chirag.plot(ax=ax, alpha=0.25, color = 'red', label='chirag')\n",
    "    wchirag.plot(ax=ax, alpha=0.25, color = 'purple', label='chirag')\n",
    "    cazeri.plot(ax=ax, alpha=0.25, color = 'green', label='c azeri')\n",
    "    wazeri.plot(ax=ax, alpha=0.25, color = 'blue', label='w azeri')\n",
    "    eazeri.plot(ax=ax, alpha=0.25, color = 'turquoise', label='e azeri')\n",
    "    # ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "gpd_polygons_wells(bal8_1510_3_polygon, well_into_bal8_1510_3,'Polygons of Balakhany VIII 15 10 body #3 & wells (buffer 250m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wells_in_out_polygon(dataset, wells_points_df, flow_units, title):   \n",
    "    geobody_well_lst = wells_points_df.well.values\n",
    "\n",
    "    well_lst = dataset[(dataset.field.isin(['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI'])) \n",
    "                       & (dataset.FORMATION.isin(flow_units))]\n",
    "    well_in_geob =  well_lst[well_lst.well.isin(geobody_well_lst)]\n",
    "    well_out_geob =  well_lst[~well_lst.well.isin(geobody_well_lst)]\n",
    "\n",
    "    well_in_geob_khtst = well_in_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_in_geob_khtst['geobody'] = 'in'\n",
    "    well_out_geob_khtst = well_out_geob.groupby('well')['KHtst'].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "    well_out_geob_khtst['geobody'] = 'out'\n",
    "    concat_df = pd.concat([well_in_geob_khtst, well_out_geob_khtst])\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "    custom_palette = {'in': 'red', 'out': 'lightgreen'}\n",
    "    sns.kdeplot(concat_df, x='KHtst', hue='geobody', log_scale=False, palette=custom_palette, ax=ax[0])\n",
    "    sns.boxplot(concat_df, x=\"geobody\", y=\"KHtst\", palette=custom_palette, ax=ax[1])\n",
    "    ax[0].set_title(title)\n",
    "    ax[1].set_title(title)\n",
    "    ax[0].grid(which='both')\n",
    "    return wells_points_df\n",
    "well_into_bal8_1510_3 = wells_in_out_polygon(df_bal_net2_kh, well_into_bal8_1510_3, ['Balakhany VIII 15', 'Balakhany VIII 10'],\n",
    "                                             'bal8_1510_3 polygon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking results of CNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strench one curve to another one with python\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define two curves (arrays)\n",
    "curve1 = np.array([1, 2, 3, 4, 5])\n",
    "curve2 = np.array([1.5, 2.8, 3.3, 4.2, 4.9])\n",
    "\n",
    "# Normalize curves\n",
    "curve1_norm = curve1 / curve1.max()\n",
    "curve2_norm = curve2 / curve2.max()\n",
    "\n",
    "# Define a function to minimize the difference between the curves\n",
    "def objective(params):\n",
    "    scale, shift = params\n",
    "    return np.sum((curve2_norm - scale * curve1_norm - shift) ** 2)\n",
    "\n",
    "# Minimize the objective function to find scaling and shifting parameters\n",
    "initial_guess = [1.0, 0.0]  # Initial guess for scale and shift\n",
    "result = minimize(objective, initial_guess)\n",
    "\n",
    "# Extract scaling and shifting parameters\n",
    "scale, shift = result.x\n",
    "\n",
    "# Stretch curve1 to match curve2\n",
    "stretched_curve1 = scale * curve1 + shift\n",
    "\n",
    "print(\"Scaling factor:\", scale)\n",
    "print(\"Shift factor:\", shift)\n",
    "print(\"Stretched curve 1:\", stretched_curve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_by_depth_fm(dataset_logs, formation_name, step):\n",
    "    def interpolate_by_depth(one_well, formation_name, step):\n",
    "        one_well = one_well.sort_values(by='TST')\n",
    "        well_name = one_well[\"well\"].iloc[0]\n",
    "        data_range = np.floor((one_well[\"TST\"].max() - one_well[\"TST\"].min())/step)\n",
    "        starting_tst = one_well[\"TST\"].iloc[0]\n",
    "        new_TST_values = [starting_tst + i*0.1 for i in range(1,int(data_range))]\n",
    "        interp_X = interp1d(one_well['TST'], one_well['X_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_Y = interp1d(one_well['TST'], one_well['Y_traj'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_PHIT = interp1d(one_well['TST'], one_well['PHIT'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_TVD = interp1d(one_well['TST'], one_well['TVD_SCS'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_NET_clp2 = interp1d(one_well['TST'], one_well['NET_clp2'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_LPERM = interp1d(one_well['TST'], one_well['LPERM'], kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_KHtst = interp1d(one_well['TST'], one_well['KHtst'], kind='linear', fill_value=\"extrapolate\")\n",
    "        # Create a new DataFrame with the interpolated values for new TVD_SCS\n",
    "        new_data = {\n",
    "            'well': [well_name for _ in range(len(new_TST_values))],\n",
    "            'FORMATION_up': [formation_name for _ in range(len(new_TST_values))],\n",
    "            'tst_index': [_ for _ in range(len(new_TST_values))],\n",
    "            'TST': new_TST_values,\n",
    "            'X_traj': interp_X(new_TST_values),\n",
    "            'Y_traj': interp_Y(new_TST_values),\n",
    "            'PHIT': interp_PHIT(new_TST_values),\n",
    "            'TVD_SCS': interp_TVD(new_TST_values),\n",
    "            'NET_clp2': interp_NET_clp2(new_TST_values),\n",
    "            'LPERM': interp_LPERM(new_TST_values),\n",
    "            'KHtst': interp_KHtst(new_TST_values),\n",
    "        }\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        return new_df\n",
    "    df_lst = []\n",
    "    print(f'Start interpolation of {formation_name}')\n",
    "    for wellnames in tqdm(dataset_logs.well.unique()):\n",
    "        well_sel = dataset_logs[dataset_logs.well == wellnames]\n",
    "        well_interp = interpolate_by_depth(well_sel, formation_name, step)\n",
    "        df_lst.append(well_interp)\n",
    "    result = pd.concat(df_lst)\n",
    "    return result\n",
    "well_bal8_interp = interpolate_by_depth_fm(df_bal_net2_kh[(df_bal_net2_kh.FORMATION_up == 'Balakhany VIII')], 'Balakhany VIII', 0.1)\n",
    "well_bal8_interp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phit_aecod = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\df_bal_net2_kh_with_prediction.csv')\n",
    "phit_aecod8 = phit_aecod[phit_aecod.FORMATION_up == 'Balakhany VIII'].reset_index(drop=True)\n",
    "phit_aecod8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "phit_aecod8_v2 = phit_aecod8[['well', 'FORMATION_up', 'TST', 'PHIT_predicted', 'NET_clp2']]\n",
    "phit_aecod8_v2 = phit_aecod8_v2[phit_aecod8_v2.NET_clp2 == 1]\n",
    "phit_aecod8_v2['TST'] = phit_aecod8_v2['TST'].round(2)\n",
    "\n",
    "well_bal8_interp_v2 = well_bal8_interp[['well', 'FORMATION_up', 'TST', 'PHIT', 'NET_clp2']]\n",
    "well_bal8_interp_v2 = well_bal8_interp_v2[well_bal8_interp_v2.NET_clp2 == 1]\n",
    "well_bal8_interp_v2['TST'] = well_bal8_interp_v2['TST'].round(2)\n",
    "\n",
    "orig_pred = well_bal8_interp_v2.set_index(['well','TST']).join(phit_aecod8_v2.set_index(['well','TST']), rsuffix='_pred').reset_index()\n",
    "\n",
    "fields = df_bal_net2_kh[['well','field']].groupby('well').apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "orig_pred_fields = orig_pred.set_index('well').join(fields.set_index('well')).reset_index()\n",
    "azeri = orig_pred_fields[orig_pred_fields.field.str.contains('AZERI')]\n",
    "chirag = orig_pred_fields[~orig_pred_fields.field.str.contains('AZERI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_phit_c = 0\n",
    "max_phit_c = 0.35\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "sns.kdeplot(data = chirag, x='PHIT', y='PHIT_predicted', ax=ax[0], alpha=0.5)\n",
    "ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c], ls='--', color='red')\n",
    "ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c*0.95], ls='--', color='blue')\n",
    "ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c*1.05], ls='--', color='blue')\n",
    "ax[0].set_title('Chirag')\n",
    "ax[0].set_xlim(0.1, 0.35)\n",
    "ax[0].set_ylim(0.1, 0.35)\n",
    "min_phit_a = 0\n",
    "max_phit_a = 0.35\n",
    "sns.kdeplot(data=azeri, x='PHIT', y='PHIT_predicted', ax=ax[1], alpha=0.5)\n",
    "ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a], ls='--', color='red')\n",
    "ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a*0.95], ls='--', color='blue')\n",
    "ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a*1.05], ls='--', color='blue')\n",
    "ax[1].set_title('Azeri')\n",
    "ax[1].set_xlim(0.1, 0.35)\n",
    "ax[1].set_ylim(0.1, 0.35);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_phit_wavg_orig_pred():\n",
    "    def phit_wavg_calc(dataset, var):\n",
    "        phit_v2 = dataset[['well', 'FORMATION_up', 'TST', var, 'NET_clp2']]\n",
    "        phit_v2 = phit_v2[phit_v2.NET_clp2 == 1]\n",
    "        phit_v3 = phit_v2.groupby('well')['NET_clp2'].sum().reset_index()\n",
    "        phit_v3['NET_clp2'] = phit_v3['NET_clp2']*0.1\n",
    "        var2 = var + '_v2'\n",
    "        phit_v2[var2] = phit_v2[var] * 0.1 \n",
    "        phit_v4 = phit_v2.groupby('well')[var2].sum().reset_index()\n",
    "        phit_v5 = phit_v4.set_index('well').join(phit_v3.set_index('well')).reset_index()\n",
    "        phit_v5['phit_wavg'] = phit_v5[var2] / phit_v5['NET_clp2']\n",
    "        return phit_v5\n",
    "\n",
    "    phit_aecod8_v2 = phit_aecod8[['well', 'FORMATION_up', 'TST', 'PHIT_predicted', 'NET_clp2']]\n",
    "    phit_aecod8_v2 = phit_aecod8_v2[phit_aecod8_v2.NET_clp2 == 1]\n",
    "\n",
    "    well_bal8_interp_v2 = well_bal8_interp[['well', 'FORMATION_up', 'TST', 'PHIT', 'NET_clp2']]\n",
    "    well_bal8_interp_v2 = well_bal8_interp_v2[well_bal8_interp_v2.NET_clp2 == 1]\n",
    "\n",
    "    pred = phit_wavg_calc(phit_aecod8_v2, 'PHIT_predicted')\n",
    "    orig = phit_wavg_calc(well_bal8_interp_v2, 'PHIT')\n",
    "    fields = df_bal_net2_kh[['well','field']].groupby('well').apply(lambda x: x.iloc[0]).reset_index(drop=True)\n",
    "    orig_pred = orig.set_index('well').join(pred.set_index('well'), rsuffix='_pred').reset_index()\n",
    "    orig_pred_fields = orig_pred.set_index('well').join(fields.set_index('well')).reset_index()\n",
    "    azeri = orig_pred_fields[orig_pred_fields.field.str.contains('AZERI')]\n",
    "    chirag = orig_pred_fields[~orig_pred_fields.field.str.contains('AZERI')]\n",
    "    return chirag, azeri\n",
    "chirag, azeri = calculation_phit_wavg_orig_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phit_wavg_orig_pred_display():\n",
    "    min_phit_c = 0.16\n",
    "    max_phit_c = 0.26\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    sns.scatterplot(data=chirag, x='phit_wavg', y='phit_wavg_pred', hue='field', ax=ax[0])\n",
    "    ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c], ls='--', color='red', alpha=0.5)\n",
    "    ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c*0.95], ls='--', color='blue', alpha=0.5)\n",
    "    ax[0].plot([min_phit_c,max_phit_c], [min_phit_c,max_phit_c*1.05], ls='--', color='blue', alpha=0.5)\n",
    "    min_phit_a = 0.16\n",
    "    max_phit_a = 0.28\n",
    "    sns.scatterplot(data=azeri, x='phit_wavg', y='phit_wavg_pred', hue='field', ax=ax[1])\n",
    "    ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a], ls='--', color='red', alpha=0.5)\n",
    "    ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a*0.95], ls='--', color='blue', alpha=0.5)\n",
    "    ax[1].plot([min_phit_a,max_phit_a], [min_phit_a,max_phit_a*1.05], ls='--', color='blue', alpha=0.5);\n",
    "phit_wavg_orig_pred_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_orig_pred(wellname):\n",
    "    phit_orig = well_bal8_interp.copy()[['well', 'FORMATION_up', 'TST', 'PHIT','NET_clp2', 'LPERM', 'KHtst']]\n",
    "    phit_orig['TST'] = phit_orig['TST'].round(2)\n",
    "    phit_pred = phit_aecod8.copy()[['well', 'FORMATION_up', 'TST', 'PHIT_predicted','NET_clp2', 'LPERM', 'KHtst']]\n",
    "    phit_pred['TST'] = phit_pred['TST'].round(2)\n",
    "    phit_orig_pred = phit_orig.set_index(['well', 'TST']).join(phit_pred.set_index(['well', 'TST']), rsuffix='_pred').reset_index()\n",
    "    phit_orig_pred = phit_orig_pred.dropna(subset='PHIT_predicted')\n",
    "    phit_orig_pred = phit_orig_pred[phit_orig_pred.NET_clp2 == 1]\n",
    "    phit_orig_pred_well = phit_orig_pred[phit_orig_pred.well == wellname]\n",
    "    sns.histplot(phit_orig_pred_well.PHIT, color='blue', label='PHIT', alpha=0.5, kde=True)\n",
    "    sns.histplot(phit_orig_pred_well.PHIT_predicted, color='red', label='PHIT_pred', alpha=0.5, kde=True)\n",
    "    plt.legend()\n",
    "    plt.title(wellname)\n",
    "histo_orig_pred('C12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_gaussian_filter_run(dataset, var, percentage):\n",
    "    new_var = var + '_gaus_' + str(percentage)\n",
    "    def well_gaussian_filter(dataset, wellname, fmname, variable, percentage):  \n",
    "        data = dataset[dataset.well == wellname][variable]\n",
    "        var_name = variable + '_gaus_' + str(percentage)\n",
    "        coeff = percentage/100\n",
    "        sigma = int(round(len(data)*coeff, 0))\n",
    "        data = data.reset_index().drop('index', axis=1)\n",
    "        smoothed_data = gaussian_filter(data, sigma=sigma)\n",
    "        data[var_name] = smoothed_data\n",
    "        data['well'] = wellname\n",
    "        data['FORMATION_up'] = fmname\n",
    "        return data\n",
    "    df_lst = []\n",
    "    for wellname in dataset.well.unique():\n",
    "        smooth_data = well_gaussian_filter(dataset, wellname, 'Balakhany VIII', var,  percentage)\n",
    "        df_lst.append(smooth_data)\n",
    "    var_gaus_smooth = pd.concat(df_lst)[new_var].reset_index(drop=True)\n",
    "    result = pd.concat([dataset, var_gaus_smooth], axis=1)\n",
    "    return result\n",
    "phit_aecod8_v2 = well_gaussian_filter_run(phit_aecod8, 'PHIT_predicted', 0.5)\n",
    "\n",
    "def well_plots_phit_pred_matrix(dataset, platform, var_selected, lims, comment):\n",
    "    \"\"\"\n",
    "    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J']\n",
    "    \"\"\"\n",
    "    rows = 4\n",
    "    columns = 9\n",
    "    wells_letter = [wellname for wellname in dataset.well.unique() if wellname.startswith(platform)]\n",
    "    fig, ax = plt.subplots(rows,columns, figsize=(16,rows*3))\n",
    "    counter = 0\n",
    "    for j in range(0, rows):\n",
    "        for i in range(0, columns):\n",
    "            if counter < len(wells_letter):\n",
    "                well_data = dataset[dataset.well==wells_letter[counter]]\n",
    "                y_desired = well_data['TST']\n",
    "                x1 = well_data['PHIT']\n",
    "                x2 = well_data[var_selected]       \n",
    "                ax[j,i].plot(x1, y_desired, color='green', lw=0.75, alpha=1, zorder=1)\n",
    "                ax[j,i].set_xlim(lims)\n",
    "                twin = ax[j,i].twiny()\n",
    "                twin.plot(x2, y_desired, color='orange', lw=1.25, alpha=1, zorder=0)\n",
    "                twin.set_xlim(lims)\n",
    "                ax[j,i].set_title(wells_letter[counter] + comment)\n",
    "                ax[j,i].invert_yaxis()\n",
    "                ax[j,i].grid()\n",
    "                counter +=1\n",
    "    return plt.tight_layout()\n",
    "for letter in ['A']:\n",
    "    well_plots_phit_pred_matrix(phit_aecod8_v2, letter, 'PHIT_predicted_gaus_0.5', (0.08, 0.3), ' bal8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRcube testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from pykrige.rk import RegressionKriging\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pykrige.rk import Krige\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.float_format = lambda x: '%.5f' % x\n",
    "pd.options.display.max_columns = 15\n",
    "pd.options.display.max_rows = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal8_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal8_azr_v4.csv')\n",
    "df_bal8_v4.columns = df_bal8_v4.columns.str.lower()\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII sand','formation'] = '1_bal8_sand'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 25','formation'] = '2_bal8_25'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 20','formation'] = '3_bal8_20'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 15','formation'] = '4_bal8_15'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 10','formation'] = '5_bal8_10'\n",
    "df_bal8_v4.loc[df_bal8_v4.formation=='Balakhany VIII 5','formation'] = '6_bal8_5'\n",
    "well_phit_flag8 = df_bal8_v4[df_bal8_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal8_v4_flag = df_bal8_v4[df_bal8_v4.well.isin(well_phit_flag8)]\n",
    "\n",
    "df_bal10_v4 = pd.read_csv('C:\\jupyter\\SPP\\inputoutput\\general_logs\\df_bal10_vshclp2_v4.csv')\n",
    "df_bal10_v4.columns = df_bal10_v4.columns.str.lower()\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X sand','formation'] = '1_bal10_sand'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 50','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 40','formation'] = '2_bal10_40'\n",
    "df_bal10_v4.loc[df_bal10_v4.formation=='Balakhany X 20','formation'] = '3_bal10_20'\n",
    "well_phit_flag10 = df_bal10_v4[df_bal10_v4.phit_flag==1].groupby('well')['phit_flag'].apply(lambda x: x.iloc[0]).reset_index().well.unique()\n",
    "df_bal10_v4_flag = df_bal10_v4[df_bal10_v4.well.isin(well_phit_flag10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntd_top_phi_bot8_bp_v4 = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\layers\\ntd_top_phi_bot8_bp_v4.csv').drop('Unnamed: 0', axis=1)\n",
    "ntd_top_phi_bot8_bp_v4.columns = ntd_top_phi_bot8_bp_v4.columns.str.lower()\n",
    "ntd_top_phi_bot10_bp_v4 = pd.read_csv(r'C:\\jupyter\\SPP\\inputoutput\\layers\\ntd_top_phi_bot10_bp_v4.csv').drop('Unnamed: 0', axis=1)\n",
    "ntd_top_phi_bot10_bp_v4.columns = ntd_top_phi_bot10_bp_v4.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_dist_calc(dataset, fm):\n",
    "    data = dataset.groupby('well')[['xmean', 'ymean']].first().reset_index().dropna()\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['xmean', 'ymean']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well = distance_fm_well.reset_index()\n",
    "    dist_melt = distance_fm_well.melt(id_vars='well', \n",
    "                                var_name='well2', \n",
    "                                value_name='dist').rename(columns={'well':'well_offset', 'well2':'well'})\n",
    "    dist_melt = dist_melt[['well', 'well_offset', 'dist']]\n",
    "    dist_melt = dist_melt[dist_melt.dist != 0].sort_values(by=['well','dist'])\n",
    "    dist_melt['FORMATION_up'] = fm\n",
    "    return dist_melt\n",
    "\n",
    "dist_bal8 = well_dist_calc(df_bal8_v4_flag, 'Balakhany VIII')\n",
    "dist_bal10 = well_dist_calc(df_bal10_v4_flag, 'Balakhany X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "for wellname in dist_bal8.well.unique():\n",
    "    data = dist_bal8[dist_bal8.well == wellname].iloc[0:1]\n",
    "    df_lst.append(data)\n",
    "well_pairs = pd.concat(df_lst).reset_index(drop=True).drop_duplicates(subset=['dist'])\n",
    "well_pairs_v2 = well_pairs[well_pairs.dist < 500] # 235m is the max distance between wells selected by elbow plot with distance 500m\n",
    "# well_pairs.hist(column='dist', bins=50)\n",
    "well_pairs_v2.sort_values(by='dist', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 5))\n",
    "sns.lineplot(data=well_pairs_v2.sort_values(by='dist', ascending=False), x='well', y='dist')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "for wellname in dist_bal8.well.unique():\n",
    "    data = dist_bal8[dist_bal8.well == wellname].iloc[0:1]\n",
    "    df_lst.append(data)\n",
    "well_pairs = pd.concat(df_lst).reset_index(drop=True).drop_duplicates(subset=['dist'])\n",
    "well_pairs_v3 = well_pairs[well_pairs.dist < 230] # 235m is the max distance between wells selected by elbow plot with distance 500m\n",
    "# well_pairs.hist(column='dist', bins=50)\n",
    "well_pairs_v3 = well_pairs_v3.sort_values(by='dist', ascending=True).reset_index(drop=True)\n",
    "well_pairs_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_offset_comparison_dashboard_pairs(dataset_wells, dataset_layers, dist_df,  well_target, offset_qty, fm_name, print_flag):\n",
    "    offset_well_list = dist_df[dist_df.well == well_target].iloc[:offset_qty]['well_offset'].values.tolist()\n",
    "    # offset_well_list = dist_df[dist_df.well == well_target].iloc[:offset_qty]\n",
    "    well_list = [well_target] + offset_well_list\n",
    "    data_logs = dataset_wells[(dataset_wells.well.isin(well_list)) & (dataset_wells.phit != 0)]\n",
    "    data_layers = dataset_layers[   (dataset_layers.well.isin(well_list)) & \n",
    "                                    (dataset_layers.htst > 1)]\n",
    "    khtst_logs = data_logs.groupby(['well','formation'])[['khtst']].apply(lambda x: x.iloc[0] - x.iloc[-1]).reset_index()\n",
    "\n",
    "    def khtst_layer_calculation(data_logs):\n",
    "        data = data_logs[data_logs.net == 1]\n",
    "        df_lst = []\n",
    "        for wellname in data.well.unique():\n",
    "            well_data = data_logs[data_logs.well == wellname]\n",
    "            well_data['tst_index_rev'] = [i for i in range(len(well_data['tst']))[::-1]]\n",
    "            df_lst.append(well_data)\n",
    "        data_logs_khtst = pd.concat(df_lst)\n",
    "        return data_logs_khtst\n",
    "    data_logs_khtst = khtst_layer_calculation(data_logs)\n",
    "\n",
    "    def well_dist_title(dist_df):\n",
    "        offset_well_list = dist_df[dist_df.well == well_target].iloc[:offset_qty]\n",
    "        well = offset_well_list['well'].iloc[0]\n",
    "        well1 = offset_well_list.iloc[0,1]\n",
    "        dist1 = offset_well_list.iloc[0,2].round(0).astype(int)\n",
    "        # well2 = offset_well_list.iloc[1,1]\n",
    "        # dist2 = offset_well_list.iloc[1,2].round(0).astype(int)\n",
    "        # well3 = offset_well_list.iloc[2,1]\n",
    "        # dist3 = offset_well_list.iloc[2,2].round(0).astype(int)\n",
    "        return f\"target well {well} : offsets {well1} - {dist1}m orange;\"\n",
    "\n",
    "    fig = plt.figure(figsize=(22, 10))\n",
    "    gs = gridspec.GridSpec(2, 4, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax5 = fig.add_subplot(gs[1, :3])\n",
    "\n",
    "    custom_palette = {well_target: 'red', offset_well_list[0]: 'orange'}\n",
    "    sns.histplot(data=data_logs, x='phit', hue='well', bins=50, kde=True, ax=ax1, palette=custom_palette)\n",
    "    sns.scatterplot(data=data_layers, x='htst', y='perm_avg', hue='well', s=75, ax=ax2, alpha=0.5, ec='black', palette=custom_palette)\n",
    "    sns.lineplot(data=data_logs_khtst, x='tst_index_rev', y='khtst', hue='well', ax=ax3, palette=custom_palette)\n",
    "    sns.barplot(data = khtst_logs, x='formation', y='khtst', hue='well', ax=ax4, palette=custom_palette)\n",
    "    ax1.set_yticklabels(ax1.get_yticklabels(), rotation=90, va='center')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax2.set_yticklabels(ax2.get_yticklabels(), rotation=90, va='center')\n",
    "    ax3.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax3.set_yticklabels(ax3.get_yticklabels(), rotation=90, va='center')\n",
    "\n",
    "    x = np.arange(len(khtst_logs.formation.unique()))\n",
    "    fms = khtst_logs.formation.unique()\n",
    "    ax4.set_xticks(x, fms, rotation=45, fontsize=6)\n",
    "    ax4.set_yticklabels(ax4.get_yticklabels(), rotation=90, va='center')\n",
    "\n",
    "    offset_well_list = dist_df[dist_df.well == well_target].iloc[:offset_qty]['well_offset'].values.tolist()\n",
    "    x = dataset_wells[dataset_wells.phit_flag == 1]['xmean']\n",
    "    y = dataset_wells[dataset_wells.phit_flag == 1]['ymean']\n",
    "    x_target = dataset_wells[dataset_wells.well == well_target]['xmean'].iloc[0]\n",
    "    y_target = dataset_wells[dataset_wells.well == well_target]['ymean'].iloc[0]\n",
    "    x_well1 = dataset_wells[dataset_wells.well == offset_well_list[0]]['xmean'].iloc[0]\n",
    "    y_well1 = dataset_wells[dataset_wells.well == offset_well_list[0]]['ymean'].iloc[0]\n",
    "    # x_well2 = dataset_wells[dataset_wells.well == offset_well_list[1]]['xmean'].iloc[0]\n",
    "    # y_well2 = dataset_wells[dataset_wells.well == offset_well_list[1]]['ymean'].iloc[0]\n",
    "    # x_well3 = dataset_wells[dataset_wells.well == offset_well_list[2]]['xmean'].iloc[0]\n",
    "    # y_well3 = dataset_wells[dataset_wells.well == offset_well_list[2]]['ymean'].iloc[0]\n",
    "    ax5.scatter(x, y, color='gray', s=10)\n",
    "    ax5.scatter(x_target, y_target, color='red', s=50, ec='black')\n",
    "    ax5.scatter(x_well1, y_well1, color='orange')\n",
    "    # ax5.scatter(x_well2, y_well2, color='green')\n",
    "    # ax5.scatter(x_well3, y_well3, color='#0797eb')\n",
    "\n",
    "    plt.suptitle(well_dist_title(dist_df), fontsize=16, y=0.92, x=0.32)\n",
    "    if print_flag == 'print':\n",
    "        plt.savefig(f'C:/jupyter/SPP/plots/offset_dashboard/{fm_name}_{well_target}_offset_dashboard.png');\n",
    "\n",
    "# df_bal8_v4_flag = df_bal8_v4_flag[~df_bal8_v4_flag.well.isin(['E31Z', 'D01Z'])]\n",
    "dist_bal8 = well_dist_calc(df_bal8_v4_flag, 'Balakhany VIII').round(0)\n",
    "for wellname in well_pairs_v3.well:\n",
    "    try:\n",
    "        well_offset_comparison_dashboard_pairs(df_bal8_v4_flag, ntd_top_phi_bot8_bp_v4, well_pairs_v3, wellname, 1, 'bal8','dontprint')\n",
    "    except:\n",
    "        print(f\"error in {wellname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegressionKriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several statistical metrics are commonly used to describe the distribution of a dataset. \n",
    "# These metrics provide insights into the shape, central tendency, and spread of the data. Here are some of the key metrics:\n",
    "\n",
    "# Mean: The average of all data points. It provides a measure of central tendency.\n",
    "\n",
    "# Median: The middle value when the data points are arranged in order. It is another measure of central tendency that \n",
    "# is less affected by outliers than the mean.\n",
    "\n",
    "# Mode: The most frequently occurring value(s) in the dataset. It can be used to understand the most common or \n",
    "# popular values in a distribution.\n",
    "\n",
    "# Standard Deviation (SD): Measures the amount of variation or dispersion of a set of values. A low SD indicates that \n",
    "# the values tend to be close to the mean, while a high SD indicates that the values are spread out over a wider range.\n",
    "\n",
    "# Variance: The square of the standard deviation. It measures how far each number in the set is from the mean and thus \n",
    "# from every other number in the set.\n",
    "\n",
    "# Range: The difference between the highest and lowest values in the dataset. It gives a sense of the spread of the data.\n",
    "\n",
    "# Interquartile Range (IQR): The difference between the 75th percentile (Q3) and the 25th percentile (Q1) in the data. \n",
    "# It is a measure of statistical dispersion and is less affected by outliers.\n",
    "\n",
    "# Skewness: A measure of the asymmetry of the probability distribution of a real-valued random variable. Positive skew indicates \n",
    "# a distribution with an asymmetric tail extending towards more positive values, while negative skew indicates a tail extending \n",
    "# towards more negative values.\n",
    "\n",
    "# Kurtosis: A measure of the \"tailedness\" of the probability distribution. High kurtosis means a distribution has heavy tails \n",
    "# and a sharp peak, while low kurtosis means a distribution has light tails and a flat peak.\n",
    "\n",
    "# Percentiles/Quartiles: Points in the distribution below which a certain percentage of the data falls. Quartiles are specific \n",
    "# percentiles: the 25th percentile (Q1), the 50th percentile (median or Q2), and the 75th percentile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntd_top_phi_bot8_bp_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntd_top_phi_bot8_bp_v4['htst*phit_avg'] = ntd_top_phi_bot8_bp_v4['htst'] * ntd_top_phi_bot8_bp_v4['phit_avg']\n",
    "ntd8 = ntd_top_phi_bot8_bp_v4.groupby('well')[['phit_avg','htst', 'htst*phit_avg']].agg({'phit_avg':'mean','htst':'sum', 'htst*phit_avg':'sum'}).reset_index()\n",
    "xy = df_bal8_v4_flag.groupby('well')[['xmean','ymean']].first().reset_index()\n",
    "ntd8 = ntd8.merge(xy, on='well').round({'xmean':0, 'ymean':0})\n",
    "ntd8 = ntd8[~ntd8.well.isin(well_pairs_v3.well.unique())]\n",
    "ntd8['phit_w_avg'] = ntd8['htst*phit_avg'] / ntd8['htst']\n",
    "ntd8 = ntd8[['well', 'phit_avg', 'htst', 'phit_w_avg', 'xmean', 'ymean']]\n",
    "\n",
    "field = df_bal8_v4.groupby('well')['field'].first().reset_index()\n",
    "ntd8 = ntd8.merge(field, on='well')\n",
    "ntd8 = ntd8[['well', 'phit_avg', 'htst', 'phit_w_avg', 'xmean', 'ymean', 'field']]\n",
    "ntd8 = pd.get_dummies(ntd8, columns=['field'])\n",
    "ntd8 = ntd8[~ntd8.well.isin(well_pairs_v3.well.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntd8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base case 42 big function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst_pred, df_lst_kriging = [], []\n",
    "for random_state_value in tqdm(range(1, 101)):\n",
    "    models_test = [svr_model, rf_model, lr_model]\n",
    "    def ml_kriging_prediction_bal8(models, random_state_value, test_size_value):\n",
    "        svr_model = SVR()\n",
    "        rf_model = RandomForestRegressor()\n",
    "        lr_model = LinearRegression()\n",
    "\n",
    "        feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "        coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "        target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "        f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "            feature_bal8, coord_bal8, target_bal8, test_size=test_size_value, random_state=random_state_value\n",
    "        )\n",
    "\n",
    "        def model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models):\n",
    "            df_final_lst = []\n",
    "            for m in models:\n",
    "                reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "                for nn in range(2,16):\n",
    "                    print(\"n_closest_points:\", nn)\n",
    "                    m_rk = RegressionKriging(regression_model=m, n_closest_points=nn, verbose=False)\n",
    "                    m_rk.fit(f_train, xy_train, target_train)\n",
    "                    reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "                    rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "                    nn_lst.append(nn)\n",
    "                    m_lst.append(m)\n",
    "                result = pd.DataFrame({'model':m_lst,'n_closest_points':nn_lst, 'reg_score':reg_score_lst,'rk_score':rk_score_lst})\n",
    "                result['random_state'] = random_state_value\n",
    "                result['test_size'] = test_size_value\n",
    "                df_final_lst.append(result)\n",
    "                df_final = pd.concat(df_final_lst)\n",
    "            return df_final\n",
    "        ml_kriging = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "\n",
    "        def model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, models_df):\n",
    "            model_sorted = models_df.sort_values(by='rk_score', ascending=False)\n",
    "            model_name = model_sorted.iloc[0]['model']\n",
    "            nn_points = model_sorted.iloc[0]['n_closest_points']\n",
    "            m_rk = RegressionKriging(regression_model=model_name, n_closest_points=nn_points)\n",
    "            m_rk.fit(f_train, xy_train, target_train)\n",
    "\n",
    "            pred = m_rk.predict(f_test, xy_test)\n",
    "            pred_df = pd.DataFrame(zip(pred, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "            pred_df['model'] = model_name\n",
    "            pred_df['n_closest_points'] = nn_points\n",
    "            pred_df['random_state'] = random_state_value\n",
    "            pred_df['test_size'] = test_size_value\n",
    "            pred_df['up_1.15pu'] = pred_df.phit_w_avg_true+0.0115\n",
    "            pred_df['down_1.15pu'] = pred_df.phit_w_avg_true-0.0115\n",
    "            pred_df['qc'] = np.where((pred_df.phit_w_avg_pred >= pred_df['down_1.15pu']) & (pred_df.phit_w_avg_pred <= pred_df['up_1.15pu']), 1, 0)\n",
    "            return pred_df\n",
    "        prediction_df = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, ml_kriging)\n",
    "\n",
    "        return prediction_df, ml_kriging\n",
    "    prediction_df, ml_kriging = ml_kriging_prediction_bal8(models_test, random_state_value, 0.5)\n",
    "    df_lst_pred.append(prediction_df)\n",
    "    df_lst_kriging.append(ml_kriging)\n",
    "df_pred = pd.concat(df_lst_pred)\n",
    "df_kriging = pd.concat(df_lst_kriging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_v2 = df_pred.groupby(['random_state','qc'])['qc'].count().rename('count').reset_index()\n",
    "sns.lineplot(data=df_pred_v2, x='random_state', y='count', hue='qc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base case 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "def model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models):\n",
    "    # f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    #     feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42)\n",
    "    df_final_lst = []\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
    "    for m in models:\n",
    "        reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "        for nn in range(2,16):\n",
    "            print(\"n_closest_points:\", nn)\n",
    "            m_rk = RegressionKriging(regression_model=m, n_closest_points=nn, verbose=False)\n",
    "            m_rk.fit(f_train, xy_train, target_train)\n",
    "            reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "            rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "            nn_lst.append(nn)\n",
    "            m_lst.append(m)\n",
    "        result = pd.DataFrame({'model':m_lst,'n_closest_points':nn_lst, 'reg_score':reg_score_lst,'rk_score':rk_score_lst})\n",
    "                \n",
    "        ax[0].plot(result.n_closest_points, result.rk_score)\n",
    "        ax[0].set_ylabel('rk_score')\n",
    "        ax[0].set_xlabel('n_closest_points')\n",
    "        ax[0].grid()\n",
    "        ax[0].legend(models)\n",
    "        ax[0].set_title('Model rk_score comparison')\n",
    "        ax[1].plot(result.n_closest_points, result.reg_score)\n",
    "        ax[1].set_ylabel('reg_score')\n",
    "        ax[1].set_xlabel('n_closest_points')\n",
    "        ax[1].grid()\n",
    "        ax[1].legend(models)\n",
    "        ax[1].set_title('Model reg_score comparison')\n",
    "        df_final_lst.append(result)\n",
    "        df_final = pd.concat(df_final_lst)\n",
    "    return df_final\n",
    "base_42 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, models_df):\n",
    "    model_sorted = models_df.sort_values(by='rk_score', ascending=False)\n",
    "    model_name = model_sorted.iloc[0]['model']\n",
    "    nn_points = model_sorted.iloc[0]['n_closest_points']\n",
    "    m_rk = RegressionKriging(regression_model=model_name, n_closest_points=nn_points)\n",
    "    m_rk.fit(f_train, xy_train, target_train)\n",
    "    print(\"Model name:\", model_name, \"n_closer_points:\", nn_points)\n",
    "    print(\"Regression Score: \", m_rk.regression_model.score(f_test, target_test))\n",
    "    print(\"RK score: \", m_rk.score(f_test, xy_test, target_test))\n",
    "\n",
    "    pred = m_rk.predict(f_test, xy_test)\n",
    "    pred_df = pd.DataFrame(zip(f_test.flatten(), pred, target_test), columns=['htst','phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "    pred_df['up5%'] = pred_df.phit_w_avg_true+0.0115\n",
    "    pred_df['down5%'] = pred_df.phit_w_avg_true-0.0115\n",
    "    pred_df['qc'] = np.where((pred_df.phit_w_avg_pred >= pred_df['down5%']) & (pred_df.phit_w_avg_pred <= pred_df['up5%']), 1, 0)\n",
    "    display(pred_df.value_counts('qc', normalize=True))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(14, 5))\n",
    "    xy_train_df = pd.DataFrame(xy_train, columns=['x', 'y'])\n",
    "    xy_train_df['source'] = 'train'\n",
    "    xy_test_df = pd.DataFrame(xy_test, columns=['x', 'y'])\n",
    "    xy_test_df['source'] = 'test'\n",
    "    xy_data_df = pd.concat([xy_train_df, xy_test_df])\n",
    "    sns.scatterplot(xy_data_df, x='x', y='y', hue='source', ax=ax[0])\n",
    "\n",
    "    custom_palette = {0: 'red', 1: 'green'}\n",
    "    sns.scatterplot(pred_df, x='phit_w_avg_true', y='phit_w_avg_pred', hue='qc', s=50, alpha=0.5, ec='black', palette=custom_palette, ax=ax[1])\n",
    "    ax[1].plot([0.15,0.27], [0.15,0.27], color='blue', ls='--')\n",
    "    ax[1].plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "    ax[1].plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "    ax[1].grid()\n",
    "    ax[1].set_xlim(0.15,0.27)\n",
    "    ax[1].set_ylim(0.15,0.27);\n",
    "    return pred_df\n",
    "pred_base_42 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, base_42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "base_1 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "pred_base_1 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, base_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=123\n",
    ")\n",
    "\n",
    "base_123 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "pred_base_123 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, base_123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_base_1['model'] = 'base_1'\n",
    "pred_base_42['model'] = 'base_42'\n",
    "pred_base_123['model'] = 'base_123'\n",
    "pred_final = pd.concat([pred_base_42, pred_base_1, pred_base_123])\n",
    "sns.scatterplot(data=pred_final, x='phit_w_avg_true', y='phit_w_avg_pred', hue='model', style='qc', palette='bright')\n",
    "plt.plot([0.15,0.27], [0.15,0.27], color='red', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "plt.grid()\n",
    "plt.xlim(0.15,0.27)\n",
    "plt.ylim(0.15,0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(pred_df.value_counts('qc', normalize=True))\n",
    "qc42 = pred_final[pred_final.model == 'base_42'].qc.value_counts(normalize=True)\n",
    "qc1 = pred_final[pred_final.model == 'base_1'].qc.value_counts(normalize=True)\n",
    "qc123 = pred_final[pred_final.model == 'base_123'].qc.value_counts(normalize=True)\n",
    "print('Quantati of test points:', len(f_test), 'Quantaty of train points:', len(f_train))\n",
    "print(\"base_42\", qc42, \"base_1\", qc1, \"base_123\", qc123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 'field' 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "feature_42 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "pred_f42 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, feature_42)\n",
    "\n",
    "# Model name: SVR(C=0.1, gamma='auto') n_closer_points: 8\n",
    "# Regression Score:  -0.026579262856369246\n",
    "# RK score:  0.6251967133689289\n",
    "# qc\n",
    "# 1   0.64286\n",
    "# 0   0.35714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 'field' f42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=242\n",
    ")\n",
    "\n",
    "feature_242 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "pred_f242 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, feature_242)\n",
    "\n",
    "# Model name: SVR(C=0.1, gamma='auto') n_closer_points: 8\n",
    "# Regression Score:  -0.026579262856369246\n",
    "# RK score:  0.6251967133689289\n",
    "# qc\n",
    "# 1   0.64286\n",
    "# 0   0.35714"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 'field' 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "feature_f1 = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "pred_f1 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, feature_242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_f42['model'] = 'feature_42'\n",
    "pred_f242['model'] = 'feature_242'\n",
    "pred_f1['model'] = 'feature_1'\n",
    "pred_ffinal = pd.concat([pred_f42, pred_f242, pred_f1])\n",
    "\n",
    "sns.scatterplot(data=pred_ffinal, x='phit_w_avg_true', y='phit_w_avg_pred', hue='model', style='qc', palette='bright')\n",
    "plt.plot([0.15,0.27], [0.15,0.27], color='red', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "plt.grid()\n",
    "plt.xlim(0.15,0.27)\n",
    "plt.ylim(0.15,0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.64 v/v of 28 = ~18, 0.75 v/v of 28 = 21, variations 3 points is equal 0.11 v/v\n",
    "qc_f42 = pred_f42[pred_f42.model == 'feature_42'].qc.value_counts(normalize=True)\n",
    "qc_f242 = pred_f242[pred_f242.model == 'feature_242'].qc.value_counts(normalize=True)\n",
    "qc_f1 = pred_f1[pred_f1.model == 'feature_1'].qc.value_counts(normalize=True)\n",
    "print('Quantati of test points:', len(f_test), 'Quantaty of train points:', len(f_train))\n",
    "print(\"feature_42\", qc_f42, \"feature_242\", qc_f242, \"feature_1\", qc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegKrig experiments: method + var_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging base 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "def model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, rk_method, vmodel):\n",
    "    df_final_lst = []\n",
    "    for m in models:\n",
    "        reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "        for nn in range(2,16):\n",
    "            print(\"n_closest_points:\", nn)\n",
    "            m_rk = RegressionKriging(regression_model=m, method=rk_method, n_closest_points=nn, variogram_model=vmodel, verbose=False)\n",
    "            m_rk.fit(f_train, xy_train, target_train)\n",
    "            reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "            rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "            nn_lst.append(nn)\n",
    "            m_lst.append(m)\n",
    "        result = pd.DataFrame({'model':m_lst,\n",
    "                               'n_closest_points':nn_lst, \n",
    "                               'reg_score':reg_score_lst,\n",
    "                               'rk_score':rk_score_lst,\n",
    "                               'rk_method':rk_method,\n",
    "                               'vmodel':vmodel})\n",
    "        df_final_lst.append(result)\n",
    "        df_final = pd.concat(df_final_lst)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "total_result_42 = []\n",
    "for method in ['universal', 'ordinary']:\n",
    "    for vmodel in ['linear', 'power', 'gaussian', 'spherical', 'exponential']:\n",
    "        base_42_kriging = model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, method, vmodel)\n",
    "        total_result_42.append(base_42_kriging)\n",
    "total_result_42 = pd.concat(total_result_42)\n",
    "total_result_42.sort_values(by='rk_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, models_df):\n",
    "    model_sorted = models_df.sort_values(by='rk_score', ascending=False)\n",
    "    model_name = model_sorted.iloc[0]['model']\n",
    "    nn_points = model_sorted.iloc[0]['n_closest_points']\n",
    "    rk_method = model_sorted.iloc[0]['rk_method']\n",
    "    vmodel = model_sorted.iloc[0]['vmodel']\n",
    "    m_rk = RegressionKriging(regression_model=model_name,method=rk_method, n_closest_points=nn_points, variogram_model=vmodel)\n",
    "    m_rk.fit(f_train, xy_train, target_train)\n",
    "    print(\"Model name:\", model_name, \"n_closer_points:\", nn_points, \"rk_method:\", rk_method, \"vmodel:\", vmodel)\n",
    "    print(\"Regression Score: \", m_rk.regression_model.score(f_test, target_test))\n",
    "    print(\"RK score: \", m_rk.score(f_test, xy_test, target_test))\n",
    "\n",
    "    pred = m_rk.predict(f_test, xy_test)\n",
    "    pred_df = pd.DataFrame(zip(pred, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "    pred_df['up5%'] = pred_df.phit_w_avg_true+0.0115\n",
    "    pred_df['down5%'] = pred_df.phit_w_avg_true-0.0115\n",
    "    pred_df['qc'] = np.where((pred_df.phit_w_avg_pred >= pred_df['down5%']) & (pred_df.phit_w_avg_pred <= pred_df['up5%']), 1, 0)\n",
    "    display(pred_df.value_counts('qc', normalize=True))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(14, 5))\n",
    "    xy_train_df = pd.DataFrame(xy_train, columns=['x', 'y'])\n",
    "    xy_train_df['source'] = 'train'\n",
    "    xy_test_df = pd.DataFrame(xy_test, columns=['x', 'y'])\n",
    "    xy_test_df['source'] = 'test'\n",
    "    xy_data_df = pd.concat([xy_train_df, xy_test_df])\n",
    "    sns.scatterplot(xy_data_df, x='x', y='y', hue='source', ax=ax[0])\n",
    "\n",
    "    custom_palette = {0: 'red', 1: 'green'}\n",
    "    sns.scatterplot(pred_df, x='phit_w_avg_true', y='phit_w_avg_pred', hue='qc', s=50, alpha=0.5, ec='black', palette=custom_palette, ax=ax[1])\n",
    "    ax[1].plot([0.15,0.27], [0.15,0.27], color='blue', ls='--')\n",
    "    ax[1].plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "    ax[1].plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "    ax[1].grid()\n",
    "    ax[1].set_xlim(0.15,0.27)\n",
    "    ax[1].set_ylim(0.15,0.27);\n",
    "    return pred_df\n",
    "\n",
    "pred_kbase_42= model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, total_result_42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging feature f42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "def model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, rk_method, vmodel):\n",
    "    # f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    #     feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42)\n",
    "    df_final_lst = []\n",
    "    # fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
    "    for m in models:\n",
    "        reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "        for nn in range(2,16):\n",
    "            print(\"n_closest_points:\", nn)\n",
    "            m_rk = RegressionKriging(regression_model=m, method=rk_method, n_closest_points=nn, variogram_model=vmodel, verbose=False)\n",
    "            m_rk.fit(f_train, xy_train, target_train)\n",
    "            reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "            rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "            nn_lst.append(nn)\n",
    "            m_lst.append(m)\n",
    "        result = pd.DataFrame({'model':m_lst,\n",
    "                               'n_closest_points':nn_lst, \n",
    "                               'reg_score':reg_score_lst,\n",
    "                               'rk_score':rk_score_lst,\n",
    "                               'rk_method':rk_method,\n",
    "                               'vmodel':vmodel})\n",
    "        df_final_lst.append(result)\n",
    "        df_final = pd.concat(df_final_lst)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "total_result_f42 = []\n",
    "for method in ['universal', 'ordinary']:\n",
    "    for vmodel in ['linear', 'power', 'gaussian', 'spherical', 'exponential']:\n",
    "        base_f42_kriging = model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, method, vmodel)\n",
    "        total_result_f42.append(base_f42_kriging)\n",
    "total_result_f42 = pd.concat(total_result_f42)\n",
    "total_result_f42.sort_values(by='rk_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kbase_f42 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, total_result_f42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kriging feature f33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=10)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=33\n",
    ")\n",
    "\n",
    "def model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, rk_method, vmodel):\n",
    "    # f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    #     feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42)\n",
    "    df_final_lst = []\n",
    "    # fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
    "    for m in models:\n",
    "        reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "        for nn in range(2,16):\n",
    "            print(\"n_closest_points:\", nn)\n",
    "            m_rk = RegressionKriging(regression_model=m, method=rk_method, n_closest_points=nn, variogram_model=vmodel, verbose=False)\n",
    "            m_rk.fit(f_train, xy_train, target_train)\n",
    "            reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "            rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "            nn_lst.append(nn)\n",
    "            m_lst.append(m)\n",
    "        result = pd.DataFrame({'model':m_lst,\n",
    "                               'n_closest_points':nn_lst, \n",
    "                               'reg_score':reg_score_lst,\n",
    "                               'rk_score':rk_score_lst,\n",
    "                               'rk_method':rk_method,\n",
    "                               'vmodel':vmodel})\n",
    "        df_final_lst.append(result)\n",
    "        df_final = pd.concat(df_final_lst)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "total_result_f33 = []\n",
    "for method in ['universal', 'ordinary']:\n",
    "    for vmodel in ['linear', 'power', 'gaussian', 'spherical', 'exponential']:\n",
    "        base_f33_kriging = model_mlkrige_run_kriging(f_train, f_test, xy_train, xy_test, target_train, target_test, models, method, vmodel)\n",
    "        total_result_f33.append(base_f33_kriging)\n",
    "total_result_f33 = pd.concat(total_result_f33)\n",
    "total_result_f33.sort_values(by='rk_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kbase_f33 = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, total_result_f33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kbase_42['model'] = 'feature_42'\n",
    "pred_kbase_f42['model'] = 'feature_f42'\n",
    "pred_kbase_f33['model'] = 'feature_f33'\n",
    "pred_kfinal = pd.concat([pred_kbase_42, pred_kbase_f42, pred_kbase_f33])\n",
    "\n",
    "sns.scatterplot(data=pred_kfinal, x='phit_w_avg_true', y='phit_w_avg_pred', hue='model', style='qc', palette='bright')\n",
    "plt.plot([0.15,0.27], [0.15,0.27], color='red', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "plt.grid()\n",
    "plt.xlim(0.15,0.27)\n",
    "plt.ylim(0.15,0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_k42 = pred_kbase_42[pred_kbase_42.model == 'feature_42'].qc.value_counts(normalize=True)\n",
    "qc_kf42 = pred_kbase_f42[pred_kbase_f42.model == 'feature_f42'].qc.value_counts(normalize=True)\n",
    "qc_kf33 = pred_kbase_f33[pred_kbase_f33.model == 'feature_f33'].qc.value_counts(normalize=True)\n",
    "print('Quantati of test points:', len(f_test), 'Quantaty of train points:', len(f_train))\n",
    "print(\"feature_k42\", qc_k42, \"feature_kf42\", qc_kf42, \"feature_kf33\", qc_kf33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anithotropy test 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"method\": [\"ordinary\", \"universal\"],\n",
    "    \"variogram_model\": [\"linear\", \"exponencial\", \"power\", \"gaussian\", \"spherical\"],\n",
    "    \"n_closest_points\": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    \"anisotropy_scaling\": [(0,1), (0.5,1), (1,1), (1,0.5), (1,0)],\n",
    "    \"anisotropy_angle\": [(0, 0, 0), (30, 0, 0), (60, 0, 0), (90, 0, 0)],\n",
    "}\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "estimator = GridSearchCV(Krige(), param_dict, verbose=True, return_train_score=True)\n",
    "estimator.fit(X=xy_train, y=target_train)\n",
    "\n",
    "if hasattr(estimator, \"best_score_\"):\n",
    "    print(\"best_score R² = {:.3f}\".format(estimator.best_score_))\n",
    "    print(\"best_params = \", estimator.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитать отдельно линейную регрессию чтоб сравнить результат с кригингом ниже !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = estimator.best_params_\n",
    "model = Krige(**best_params)\n",
    "model.fit(xy_train, target_train)\n",
    "pred_krige = model.predict(xy_test)\n",
    "pred_krige_df = pd.DataFrame(zip(pred_krige, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "xy_krige_df = pd.DataFrame(xy_test, columns=['x', 'y'])\n",
    "pred_krige = pd.concat([xy_krige_df, pred_krige_df], axis=1)\n",
    "pred_krige['up5%'] = pred_krige.phit_w_avg_true+0.0115\n",
    "pred_krige['down5%'] = pred_krige.phit_w_avg_true-0.0115\n",
    "pred_krige['qc'] = np.where((pred_krige.phit_w_avg_pred >= pred_krige['down5%']) & (pred_krige.phit_w_avg_pred <= pred_krige['up5%']), 1, 0)\n",
    "pred_krige['model'] = 'krige_42'\n",
    "display(pred_krige.value_counts('qc', normalize=True))\n",
    "\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(pred_krige, x='phit_w_avg_true', y='phit_w_avg_pred', hue='qc', s=50, alpha=0.5, ec='black', palette=custom_palette)\n",
    "plt.plot([0.15,0.27], [0.15,0.27], color='red', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15+0.0115,0.27+0.0115], color='green', ls='--')\n",
    "plt.plot([0.15,0.27], [0.15-0.0115,0.27-0.0115], color='green', ls='--')\n",
    "plt.grid()\n",
    "plt.xlim(0.15,0.27)\n",
    "plt.ylim(0.15,0.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_k42 = pred_kbase_42[pred_kbase_42.model == 'feature_42'].qc.value_counts().reset_index()\n",
    "qc_k42['norm'] = (qc_k42['count'] / qc_k42['count'].sum()).round(2)\n",
    "qc_kf42 = pred_kbase_f42[pred_kbase_f42.model == 'feature_f42'].qc.value_counts().reset_index()\n",
    "qc_kf42['norm'] = (qc_kf42['count'] / qc_kf42['count'].sum()).round(2)\n",
    "qc_kf33 = pred_kbase_f33[pred_kbase_f33.model == 'feature_f33'].qc.value_counts().reset_index()\n",
    "qc_kf33['norm'] = (qc_kf33['count'] / qc_kf33['count'].sum()).round(2)\n",
    "qc_krige = pred_krige[pred_krige.model == 'krige_42'].qc.value_counts().reset_index()\n",
    "qc_krige['norm'] = (qc_krige['count'] / qc_krige['count'].sum()).round(2)\n",
    "print('Quantati of test points:', len(f_test), 'Quantaty of train points:', len(f_train))\n",
    "print(\"\\nKriging base 42 Model name: SVR(C=0.1, gamma='auto') n_closer_points: 9 rk_method: ordinary vmodel: exponential\\n\", \n",
    "      qc_k42, \n",
    "      \"\\nKriging feature f42 Model name: LinearRegression(fit_intercept=False) n_closer_points: 9 rk_method: ordinary vmodel: gaussian\\n\", \n",
    "      qc_kf42, \n",
    "      \"\\nKriging feature f33 Model name: SVR(C=0.1, gamma='auto') n_closer_points: 2 rk_method: ordinary vmodel: power\\n\", \n",
    "      qc_kf33, \n",
    "      \"\\nAnithotropy test 42 {'anisotropy_angle': (60, 0, 0), 'anisotropy_scaling': (0.5, 1), 'method': 'universal', 'n_closest_points': 2, 'variogram_model': 'gaussian'}\\n\", \n",
    "      qc_krige)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing influence ml, kriging, ml+kriging to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. написать функцию для расчета предикшена с разными ramdom_state для базовых настроек кригинга и модели              +\n",
    "# 2. посчитать стабильность предсказаний для 100 разных random_state                                                    +\n",
    "# 3. посчитать предсказание отдельно для регрессии, регрессии с кригингом и кригинга - везде базовые настройки          +\n",
    "# 4. добавить расчет поросити по соседним скважинам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml + kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_kriging_prediction_bal8(models, random_state_value, test_size_value):\n",
    "    svr_model = SVR()\n",
    "    rf_model = RandomForestRegressor()\n",
    "    lr_model = LinearRegression()\n",
    "\n",
    "    feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "    coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "    target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "    f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "        feature_bal8, coord_bal8, target_bal8, test_size=test_size_value, random_state=random_state_value\n",
    "    )\n",
    "\n",
    "    def model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models):\n",
    "        df_final_lst = []\n",
    "        for m in models:\n",
    "            reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "            for nn in range(2,16):\n",
    "                print(\"n_closest_points:\", nn)\n",
    "                m_rk = RegressionKriging(regression_model=m, n_closest_points=nn, verbose=False)\n",
    "                m_rk.fit(f_train, xy_train, target_train)\n",
    "                reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "                rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "                nn_lst.append(nn)\n",
    "                m_lst.append(m)\n",
    "            result = pd.DataFrame({'model':m_lst,'n_closest_points':nn_lst, 'reg_score':reg_score_lst,'rk_score':rk_score_lst})\n",
    "            result['random_state'] = random_state_value\n",
    "            result['test_size'] = test_size_value\n",
    "            df_final_lst.append(result)\n",
    "            df_final = pd.concat(df_final_lst)\n",
    "        return df_final\n",
    "    ml_kriging = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "\n",
    "    def model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, models_df):\n",
    "        model_sorted = models_df.sort_values(by='rk_score', ascending=False)\n",
    "        model_name = model_sorted.iloc[0]['model']\n",
    "        nn_points = model_sorted.iloc[0]['n_closest_points']\n",
    "        m_rk = RegressionKriging(regression_model=model_name, n_closest_points=nn_points)\n",
    "        m_rk.fit(f_train, xy_train, target_train)\n",
    "\n",
    "        pred = m_rk.predict(f_test, xy_test)\n",
    "        pred_df = pd.DataFrame(zip(pred, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "        pred_df['model'] = model_name\n",
    "        pred_df['n_closest_points'] = nn_points\n",
    "        pred_df['random_state'] = random_state_value\n",
    "        pred_df['test_size'] = test_size_value\n",
    "        pred_df['up_1.15pu'] = pred_df.phit_w_avg_true+0.0115\n",
    "        pred_df['down_1.15pu'] = pred_df.phit_w_avg_true-0.0115\n",
    "        pred_df['qc'] = np.where((pred_df.phit_w_avg_pred >= pred_df['down_1.15pu']) & (pred_df.phit_w_avg_pred <= pred_df['up_1.15pu']), 1, 0)\n",
    "        return pred_df\n",
    "    prediction_df = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, ml_kriging)\n",
    "\n",
    "    return prediction_df, ml_kriging\n",
    "models_test = [svr_model, rf_model, lr_model]\n",
    "prediction_df, ml_kriging = ml_kriging_prediction_bal8(models_test, 42, 0.5)\n",
    "qc_calc = prediction_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=prediction_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc[qc_calc.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_kriging.sort_values(by='rk_score', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()\n",
    "\n",
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.5, random_state=42\n",
    ")\n",
    "svr_model.fit(f_train, target_train)\n",
    "pred_svr = svr_model.predict(f_test)\n",
    "pred_svr_df = pd.DataFrame(zip(pred_svr, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "pred_svr_df['model'] = svr_model.__class__.__name__\n",
    "# pred_svr_df['n_closest_points'] = nn_points\n",
    "pred_svr_df['random_state'] = 42\n",
    "pred_svr_df['test_size'] = 0.5\n",
    "pred_svr_df['up_1.15pu'] = pred_svr_df.phit_w_avg_true+0.0115\n",
    "pred_svr_df['down_1.15pu'] = pred_svr_df.phit_w_avg_true-0.0115\n",
    "pred_svr_df['qc'] = np.where((pred_svr_df.phit_w_avg_pred >= pred_svr_df['down_1.15pu']) & (pred_svr_df.phit_w_avg_pred <= pred_svr_df['up_1.15pu']), 1, 0)\n",
    "\n",
    "qc_calc = pred_svr_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=pred_svr_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc[qc_calc.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bal8 = ntd8[['htst']].values.reshape(-1,1)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "kriging = Krige(n_closest_points=2, method='ordinary', variogram_model='linear')\n",
    "kriging.fit(x=xy_train, y=target_train)\n",
    "pred_kriging = kriging.predict(xy_test)\n",
    "\n",
    "kriging_df = pd.DataFrame(zip(pred_kriging, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "kriging_df['model'] = kriging.__class__.__name__\n",
    "kriging_df['n_closest_points'] = 2\n",
    "kriging_df['random_state'] = 42\n",
    "kriging_df['test_size'] = 0.5\n",
    "kriging_df['up_1.15pu'] = kriging_df.phit_w_avg_true+0.0115\n",
    "kriging_df['down_1.15pu'] = kriging_df.phit_w_avg_true-0.0115\n",
    "kriging_df['qc'] = np.where((kriging_df.phit_w_avg_pred >= kriging_df['down_1.15pu']) & (kriging_df.phit_w_avg_pred <= kriging_df['up_1.15pu']), 1, 0)\n",
    "kriging_df\n",
    "\n",
    "qc_calc = kriging_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=kriging_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc[qc_calc.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 simple feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml+kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_kriging_prediction_feature_bal8(models, random_state_value, test_size_value):\n",
    "    svr_model = SVR()\n",
    "    rf_model = RandomForestRegressor()\n",
    "    lr_model = LinearRegression()\n",
    "\n",
    "    feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "    coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "    target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "    f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "        feature_bal8, coord_bal8, target_bal8, test_size=test_size_value, random_state=random_state_value\n",
    "    )\n",
    "\n",
    "    def model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models):\n",
    "        df_final_lst = []\n",
    "        for m in models:\n",
    "            reg_score_lst, rk_score_lst, nn_lst, m_lst = [], [], [], []\n",
    "            for nn in range(2,16):\n",
    "                print(\"n_closest_points:\", nn)\n",
    "                m_rk = RegressionKriging(regression_model=m, n_closest_points=nn, verbose=False)\n",
    "                m_rk.fit(f_train, xy_train, target_train)\n",
    "                reg_score_lst.append(m_rk.regression_model.score(f_test, target_test))\n",
    "                rk_score_lst.append(m_rk.score(f_test, xy_test, target_test))\n",
    "                nn_lst.append(nn)\n",
    "                m_lst.append(m)\n",
    "            result = pd.DataFrame({'model':m_lst,'n_closest_points':nn_lst, 'reg_score':reg_score_lst,'rk_score':rk_score_lst})\n",
    "            result['random_state'] = random_state_value\n",
    "            result['test_size'] = test_size_value\n",
    "            df_final_lst.append(result)\n",
    "            df_final = pd.concat(df_final_lst)\n",
    "        return df_final\n",
    "    ml_kriging = model_mlkrige_run(f_train, f_test, xy_train, xy_test, target_train, target_test, models)\n",
    "\n",
    "    def model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, models_df):\n",
    "        model_sorted = models_df.sort_values(by='rk_score', ascending=False)\n",
    "        model_name = model_sorted.iloc[0]['model']\n",
    "        nn_points = model_sorted.iloc[0]['n_closest_points']\n",
    "        m_rk = RegressionKriging(regression_model=model_name, n_closest_points=nn_points)\n",
    "        m_rk.fit(f_train, xy_train, target_train)\n",
    "\n",
    "        pred = m_rk.predict(f_test, xy_test)\n",
    "        pred_df = pd.DataFrame(zip(pred, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "        pred_df['model'] = model_name\n",
    "        pred_df['n_closest_points'] = nn_points\n",
    "        pred_df['random_state'] = random_state_value\n",
    "        pred_df['test_size'] = test_size_value\n",
    "        pred_df['up_1.15pu'] = pred_df.phit_w_avg_true+0.0115\n",
    "        pred_df['down_1.15pu'] = pred_df.phit_w_avg_true-0.0115\n",
    "        pred_df['qc'] = np.where((pred_df.phit_w_avg_pred >= pred_df['down_1.15pu']) & (pred_df.phit_w_avg_pred <= pred_df['up_1.15pu']), 1, 0)\n",
    "        return pred_df\n",
    "    prediction_df = model_mlkrige_best_res(f_train, f_test, xy_train, xy_test, target_train, target_test, ml_kriging)\n",
    "\n",
    "    return prediction_df, ml_kriging\n",
    "models_test = [svr_model, rf_model, lr_model]\n",
    "prediction_f_df, ml_f_kriging = ml_kriging_prediction_feature_bal8(models_test, 42, 0.5)\n",
    "qc_calc_ml_kri = prediction_f_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=prediction_f_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc_ml_kri[qc_calc_ml_kri.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_f_kriging.sort_values(by='rk_score', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.5, random_state=42\n",
    ")\n",
    "lr_model.fit(f_train, target_train)\n",
    "pred_lr = lr_model.predict(f_test)\n",
    "pred_lr_df = pd.DataFrame(zip(pred_lr, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "pred_lr_df['model'] = pred_lr.__class__.__name__\n",
    "# pred_svr_df['n_closest_points'] = nn_points\n",
    "pred_lr_df['random_state'] = 42\n",
    "pred_lr_df['test_size'] = 0.5\n",
    "pred_lr_df['up_1.15pu'] = pred_lr_df.phit_w_avg_true+0.0115\n",
    "pred_lr_df['down_1.15pu'] = pred_lr_df.phit_w_avg_true-0.0115\n",
    "pred_lr_df['qc'] = np.where((pred_lr_df.phit_w_avg_pred >= pred_lr_df['down_1.15pu']) & (pred_lr_df.phit_w_avg_pred <= pred_lr_df['up_1.15pu']), 1, 0)\n",
    "\n",
    "qc_calc_ml = pred_svr_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=pred_lr_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc_ml[qc_calc_ml.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bal8 = ntd8[['htst','field_CENTRAL AZERI', 'field_EAST AZERI', 'field_WEST AZERI']].values.reshape(-1,4)\n",
    "coord_bal8 = ntd8[['xmean', 'ymean']].values\n",
    "target_bal8 = ntd8['phit_w_avg'].values\n",
    "\n",
    "f_train, f_test, xy_train, xy_test, target_train, target_test = train_test_split(\n",
    "    feature_bal8, coord_bal8, target_bal8, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "kriging = Krige(n_closest_points=2, method='ordinary', variogram_model='linear')\n",
    "kriging.fit(x=xy_train, y=target_train)\n",
    "pred_kriging = kriging.predict(xy_test)\n",
    "\n",
    "kriging_df = pd.DataFrame(zip(pred_kriging, target_test), columns=['phit_w_avg_pred', 'phit_w_avg_true'])\n",
    "kriging_df['model'] = kriging.__class__.__name__\n",
    "kriging_df['n_closest_points'] = 2\n",
    "kriging_df['random_state'] = 42\n",
    "kriging_df['test_size'] = 0.5\n",
    "kriging_df['up_1.15pu'] = kriging_df.phit_w_avg_true+0.0115\n",
    "kriging_df['down_1.15pu'] = kriging_df.phit_w_avg_true-0.0115\n",
    "kriging_df['qc'] = np.where((kriging_df.phit_w_avg_pred >= kriging_df['down_1.15pu']) & (kriging_df.phit_w_avg_pred <= kriging_df['up_1.15pu']), 1, 0)\n",
    "\n",
    "qc_calc_kriging = kriging_df.qc.value_counts(normalize=True).reset_index()\n",
    "custom_palette = {0: 'red', 1: 'green'}\n",
    "sns.scatterplot(data=kriging_df, x='phit_w_avg_true', y='phit_w_avg_pred', s=30, hue='qc', alpha=0.5, ec='black', palette=custom_palette)\n",
    "sns.lineplot(x=[0.16,0.27], y=[0.16,0.27], color='blue', ls='--')\n",
    "plt.title('qc = 1 ' + str(qc_calc_kriging[qc_calc_kriging.qc==1]['proportion'].values[0].round(2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('phit_w_avg prediction\\nkriging:', qc_calc_kriging[qc_calc_kriging.qc==1]['proportion'].values[0].round(3), \n",
    "      'ml:', qc_calc_ml[qc_calc_ml.qc==1]['proportion'].values[0].round(3), \n",
    "      'ml + kriging:', qc_calc_ml_kri[qc_calc_ml_kri.qc==1]['proportion'].values[0].round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(C=0.1, gamma=\"auto\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "lr_model = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "models = [svr_model, rf_model, lr_model]\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# take the first 5000 as Kriging is memory intensive\n",
    "p = housing[\"data\"][:5000, :-2]\n",
    "x = housing[\"data\"][:5000, -2:]\n",
    "target = housing[\"target\"][:5000]\n",
    "\n",
    "p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "    p, x, target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "for m in models:\n",
    "    print(\"=\" * 40)\n",
    "    print(\"regression model:\", m.__class__.__name__)\n",
    "    m_rk = RegressionKriging(regression_model=m, n_closest_points=10)\n",
    "    m_rk.fit(p_train, x_train, target_train)\n",
    "    print(\"Regression Score: \", m_rk.regression_model.score(p_test, target_test))\n",
    "    print(\"RK score: \", m_rk.score(p_test, x_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "p = housing[\"data\"][:5000, :-2]\n",
    "x = housing[\"data\"][:5000, -2:]\n",
    "target = housing[\"target\"][:5000]\n",
    "\n",
    "p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "    p, x, target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(p_train, target_train)\n",
    "pred_rf = rf_model.predict(p_test)\n",
    "score_rf = rf_model.score(p_test, target_test).round(3)\n",
    "print(\"RandomForest Score: \", score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = housing[\"data\"][:5000, :-2]\n",
    "x = housing[\"data\"][:5000, -2:]\n",
    "target = housing[\"target\"][:5000]\n",
    "\n",
    "p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "    p, x, target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "kriging = Krige(method='ordinary', variogram_model='linear')\n",
    "kriging.fit(x=x_train, y=target_train)\n",
    "pred_kriging = kriging.predict(x_test)\n",
    "score_kriging = kriging.score(x_test, target_test).round(3)\n",
    "print(\"Kriging Score: \", score_kriging)\n",
    "print('RFR + kriging:',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "p = housing[\"data\"][:5000, :-2]\n",
    "x = housing[\"data\"][:5000, -2:]\n",
    "target = housing[\"target\"][:5000]\n",
    "\n",
    "p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "    p, x, target, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "m_rk = RegressionKriging(regression_model=rf_model)\n",
    "m_rk.fit(p_train, x_train, target_train)\n",
    "score_rf_kriging = m_rk.score(p_test, x_test, target_test).round(3)\n",
    "print(\"RK score: \", score_rf_kriging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('synthetic dataset\\nkriging:', score_kriging, 'ml:', score_rf, 'ml + kriging:', score_rf_kriging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка модели на разных количествах фичей\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "for i in range(2,8,1):\n",
    "    p = housing[\"data\"][:5000, :-i]\n",
    "    x = housing[\"data\"][:5000, -2:]\n",
    "    target = housing[\"target\"][:5000]\n",
    "\n",
    "    p_train, p_test, x_train, x_test, target_train, target_test = train_test_split(\n",
    "        p, x, target, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print('i:', i)\n",
    "    print(\"regression model:\", rf_model.__class__.__name__)\n",
    "    m_rk = RegressionKriging(regression_model=rf_model, n_closest_points=10)\n",
    "    m_rk.fit(p_train, x_train, target_train)\n",
    "\n",
    "    print(\"Regression Score: \", m_rk.regression_model.score(p_test, target_test))\n",
    "    print(\"RK score: \", m_rk.score(p_test, x_test, target_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

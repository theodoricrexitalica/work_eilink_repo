{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "from segysak.segy import segy_loader, well_known_byte_locs, segy_writer, segy_header_scrape\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA coordinate extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\AslanRzayev\\Desktop\\workspace\\Projects\\eilink\\kh_static\\data\\df_bal_ne 3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_bal8 = df[(df['FORMATION_up'] == 'Balakhany VIII') & (df['field'] == 'CENTRAL AZERI')]\n",
    "df_ca_bal8_coordinates = {'x_min': df_ca_bal8['X_traj'].min(), \n",
    "                'x_max': df_ca_bal8['X_traj'].max(),\n",
    "                'y_min': df_ca_bal8['Y_traj'].min(),\n",
    "                'y_max': df_ca_bal8['Y_traj'].max(),\n",
    "                'z_min': df_ca_bal8['TVD_SCS'].min(),\n",
    "                'z_max': df_ca_bal8['TVD_SCS'].max()              \n",
    "                }\n",
    "df_ca_bal8_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_bal10 = df[(df['FORMATION_up'] == 'Balakhany X') & (df['field'] == 'CENTRAL AZERI')]\n",
    "df_ca_bal10_coordinates = {'x_min': df_ca_bal10['X_traj'].min(), \n",
    "                'x_max': df_ca_bal10['X_traj'].max(),\n",
    "                'y_min': df_ca_bal10['Y_traj'].min(),\n",
    "                'y_max': df_ca_bal10['Y_traj'].max(),\n",
    "                'z_min': df_ca_bal10['TVD_SCS'].min(),\n",
    "                'z_max': df_ca_bal10['TVD_SCS'].max()              \n",
    "                }\n",
    "df_ca_bal10_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGY file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = segyio.open(r\"C:\\Users\\NadirZeynalli\\Desktop\\SPP\\GR_cube\\GR_cube_HDOBN_Z.sgy\")\n",
    "\n",
    "v.header[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v.xlines)\n",
    "print(v.ilines)\n",
    "print(v.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(v.xlines))\n",
    "print(len(v.ilines))\n",
    "print(len(v.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.iline[v.ilines[600]][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 15))\n",
    "plt.plot(v.iline[v.ilines[600]][100],v.samples)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21,10))\n",
    "plt.imshow(v.iline[v.ilines[5873]].T, vmin=0, vmax=100)\n",
    "# plt.savefig(r\"C:\\Users\\eiGroup - Nadir\\Desktop\\GR_cube.jpg\")\n",
    "plt.yticks(ticks=plt.yticks()[0][1:], labels=[str(int(ytick) + 1380) for ytick in plt.yticks()[0][1:]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_slice(slice_index):\n",
    "#     plt.figure(figsize=(21,13))\n",
    "#     plt.imshow(v.iline[v.ilines[slice_index]].T, vmin=0, vmax=100)\n",
    "#     plt.yticks(ticks=plt.yticks()[0][1:], labels=[str(int(ytick) + 1380) for ytick in plt.yticks()[0][1:]])\n",
    "#     plt.show()\n",
    "\n",
    "# slice_slider = widgets.IntSlider(min=600, max=6600, step=1, value=600, description='Inline number')\n",
    "# interactive_plot = interactive(plot_slice, slice_index=slice_slider)\n",
    "# interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasio\n",
    "\n",
    "las = lasio.read(r\"C:\\Users\\NadirZeynalli\\Desktop\\SPP\\GR_cube\\well_trajectories2\\K01.las\")\n",
    "\n",
    "k01 = las.df().reset_index()[['X','Y','TVD','DEPTH']]\n",
    "k01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "df = k01\n",
    "\n",
    "new_tvd = np.arange(df['TVD'].min(), df['TVD'].max() + 1)\n",
    "\n",
    "cs_x = CubicSpline(df['TVD'], df['X'])\n",
    "cs_y = CubicSpline(df['TVD'], df['Y'])\n",
    "cs_depth = CubicSpline(df['TVD'], df['DEPTH'])\n",
    "\n",
    "new_x = cs_x(new_tvd)\n",
    "new_y = cs_y(new_tvd)\n",
    "new_depth = cs_depth(new_tvd)\n",
    "\n",
    "interpolated_df = pd.DataFrame({'TVD': new_tvd, 'X': new_x, 'Y': new_y, 'DEPTH':new_depth})\n",
    "\n",
    "interpolated_df = interpolated_df[interpolated_df['TVD'] >= 1380][interpolated_df['TVD'] <= 4250]\n",
    "interpolated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_df.rename(columns={\n",
    "    'X':'CDP_X',\n",
    "    'Y':'CDP_Y'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame of SEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cube = pd.read_parquet(r\"C:\\Users\\NadirZeynalli\\Desktop\\SPP\\GR_cube\\GR_cube_HDOBN_Z.gzip\")\n",
    "df_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cube = df_cube[[\n",
    "    'CDP_X', \n",
    "    'CDP_Y', \n",
    "    'INLINE_3D', \n",
    "    'CROSSLINE_3D'\n",
    "]]\n",
    "\n",
    "df_cube['CDP_X'] /= 100\n",
    "df_cube['CDP_Y'] /= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closest coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "df1 = interpolated_df\n",
    "df2 = df_cube\n",
    "\n",
    "tree = cKDTree(df2[['CDP_X', 'CDP_Y']])\n",
    "\n",
    "distances, indices = tree.query(df1[['CDP_X', 'CDP_Y']])\n",
    "\n",
    "closest_points = df2.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "result = pd.concat([df1.reset_index(drop=True), closest_points], axis=1)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.ilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GR_extract(iline, xline, sample):\n",
    "    iline = iline\n",
    "    xline = xline - 1400\n",
    "    sample = sample - 1380\n",
    "\n",
    "    return v.iline[v.ilines[iline]][xline][sample]\n",
    "\n",
    "result['GR_center'] = result.apply(lambda row: GR_extract(row['INLINE_3D'].astype(int), row['CROSSLINE_3D'].astype(int), row['TVD'].astype(int)), axis=1)\n",
    "# result['GR1'] = result.apply(lambda row: GR_extract(row['INLINE_3D'].astype(int)+1, row['CROSSLINE_3D'].astype(int), row['TVD'].astype(int)), axis=1)\n",
    "# result['GR2'] = result.apply(lambda row: GR_extract(row['INLINE_3D'].astype(int), row['CROSSLINE_3D'].astype(int)+1, row['TVD'].astype(int)), axis=1)\n",
    "# result['GR_center'] = result.apply(lambda row: GR_extract(row['INLINE_3D'].astype(int), row['CROSSLINE_3D'].astype(int)+1, row['TVD'].astype(int)), axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result.plot(x='GR_center', y='DEPTH', figsize=(3, 20))\n",
    "ax.invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others (not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cube_ca_bal8 = df_cube[(df_cube['CDP_X'] / 100 >= df_ca_bal8_coordinates['x_min']) &\n",
    "                          (df_cube['CDP_X'] / 100 <= df_ca_bal8_coordinates['x_max']) &\n",
    "                          (df_cube['CDP_Y'] / 100 >= df_ca_bal8_coordinates['y_min']) &\n",
    "                          (df_cube['CDP_Y'] / 100 <= df_ca_bal8_coordinates['y_max']) \n",
    "                          ]\n",
    "\n",
    "df_cube_ca_bal8 = df_cube_ca_bal8[['CDP_X', 'CDP_Y', 'INLINE_3D', 'CROSSLINE_3D']]\n",
    "df_cube_ca_bal8['CDP_X'] = df_cube_ca_bal8['CDP_X'] / 100\n",
    "df_cube_ca_bal8['CDP_Y'] = df_cube_ca_bal8['CDP_Y'] / 100\n",
    "\n",
    "ca_bal8_inlines = df_cube_ca_bal8['INLINE_3D'].unique().tolist()\n",
    "ca_bal8_crosslines = df_cube_ca_bal8['CROSSLINE_3D'].unique().tolist()\n",
    "\n",
    "ca_bal8_inlines.sort()\n",
    "ca_bal8_crosslines.sort()\n",
    "\n",
    "print(ca_bal8_inlines)\n",
    "print(len(ca_bal8_inlines))\n",
    "\n",
    "print(len(ca_bal8_crosslines))\n",
    "print(ca_bal8_crosslines)\n",
    "\n",
    "\n",
    "df_cube_ca_bal8.sort_values(by=['INLINE_3D', 'CROSSLINE_3D'], inplace=True)\n",
    "\n",
    "df_cube_ca_bal8['INLINE_3D_index'] = df_cube_ca_bal8['INLINE_3D'] - df_cube_ca_bal8['INLINE_3D'].min()\n",
    "df_cube_ca_bal8['CROSSLINE_3D_index'] = df_cube_ca_bal8['CROSSLINE_3D'] - df_cube_ca_bal8['CROSSLINE_3D'].min()\n",
    "\n",
    "df_cube_ca_bal8 = df_cube_ca_bal8[['CDP_X', 'CDP_Y', 'INLINE_3D', 'INLINE_3D_index', 'CROSSLINE_3D', 'CROSSLINE_3D_index']]\n",
    "\n",
    "df_cube_ca_bal8['Z_index'] = np.nan\n",
    "df_cube_ca_bal8['GR_value'] = np.nan\n",
    "\n",
    "df_cube_ca_bal8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code for the whole gr cube\n",
    "\n",
    "volume_samples = []\n",
    "\n",
    "dt = 4\n",
    "iline_range = [-1, 10000]\n",
    "xline_range = [-1, 10000]\n",
    "time_range  = [-1, 10000]\n",
    "iline_xline_spacing = 1\n",
    "\n",
    "mask_il = (iline_range[0] <= v.ilines) & (v.ilines <= iline_range[-1])\n",
    "mask_xl = (xline_range[0] <= v.xlines) & (v.xlines <= xline_range[-1])\n",
    "mask_t  = (time_range[0] <= v.samples) & (v.samples <= time_range[1])\n",
    "\n",
    "\n",
    "\n",
    "for il in tqdm(v.ilines[mask_il]):\n",
    "    v_slice = v.iline[il][mask_xl, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "\n",
    "    volume_samples.append(v_slice)\n",
    "    \n",
    "volume_samples = np.array(volume_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples = []\n",
    "\n",
    "dt = 4\n",
    "iline_range = [-1, 10000]\n",
    "xline_range = [-1, 10000]\n",
    "time_range  = [-1, 10000]\n",
    "iline_xline_spacing = 1\n",
    "\n",
    "mask_il = (ca_bal8_inlines[0] <= v.ilines) & (v.ilines <= ca_bal8_inlines[-1])\n",
    "mask_xl = (ca_bal8_crosslines[0] <= v.xlines) & (v.xlines <= ca_bal8_crosslines[-1])\n",
    "mask_t  = (time_range[0] <= v.samples) & (v.samples <= time_range[1])\n",
    "\n",
    "\n",
    "\n",
    "for il in tqdm(v.ilines[mask_il]):\n",
    "    v_slice = v.iline[il][mask_xl, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "\n",
    "    volume_samples.append(v_slice)\n",
    "    \n",
    "volume_samples = np.array(volume_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inlines_xlines = df_cube_ca_bal8[[ 'INLINE_3D', 'CROSSLINE_3D']].drop_duplicates()\n",
    "df_inlines_xlines.sort_values(by=['INLINE_3D', 'CROSSLINE_3D'], inplace=True)\n",
    "df_inlines_xlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline_crossline_dict = {}\n",
    "\n",
    "for index, row in df_inlines_xlines.iterrows():\n",
    "    inline_3d = row['INLINE_3D']\n",
    "    crossline_3d = row['CROSSLINE_3D']\n",
    "    \n",
    "    # Check if the INLINE_3D already exists in the dictionary\n",
    "    if inline_3d in inline_crossline_dict:\n",
    "        # If it exists, append the CROSSLINE_3D to the existing list\n",
    "        inline_crossline_dict[inline_3d].append(crossline_3d)\n",
    "    else:\n",
    "        # If it doesn't exist, create a new list with the CROSSLINE_3D as the first element\n",
    "        inline_crossline_dict[inline_3d] = [crossline_3d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inline_crossline_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range  = [-1, 10000]\n",
    "iline_xline_spacing = 1\n",
    "\n",
    "\n",
    "mask_t  = (time_range[0] <= v.samples) & (v.samples <= time_range[1])\n",
    "\n",
    "for i in inline_crossline_dict.keys():\n",
    "    for j in inline_crossline_dict[i]:\n",
    "        mask_il = (v.ilines == i)\n",
    "        mask_xl = (v.xlines == j)\n",
    "        \n",
    "        # mask_il = (ca_bal8_inlines[i] = v.ilines) & (v.ilines <= ca_bal8_inlines[-1])\n",
    "        # mask_xl = (ca_bal8_crosslines[] = v.xlines) & (v.xlines <= ca_bal8_crosslines[-1])\n",
    "        \n",
    "        v_slice = v.iline[mask_il][mask_xl, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "        # volume_samples.append(v_slice)\n",
    "        # v_z_slice = v.iline[i][j, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "        # v_val_slice = v.iline[i][j, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "        # print(v_slice)\n",
    "        # print(v_z_slice)\n",
    "        # print(v_val_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples = np.array(volume_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples = []\n",
    "\n",
    "dt = 4\n",
    "iline_range = [-1, 10000]\n",
    "xline_range = [-1, 10000]\n",
    "time_range  = [-1, 10000]\n",
    "iline_xline_spacing = 1\n",
    "\n",
    "mask_il = (iline_range[0] <= v.ilines) & (v.ilines <= iline_range[1])\n",
    "mask_xl = (xline_range[0] <= v.xlines) & (v.xlines <= xline_range[1])\n",
    "mask_t  = (time_range[0] <= v.samples) & (v.samples <= time_range[1])\n",
    "\n",
    "for il in tqdm(v.ilines[mask_il]):\n",
    "    print(il)\n",
    "    # v_slice = v.iline[il][mask_xl, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "\n",
    "    # volume_samples.append(v_slice)\n",
    "    \n",
    "# volume_samples = np.array(volume_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "volume_samples = []\n",
    "\n",
    "dt = 4\n",
    "iline_range = [-1, 10000]\n",
    "xline_range = [-1, 10000]\n",
    "time_range  = [-1, 10000]\n",
    "iline_xline_spacing = 1\n",
    "\n",
    "mask_il = (iline_range[0] <= v.ilines) & (v.ilines <= iline_range[1])\n",
    "mask_xl = (xline_range[0] <= v.xlines) & (v.xlines <= xline_range[1])\n",
    "mask_t  = (time_range[0] <= v.samples) & (v.samples <= time_range[1])\n",
    "\n",
    "# Define a function to process each iline\n",
    "def process_il(il):\n",
    "    v_slice = v.iline[il][mask_xl, :][:, mask_t][::iline_xline_spacing, ::int(dt / (v.samples[1] - v.samples[0]))]\n",
    "    return v_slice\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the loop\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Use tqdm to display a progress bar\n",
    "    futures = [executor.submit(process_il, il) for il in tqdm(v.ilines[mask_il])]\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        volume_samples.append(future.result())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_samples = np.array(volume_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_lst = v.samples.tolist()\n",
    "samples_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_gr = pd.DataFrame(columns=['inline', 'crossline', 'z', 'value'])\n",
    "\n",
    "for i in (ca_bal8_inlines):\n",
    "    for j in (ca_bal8_crosslines):\n",
    "        for k in (range(len(samples_lst))):\n",
    "\n",
    "            if(v.gather[i, j].T[k] != 0):\n",
    "                print(i, j, k)\n",
    "                \n",
    "                # Create a dictionary with the values\n",
    "                data = {\n",
    "                    'inline': i,\n",
    "                    'crossline': j,\n",
    "                    'z': k,\n",
    "                    'value': v.gather[i, j].T[k][0]\n",
    "                }\n",
    "                print(data)\n",
    "                # df_one_sample = pd.DataFrame(data)\n",
    "                # Append the dictionary to the DataFrame\n",
    "                # df_samples_gr = pd.concat([df_samples_gr, data], ignore_index=False)\n",
    "                \n",
    "                df_samples_gr = pd.concat([df_samples_gr, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "\n",
    "\n",
    "                \n",
    "print(df_samples_gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "\n",
    "# Define your DataFrame columns\n",
    "df_samples_gr = pd.DataFrame(columns=['inline', 'crossline', 'z', 'value'])\n",
    "\n",
    "# Define your function to process a single combination of i, j, k\n",
    "def process_combination(i, j, k):\n",
    "    if v.gather[i, j].T[k] != 0:\n",
    "        data = {\n",
    "            'inline': i,\n",
    "            'crossline': j,\n",
    "            'z': k,\n",
    "            'value': v.gather[i, j].T[k][0]\n",
    "        }\n",
    "        print(data)\n",
    "        \n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define your main function\n",
    "def main():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i in ca_bal8_inlines:\n",
    "            for j in ca_bal8_crosslines:\n",
    "                for k in range(len(samples_lst)):\n",
    "                    futures.append(executor.submit(process_combination, i, j, k))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                df_samples_gr = df_samples_gr.append(data, ignore_index=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(df_samples_gr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.xline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v.xline[1500]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.gather[600 , 1400].T[550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_gr = pd.DataFrame(columns=['i', 'j', 'k', 'value'])\n",
    "\n",
    "for i in (v.ilines):\n",
    "    for j in (v.xlines):\n",
    "        for k in (range(len(v.samples))):\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            k = int(k)\n",
    "            \n",
    "            if(v.gather[i, j].T[k] != 0):\n",
    "                print(i, j, k)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.ilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilines_lst = v.ilines.tolist()\n",
    "ilines_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".khstatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

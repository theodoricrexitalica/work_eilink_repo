{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statistics as st\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import geopandas as gpd\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the csv file\n",
    "# path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "# data_init = pd.read_csv(path + 'ACG_wells_JOINT_BEST_v7.csv', sep=',')\n",
    "# # Data cleaning of TL-dataset\n",
    "# df = data_init.copy()\n",
    "# df = df[1:]\n",
    "# #Select only neccessary data\n",
    "# df_cln = df[['wellName', 'DEPTH', 'AREA', 'BADPORLOG', 'Casings', 'FORMATION',\n",
    "#             'FLANK1', 'FLANK2', 'FLUIDS',\n",
    "#             'LPERM', 'PHIT', 'NET', \n",
    "#             'GR_N', 'GRMATRIX', 'GRSHALE','VSH', 'NPSS', 'RHOB', 'RHOF', 'RHOMA', \n",
    "#             'RDEEP',  'SON', 'SONSH', \n",
    "#             'TVD_SCS','TST', 'DEVI','HAZI','X', 'Y', 'Dip_Azimuth', 'Dip_TRU']]\n",
    "# #Fill up nan and -9999 values with 0\n",
    "# df_cln = df_cln.fillna(0)\n",
    "# df_cln = df_cln.replace(-9999, 0)\n",
    "# df_cln = df_cln.replace('-9999', '0')\n",
    "# #Assing proper datatypes for df\n",
    "# dicttypes = {'wellName':'string', 'DEPTH':'float', 'AREA':'int', 'BADPORLOG':'int', 'Casings':'float', 'FLANK1':'int', 'FLANK2':'int',\n",
    "#              'FLUIDS':'int','FORMATION':'string', 'GR_N':'float', 'GRMATRIX':'float', \n",
    "#              'GRSHALE':'float', 'LPERM':'float', 'NPSS':'float',\n",
    "#              'PHIT':'float', 'NET':'float', 'RDEEP':'float', 'RHOB':'float', 'RHOF':'float', 'RHOMA':'float', 'TVD_SCS':'float', 'TST':'float',\n",
    "#              'VSH':'float', 'X':'float', 'Y':'float', 'Dip_Azimuth':'float', 'Dip_TRU':'float'}\n",
    "# df_cln = df_cln.astype(dicttypes, errors='ignore')\n",
    "# df_cln.loc[df_cln.FORMATION=='0', 'FORMATION']='None'\n",
    "#Save data to parquet\n",
    "# df_cln.to_parquet('ACG_wells_JOINT_BEST_v7.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading metadata, distribution wells per Platforms and all the that.\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "metadata = metadata_init.copy()\n",
    "metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "metadata.Status = metadata.Status.str.strip()\n",
    "metadata.Status = metadata.Status.str.lower()\n",
    "metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "\n",
    "#Read data from parquet\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v10.parquet.gzip')\n",
    "df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "# print('wells in df totally:', len(df_prq.well.unique()))\n",
    "# Filter data with bad_well_list \n",
    "bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP']\n",
    "df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "#Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "df_prq.loc[df_prq.FLUIDS>0, 'FLUIDS_int'] = 1\n",
    "df_prq.loc[df_prq.FLUIDS<=0, 'FLUIDS_int'] = 0\n",
    "df_prq.FLUIDS_int = df_prq.FLUIDS_int.astype('int')\n",
    "#Getting XY coords of Balakhany formation tops\n",
    "xy_coord = df_prq[['well', 'FORMATION', 'X', 'Y']]\n",
    "xy_coord = xy_coord.groupby(['well', 'FORMATION']).apply(lambda x: x.iloc[0]).drop(columns=['well', 'FORMATION']).reset_index()\n",
    "xy_coord = xy_coord[xy_coord.FORMATION.str.contains('Balakhany') & (xy_coord.X>0) & (xy_coord.Y>0)]\n",
    "#Find top TVD_SCS for each formation\n",
    "df_prq_tvdss = df_prq[['well','MD','FORMATION','TVD_SCS']].groupby(['well','FORMATION']).apply(lambda x: x.iloc[0])\n",
    "df_prq_tvdss = df_prq_tvdss.drop(['well','FORMATION'], axis=1).reset_index()\n",
    "df_prq_tvdss = df_prq_tvdss[df_prq_tvdss.TVD_SCS>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataset for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd_fld[df_khtst_xy_tvd_fld.TVD_SCS.notna()]\n",
    "#Clean dataset for outliers for Balakhany VIII & X  for AZR and CHG fields by rule 1.5 * IQR\n",
    "fm_list_8_10 = ['Balakhany VIII', 'Balakhany VIII sand', 'Balakhany VIII 25','Balakhany VIII 20', \n",
    "                'Balakhany VIII 15', 'Balakhany VIII 10', 'Balakhany VIII 5',\n",
    "                'Balakhany X', 'Balakhany X sand', 'Balakhany X 40', 'Balakhany X 20'] \n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_lst = []\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(azr_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} azr IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(chg_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} chg IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "df_khtst_bal_qcl = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                                            df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                                            ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                                            ['well','FORMATION'], axis=1)\n",
    "                                                            ).reset_index()\n",
    "# Function to display well plots with logging curves\n",
    "def well_display(wellname, fmname):\n",
    "    data = df_prq[(df_prq.well==wellname) & (df_prq.FORMATION == fmname)]\n",
    "    depth = data['MD']\n",
    "    grn = data['GR_N']\n",
    "    rhob = data['RHOB'] \n",
    "    npss = data['NPSS']\n",
    "    rdeep = data['RDEEP']\n",
    "    phit = data['PHIT'] \n",
    "    fluid = data['gross_pay']\n",
    "    perm = data['LPERM']\n",
    "    fig, ax = plt.subplots(1,5, figsize=(7,7), sharey=True)\n",
    "    ax[0].plot(grn, depth, color='lightgreen'), ax[0].invert_yaxis(), ax[0].set_xlim(0, 150)\n",
    "    ax[1].plot(rhob, depth, color='red'), ax[1].invert_yaxis(), ax[1].set_xlim(1.65, 2.65)\n",
    "    twin1 = ax[1].twiny()\n",
    "    twin1.plot(npss, depth, color='blue')\n",
    "    twin1.set_xlim(0.6, 0)\n",
    "    ax[2].plot(rdeep, depth, color='black'), ax[2].set_xscale('log'), ax[2].set_xlim(1, 100), ax[2].invert_yaxis(), ax[2].grid(axis='x', which='both')\n",
    "    ax[3].plot(phit, depth, color='green'), ax[3].set_xlim(0.3, 0), ax[3].grid(axis='x'), ax[3].invert_yaxis()\n",
    "    ax[3].vlines(0.13, ymin=min(depth), ymax=max(depth), color='black', linestyle='dashed')\n",
    "    twin2 = ax[3].twiny()\n",
    "    twin2.plot(fluid, depth, color='orange', linewidth=0.5)\n",
    "    twin2.fill_betweenx(depth,fluid, color='orange', alpha=0.33)\n",
    "    twin2.set_xlim(0, 1)\n",
    "    twin2.set_ylim(min(depth), max(depth))\n",
    "    ax[4].plot(perm, depth, color='purple'), ax[4].set_xscale('log'), ax[4].set_xlim(1, 1000), ax[4].grid(axis='x'), ax[4].invert_yaxis()\n",
    "    fig.suptitle(wellname + ' ' + fmname, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(dist_formation, iqr_clean, iqr_wells):\n",
    "    \"\"\"\n",
    "    dist_formation, iqr_clean=f(1,0), iqr_wells == df_khtst_bal_qcl\n",
    "    \"\"\"\n",
    "    data = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == dist_formation) & (df_khtst_xy_tvd_fld.X > 0) & (df_khtst_xy_tvd_fld.Y > 0)]\n",
    "    if iqr_clean == 1:\n",
    "        data = data[data.well.isin(iqr_wells)]\n",
    "    else:\n",
    "        pass\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "#Collecting of EucDist, XY and KHtst data \n",
    "def well_kh_accum(data, kh_formation):\n",
    "    well_kh_accum = []\n",
    "    well_x_accum = []\n",
    "    well_y_accum = []\n",
    "    for i in data:\n",
    "        well_kh_accum.append(df_khtst_xy[(df_khtst_xy.well==i)&(df_khtst_xy.FORMATION == kh_formation)]['KHtst'].reset_index())    \n",
    "        well_x_accum.append(df_khtst_xy[(df_khtst_xy.well==i)&(df_khtst_xy.FORMATION == kh_formation)]['X'].reset_index())\n",
    "        well_y_accum.append(df_khtst_xy[(df_khtst_xy.well==i)&(df_khtst_xy.FORMATION == kh_formation)]['Y'].reset_index())\n",
    "    well_kh3 = pd.concat(well_kh_accum).T[1:]\n",
    "    well_kh3.columns = ['kh1','kh2','kh3']\n",
    "    well_x3 = pd.concat(well_x_accum).T[1:]\n",
    "    well_x3.columns = ['x1','x2','x3']\n",
    "    well_y3 = pd.concat(well_y_accum).T[1:]\n",
    "    well_y3.columns = ['y1','y2','y3']\n",
    "    final = pd.concat([ well_kh3.reset_index().drop('index',axis=1), \n",
    "                        well_x3.reset_index().drop('index',axis=1), \n",
    "                        well_y3.reset_index().drop('index',axis=1)], axis=1)\n",
    "    return final\n",
    "#Collecting of Dist & Wells data togher with func(well_kh_accum)\n",
    "def well_offsets_collection(dist_dataset, off_formation, kh_dataset, metadata):\n",
    "    df_collect = []\n",
    "    for num, well_name in enumerate(dist_dataset.well[:]):\n",
    "        well_dist3 = dist_dataset[dist_dataset.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "        well_dist3_tuple = tuple(well_dist3['index'])\n",
    "        well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)   \n",
    "        well_name3_res = well_dist3.T[:1].reset_index().drop('index', axis=1)\n",
    "        well_kh3_res = well_kh_accum(well_dist3_tuple, off_formation)\n",
    "        well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "        well_name3_res.columns =['well1', 'well2', 'well3']\n",
    "        concat_df = pd.concat([well_dist3_res, well_kh3_res, well_name3_res], axis=1)\n",
    "        result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "        df_collect.append(result)       \n",
    "    df_well_kh_dist = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "    df_khtst_xy_bal = kh_dataset[kh_dataset.FORMATION==off_formation][['well', 'FORMATION', 'KHtst']]\n",
    "    df_well_kh_dist_frm = df_well_kh_dist.set_index('well').join(df_khtst_xy_bal.set_index('well')).reset_index()\n",
    "    df_well_kh_dist_frm_fld = df_well_kh_dist_frm.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "    return df_well_kh_dist_frm_fld\n",
    "#Calculating avg properties and collecting df per FU\n",
    "def df_avg_properties(formation_avg_prop, df_avg_prop, df_joined):\n",
    "    df_hpv = df_joined[df_joined.FORMATION == formation_avg_prop][['well','FORMATION','res_tst','phit_wavg','vsh_wavg']]\n",
    "    df_permh = df_avg_prop[df_avg_prop.FORMATION == formation_avg_prop].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "    df_phhpv = df_hpv.set_index(['well','FORMATION']).join(df_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "    return df_phhpv\n",
    "#Rotate x,y around xo,yo by theta (rad)\n",
    "def rotate(x,y): \n",
    "    theta = (math.pi/180)*34\n",
    "    xo = st.median(np.array(df_khtst_xy['X'].to_list()))\n",
    "    yo = st.median(np.array(df_khtst_xy['Y'].to_list()))\n",
    "    xr = math.cos(theta)*(x-xo)-math.sin(theta)*(y-yo) + xo\n",
    "    yr = math.sin(theta)*(x-xo)+math.cos(theta)*(y-yo) + yo\n",
    "    return [xr,yr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting wells without outliers\n",
    "well_clean_8a = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII')].well \n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10a = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "well_clean_10_20 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X 20')].well\n",
    "well_clean_10_40 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X 40')].well\n",
    "well_clean_8_25 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII 25')].well\n",
    "well_clean_8_20 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII 20')].well\n",
    "well_clean_8_15 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII 15')].well\n",
    "well_clean_8_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII 10')].well\n",
    "well_clean_8_5 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII 5')].well\n",
    "# Distance calculation\n",
    "qc_n = 1\n",
    "dist_bal8a = well_dist_calc('Balakhany VIII', qc_n, well_clean_8a)\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand', qc_n, well_clean_8)\n",
    "dist_bal10a = well_dist_calc('Balakhany X', qc_n, well_clean_10a)\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand', qc_n, well_clean_10)\n",
    "dist_bal10_20 = well_dist_calc('Balakhany X 20', qc_n, well_clean_10_20)\n",
    "dist_bal10_40 = well_dist_calc('Balakhany X 40', qc_n, well_clean_10_40)\n",
    "dist_bal8_25 = well_dist_calc('Balakhany VIII 25', qc_n, well_clean_8_25)\n",
    "dist_bal8_20 = well_dist_calc('Balakhany VIII 20', qc_n, well_clean_8_20)\n",
    "dist_bal8_15 = well_dist_calc('Balakhany VIII 15', qc_n, well_clean_8_15)\n",
    "dist_bal8_10 = well_dist_calc('Balakhany VIII 10', qc_n, well_clean_8_10)\n",
    "dist_bal8_5 = well_dist_calc('Balakhany VIII 5', qc_n, well_clean_8_5)\n",
    "# Creating datasets according to FU\n",
    "df_well_kh_dist_bal8a_fld = well_offsets_collection(dist_bal8a, 'Balakhany VIII', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_fld = well_offsets_collection(dist_bal8, 'Balakhany VIII sand', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_25_fld = well_offsets_collection(dist_bal8_25, 'Balakhany VIII 25', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_20_fld = well_offsets_collection(dist_bal8_20, 'Balakhany VIII 20', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_15_fld = well_offsets_collection(dist_bal8_15, 'Balakhany VIII 15', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_10_fld = well_offsets_collection(dist_bal8_10, 'Balakhany VIII 10', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal8_5_fld = well_offsets_collection(dist_bal8_5, 'Balakhany VIII 5', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal10a_fld = well_offsets_collection(dist_bal10a, 'Balakhany X', df_khtst_xy, metadata)                                   \n",
    "df_well_kh_dist_bal10_fld = well_offsets_collection(dist_bal10, 'Balakhany X sand', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal10_40_fld = well_offsets_collection(dist_bal10_40, 'Balakhany X 40', df_khtst_xy, metadata)\n",
    "df_well_kh_dist_bal10_20_fld = well_offsets_collection(dist_bal10_20, 'Balakhany X 20', df_khtst_xy, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenation all dist-datasets                                                  \n",
    "df_well_kh_dist_all = pd.concat([   df_well_kh_dist_bal8a_fld,\n",
    "                                    df_well_kh_dist_bal8_fld,    \n",
    "                                    df_well_kh_dist_bal8_25_fld,\n",
    "                                    df_well_kh_dist_bal8_20_fld,\n",
    "                                    df_well_kh_dist_bal8_15_fld,\n",
    "                                    df_well_kh_dist_bal8_10_fld, \n",
    "                                    df_well_kh_dist_bal8_5_fld,\n",
    "                                    df_well_kh_dist_bal10a_fld,                                    \n",
    "                                    df_well_kh_dist_bal10_fld,\n",
    "                                    df_well_kh_dist_bal10_40_fld,\n",
    "                                    df_well_kh_dist_bal10_20_fld])\n",
    "df_well_kh_dist_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of TST-thickness Balakhany VIII & X\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'MD','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "#Joining coordinates datasets\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = -1\n",
    "cutoff_perm_avg = -1\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'res_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.res_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.res_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating avg properties and collecting df per FU\n",
    "df_8abal_phhpv = df_avg_properties('Balakhany VIII', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_phhpv = df_avg_properties('Balakhany VIII sand', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_10abal_phhpv = df_avg_properties('Balakhany X', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_10bal_phhpv = df_avg_properties('Balakhany X sand', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_10bal_20_phhpv = df_avg_properties('Balakhany X 20', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_10bal_40_phhpv = df_avg_properties('Balakhany X 40', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_25_phhpv = df_avg_properties('Balakhany VIII 25', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_20_phhpv = df_avg_properties('Balakhany VIII 20', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_15_phhpv = df_avg_properties('Balakhany VIII 15', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_10_phhpv = df_avg_properties('Balakhany VIII 10', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "df_8bal_5_phhpv = df_avg_properties('Balakhany VIII 5', df_htst_avgprop_nz, df_htst_avgprop_nz_avgpropsum_join)\n",
    "#Concatenation of all df per FU\n",
    "df_all_bal_phhpv = pd.concat([  df_8abal_phhpv, df_8bal_phhpv, df_10abal_phhpv, df_10bal_phhpv, df_10bal_20_phhpv, df_10bal_40_phhpv, \n",
    "                                df_8bal_25_phhpv, df_8bal_20_phhpv, df_8bal_15_phhpv, df_8bal_10_phhpv, df_8bal_5_phhpv])\n",
    "df_all_bal_phhpv_tstint = df_all_bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_avgprop_final_wa = df_all_bal_phhpv_tstint.copy()\n",
    "df_avgprop_final_wa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Shahriyar\n",
    "perm_cutoff = -1\n",
    "perm_cutoff_top = 140_000\n",
    "df_dist_kh_bal_shahriayr_init = df_avgprop_final_wa.set_index(['well','FORMATION']).join(\n",
    "                                df_well_kh_dist_all.drop('field',axis=1).set_index(['well','FORMATION'])).reset_index()\n",
    "df_dist_kh_bal_shahriayr_init.rename(columns={'TST_interv':'interv_tst', 'TST_top':'tst_top', 'TST_bot':'tst_bot'}, inplace=True)\n",
    "df_dist_kh_bal_shahriayr = df_dist_kh_bal_shahriayr_init[df_dist_kh_bal_shahriayr_init.MD.notna()]\n",
    "df_dist_kh_bal_shahriayr = df_dist_kh_bal_shahriayr[ (df_dist_kh_bal_shahriayr.kh1>perm_cutoff) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kh2>perm_cutoff) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kh3>perm_cutoff) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kavg_htst>perm_cutoff)]\n",
    "df_dist_kh_bal_shahriayr = df_dist_kh_bal_shahriayr[ (df_dist_kh_bal_shahriayr.kh1<perm_cutoff_top) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kh2<perm_cutoff_top) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kh3<perm_cutoff_top) &\n",
    "                                                     (df_dist_kh_bal_shahriayr.kavg_htst<perm_cutoff_top)]\n",
    "df_dist_kh_bal_shahriayr.loc[df_dist_kh_bal_shahriayr.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "df_dist_kh_bal_shahriayr.loc[df_dist_kh_bal_shahriayr.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "df_dist_kh_bal_shahriayr['kavg_htst_lg10'] = np.log10(df_dist_kh_bal_shahriayr['kavg_htst'])\n",
    "df_dist_kh_bal_shahriayr['kh1_lg10'] = np.log10(df_dist_kh_bal_shahriayr['kh1'])\n",
    "df_dist_kh_bal_shahriayr['kh2_lg10'] = np.log10(df_dist_kh_bal_shahriayr['kh2'])\n",
    "df_dist_kh_bal_shahriayr['kh3_lg10'] = np.log10(df_dist_kh_bal_shahriayr['kh3'])\n",
    "df_dist_kh_bal_shahriayr[['X_new', 'Y_new']] = df_dist_kh_bal_shahriayr.apply(lambda row: rotate(row['X'], row['Y']), axis=1, result_type='expand')\n",
    "df_dist_kh_bal_shahriayr = pd.get_dummies(df_dist_kh_bal_shahriayr, columns = ['FORMATION_up'])\n",
    "# df_dist_kh_bal_shahriayr_init.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize all FU tst_interv for Bal 8 & Bal 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution tst-thickness Balaknany VIII / X over Chirag and Azeri zones\n",
    "# Calculation of TST-thickness Balakhany VIII & X\n",
    "def histo_creation(data_ds1,ds1_label, data_ds2, ds2_label, title_ds):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(\n",
    "                x=data_ds1.TST_interv, \n",
    "                xbins=dict(start=0, end=300 , size=5), marker_color='yellow', name=ds1_label))\n",
    "    fig.add_trace(go.Histogram(\n",
    "                x=data_ds2.TST_interv, \n",
    "                xbins=dict(start=0, end=300, size=5), marker_color='blue', name=ds2_label))\n",
    "    fig.update_traces(opacity=0.75)\n",
    "    fig.update_layout(title_text=title_ds,\n",
    "                    xaxis_title_text='tst_thickness', yaxis_title_text='Count',\n",
    "                    autosize=True, width=1000, height=300, margin=dict(l=10,r=10,b=10,t=40))\n",
    "    fig.update_layout(barmode='stack')\n",
    "    fig.update_xaxes(nticks=40, showgrid=True)\n",
    "    return fig.show()\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'MD','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'DDGG', 'field_num'] = 1\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'DWG', 'field_num'] = 2\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'WEST CHIRAG', 'field_num'] = 3\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'CHIRAG', 'field_num'] = 4\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'WEST AZERI', 'field_num'] = 5\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'CENTRAL AZERI', 'field_num'] = 6\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'EAST AZERI', 'field_num'] = 7\n",
    "# Summarize all FU tst_interv for Bal 8 & Bal 10\n",
    "df_fu_tst_final_8 = df_fu_tst_final[df_fu_tst_final.FORMATION.str.contains('Balakhany VIII')]\n",
    "df_fu_tst_final_10 = df_fu_tst_final[df_fu_tst_final.FORMATION.str.contains('Balakhany X')]\n",
    "df_fu_tst_final_10_tstinterv = df_fu_tst_final_10.groupby('well')['TST_interv'].sum().reset_index()\n",
    "df_fu_tst_final_8_tstinterv = df_fu_tst_final_8.groupby('well')['TST_interv'].sum().reset_index()\n",
    "df_8_tstinterv = df_fu_tst_final_8_tstinterv.set_index('well').join(df_fu_tst_final_8[['well','field_num']].set_index('well'))\n",
    "df_10_tstinterv = df_fu_tst_final_10_tstinterv.set_index('well').join(df_fu_tst_final_10[['well','field_num']].set_index('well'))\n",
    "# Distribution tst-thickness Balaknany VIII / X over Chirag and Azeri zones\n",
    "df_8_tstinterv_chi = df_8_tstinterv[df_8_tstinterv.field_num <= 4]\n",
    "df_8_tstinterv_azr = df_8_tstinterv[df_8_tstinterv.field_num > 4]\n",
    "df_10_tstinterv_chi = df_10_tstinterv[df_10_tstinterv.field_num <= 4]\n",
    "df_10_tstinterv_azr = df_10_tstinterv[df_10_tstinterv.field_num > 4]\n",
    "# Histograms per Bal8 & Bal10\n",
    "histo_creation(df_8_tstinterv_chi, 'bal8_crg', df_8_tstinterv_azr, 'bal8_azr', 'Bal 8 chi & azr')\n",
    "histo_creation(df_10_tstinterv_chi, 'bal10_crg', df_10_tstinterv_azr, 'bal10_azr','Bal 10 chi & azr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building map KHtst for whole Bal_8 and Bal_10 intervals with summarization of all subsidiary FU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading df_avgprop_final_wa and getting outliers\n",
    "df_summ_bal810 = df_avgprop_final_wa.copy()\n",
    "df_summ_bal810.loc[df_summ_bal810.FORMATION.str.contains('Balakhany X'), 'FORMATION_up'] = 'Balakhany X'\n",
    "df_summ_bal810.loc[df_summ_bal810.FORMATION.str.contains('Balakhany VIII'), 'FORMATION_up'] = 'Balakhany VIII'\n",
    "df_bal8_10 = df_summ_bal810.copy()\n",
    "df_bal8_10_gb = df_bal8_10.groupby(['well','FORMATION_up'])['kavg_htst'].sum().reset_index()\n",
    "df_bal8_10_gb_xy = df_bal8_10.groupby(['well','FORMATION_up'])[['X','Y','TVD_SCS']].mean().reset_index()\n",
    "df_bal8_10_fin = df_bal8_10_gb.set_index(['well', 'FORMATION_up']).join(df_bal8_10_gb_xy.set_index(['well', 'FORMATION_up'])).reset_index()\n",
    "df_bal8_10_fin_fld = df_bal8_10_fin.set_index(['well']).join(df_bal8_10[['well','field']].set_index(['well']), how='inner').reset_index()\n",
    "df_bal8_10_fin_fld.drop_duplicates(subset=['X','Y','field'], keep='first', inplace=True)\n",
    "df_bal8_10_fin_fld.rename(columns={'kavg_htst':'kavg_htst_up'}, inplace=True)\n",
    "df_bal8_10_fin_fld['kavg_htst_up'] = df_bal8_10_fin_fld.kavg_htst_up.round(0)\n",
    "df_bal8_10_fin_fld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file(\"input\\polygons_geojson\\E10_tbal_Poor_Data_Quality_ZARF_5174_M400000_QLSKPrSDM_meaefx.ptd.geojson\")\n",
    "# gdf.plot(aspect='equal', figsize=(12,8))\n",
    "# plt.grid()\n",
    "# plt.scatter(df_bal8_10_fin_fld.X, df_bal8_10_fin_fld.Y, c='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_kh_2plots(metadata, kh_dataset, formation, kh_value, multi_chr = 0.002, multi_azr = 0.001):\n",
    "    \"\"\"\n",
    "    metadata, \n",
    "    kh_dataset = df_khtst_xy_tvd_fld, \n",
    "    formation = 'Balakhany VIII',  \n",
    "    kh_value = 'KHtst',\n",
    "    multi_chr = 0.001, multi_azr = 0.001\n",
    "    \"\"\"\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=(\"CHG, 0.0025\", \"AZR, 0.0075\"), \n",
    "                        vertical_spacing = 0.025)\n",
    "    azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "    chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "    field_avg_coord = metadata.groupby('field')[['X_wellhead','Y_wellhead']].mean().reset_index()\n",
    "    field_avg_coord_chg = field_avg_coord[field_avg_coord.field.isin(chg_lst)]\n",
    "    field_avg_coord_azr = field_avg_coord[field_avg_coord.field.isin(azr_lst)] \n",
    "    df_chg = kh_dataset[(kh_dataset.FORMATION == formation) & (kh_dataset.field.isin(chg_lst))]\n",
    "    df_azr = kh_dataset[(kh_dataset.FORMATION == formation) & (kh_dataset.field.isin(azr_lst))]\n",
    "    # df_khtst_xy_10high = df_khtst_xy_tvd[(df_khtst_xy_tvd.FORMATION == 'Balakhany X sand') & (df_khtst_xy_tvd.well.isin(khtst_map_hwells))]\n",
    "    fig.add_trace(go.Scatter(x=df_chg.X, y=df_chg.Y, customdata = df_chg[['well', kh_value]],\n",
    "                            marker=dict(color=df_chg.TVD_SCS, size=df_chg[kh_value]*multi_chr, colorscale='Viridis_r',  showscale=True,\n",
    "                            line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            mode='markers', name='KHtst chirag', hovertemplate=\"\".join([\"well:%{customdata[0]}, KHtst:%{customdata[1]}<extra></extra>\"])),\n",
    "                            row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=field_avg_coord_chg.X_wellhead, y=field_avg_coord_chg.Y_wellhead, customdata = field_avg_coord_chg[['field']],\n",
    "                            text=field_avg_coord_chg['field'], textposition=\"middle right\",\n",
    "                            marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                            mode='markers+text', name='Platforms', \n",
    "                            marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])),\n",
    "                            row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df_azr.X, y=df_azr.Y, customdata = df_azr[['well', kh_value]],\n",
    "                            marker=dict(color=df_azr.TVD_SCS, size=df_azr[kh_value]*multi_azr, colorscale='Viridis_r',  showscale=False,\n",
    "                            line=dict(color='rgb(47, 57, 61)', width=0.5)),\n",
    "                            mode='markers', name='KHtst azeri', hovertemplate=\"\".join([\"well:%{customdata[0]}, KHtst:%{customdata[1]}<extra></extra>\"])),\n",
    "                            row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=field_avg_coord_azr.X_wellhead, y=field_avg_coord_azr.Y_wellhead, customdata = field_avg_coord_azr[['field']],\n",
    "                            text=field_avg_coord_azr['field'], textposition=\"middle right\",\n",
    "                            marker=dict(color='rgb(0, 0,0)', size=12),\n",
    "                            mode='markers+text', name='Platforms', \n",
    "                            marker_symbol='square', hovertemplate=\"\".join([\"%{customdata[0]}<extra></extra>\"])),\n",
    "                            row=2, col=1)\n",
    "    fig.update_layout(title_text= formation + 'size=f(KHtst), color=f(TVD_SCS), cleaned by rule 1.5*IQR',\n",
    "                    autosize=True, width=1300, height=1400, margin=dict(l=10,r=10,b=10,t=50))\n",
    "    fig.update_layout(legend=dict( yanchor=\"top\", y=1, xanchor=\"right\", x=1, bgcolor='rgba(255,255,255,1)', bordercolor='Black',borderwidth=1))\n",
    "    return fig.show()\n",
    "map_kh_2plots(metadata, df_khtst_xy_tvd_fld, 'Balakhany VIII', 'KHtst', 0.02, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_khtst_xy_tvd_fld.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formation = 'Balakhany VIII'\n",
    "# for well in df_khtst_xy_tvd_fld[df_khtst_xy_tvd_fld.FORMATION == formation].well.unique()[:5]:\n",
    "#     well_display(well, formation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well plot verifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_prq[((df_prq.FORMATION == fmname) & (df_prq.PHIT>0.13))].well.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmname = 'Balakhany VIII'\n",
    "for w in df_prq[(df_prq.FORMATION == fmname)].well.unique():\n",
    "    well_display(w, fmname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

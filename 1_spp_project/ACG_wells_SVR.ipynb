{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libs \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import statistics as st\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from statistics import mean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the ACG_wells_JOINT_BEST_v6.csv file\n",
    "# path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "# data_init = pd.read_csv(path + 'ACG_wells_JOINT_BEST_v6.csv', sep=',')\n",
    "# # Data cleaning of TL-dataset\n",
    "# df = data_init.copy()\n",
    "# df = df[1:]\n",
    "# #Select only neccessary data\n",
    "# df_cln = df[['wellName', 'DEPTH', 'AREA', 'BADPORLOG', 'Casings', 'FORMATION',\n",
    "#             'FLANK1', 'FLANK2', 'Fluidcode', 'Fluidcode_mod', 'FLUIDCODE_PP',\n",
    "#             'LPERM', 'PHIT', 'NET', \n",
    "#             'GR_N', 'GRMATRIX', 'GRSHALE','VSH', 'NPSS', 'RHOB', 'RHOF', 'RHOMA', \n",
    "#             'RDEEP',  'SON', 'SONSH', \n",
    "#             'TVD_SCS','TST', 'DEVI','HAZI','X', 'Y', 'Dip_Azimuth', 'Dip_TRU']]\n",
    "# #Fill up nan and -9999 values with 0\n",
    "# df_cln = df_cln.fillna(0)\n",
    "# df_cln = df_cln.replace(-9999, 0)\n",
    "# df_cln = df_cln.replace('-9999', '0')\n",
    "# #Assing proper datatypes for df\n",
    "# dicttypes = {'wellName':'string', 'DEPTH':'float', 'AREA':'int', 'BADPORLOG':'int', 'Casings':'float', 'FLANK1':'int', 'FLANK2':'int',\n",
    "#              'Fluidcode':'int', 'Fluidcode_mod':'int','FLUIDCODE_PP':'int','FORMATION':'string', 'GR_N':'float', 'GRMATRIX':'float', \n",
    "#              'GRSHALE':'float', 'LPERM':'float', 'NPSS':'float',\n",
    "#              'PHIT':'float', 'NET':'float', 'RDEEP':'float', 'RHOB':'float', 'RHOF':'float', 'RHOMA':'float', 'TVD_SCS':'float', 'TST':'float',\n",
    "#              'VSH':'float', 'X':'float', 'Y':'float', 'Dip_Azimuth':'float', 'Dip_TRU':'float'}\n",
    "# df_cln = df_cln.astype(dicttypes, errors='ignore')\n",
    "# df_cln.loc[df_cln.FORMATION=='0', 'FORMATION']='None'\n",
    "# #Save data to parquet\n",
    "# df_cln.to_parquet('ACG_wells_JOINT_BEST_v6.parquet.gzip', compression='gzip')\n",
    "\n",
    "#Loading metadata, distribution wells per Platforms and all the that.\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "metadata_init = pd.read_csv(path + 'ACG_wells_metadata.csv', sep=',')\n",
    "metadata = metadata_init.copy()\n",
    "metadata = metadata.rename(columns={'X':'X_wellhead', 'Y':'Y_wellhead'})\n",
    "metadata.Status = metadata.Status.str.strip()\n",
    "metadata.Status = metadata.Status.str.lower()\n",
    "metadata.loc[metadata.Status == 'oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'oil producer', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'produiction oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'production_oil', 'Status' ] = 'production oil'\n",
    "metadata.loc[metadata.Status == 'abandoned production oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned  oil', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'abandoned oi', 'Status' ] = 'abandoned oil'\n",
    "metadata.loc[metadata.Status == 'injector  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injector water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'injetor  - water', 'Status' ] = 'injector - water'\n",
    "metadata.loc[metadata.Status == 'abandoned injector - water per b', 'Status' ] = 'abandoned injector - water'\n",
    "metadata.loc[metadata.Status == 'plugged and abandoned', 'Status' ] = 'p&a'\n",
    "metadata.loc[metadata.X_wellhead==118.270, 'X_wellhead'] = 526258.84\n",
    "metadata.loc[metadata.Y_wellhead==526261.510, 'Y_wellhead'] = 4435802.01\n",
    "metadata.loc[metadata.well=='C39', 'X_wellhead'] = 526258.840\n",
    "metadata.loc[metadata.well=='C39', 'Y_wellhead'] = 4435802.010\n",
    "metadata.loc[metadata.field=='West Azeri', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.field=='COP', 'field'] = 'WEST CHIRAG'\n",
    "metadata.loc[metadata.well=='AZERI2', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='AZERI3', 'field'] = 'WEST AZERI'\n",
    "metadata.loc[metadata.well=='B31', 'field'] = 'CENTRAL AZERI'\n",
    "metadata.loc[metadata.well=='J28_bpQIP', 'field'] = 'WEST CHIRAG'\n",
    "\n",
    "#Read data from parquet\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "df_prq = pd.read_parquet(path + 'ACG_wells_JOINT_BEST_v6.parquet.gzip')\n",
    "df_prq.rename(columns={'wellName':'well'}, inplace=True)\n",
    "df_prq = df_prq.set_index('well').join(metadata.set_index('well')).reset_index()\n",
    "# print('wells in df totally:', len(df_prq.well.unique()))\n",
    "# Filter data with bad_well_list \n",
    "bad_well_list = ['E10Z','Predrill_J01Z', 'Predrill_J08', 'J28_bpQIP']\n",
    "df_prq = df_prq[~df_prq.well.isin(bad_well_list)]\n",
    "#Assign any Fluidcode_mod number by variable gross_pay=1 and gross_pay=0 if Fluidcode_mod as NaN\n",
    "df_prq.loc[df_prq.Fluidcode_mod>0, 'gross_pay'] = 1\n",
    "df_prq.loc[df_prq.Fluidcode_mod<=0, 'gross_pay'] = 0\n",
    "df_prq.gross_pay = df_prq.gross_pay.astype('int')\n",
    "#Getting XY coords of Balakhany formation tops\n",
    "xy_coord = df_prq[['well', 'FORMATION', 'X', 'Y']]\n",
    "xy_coord = xy_coord.groupby(['well', 'FORMATION']).apply(lambda x: x.iloc[0]).drop(columns=['well', 'FORMATION']).reset_index()\n",
    "xy_coord = xy_coord[xy_coord.FORMATION.str.contains('Balakhany') & (xy_coord.X>0) & (xy_coord.Y>0)]\n",
    "#Find top TVD_SCS for each formation\n",
    "df_prq_tvdss = df_prq[['well','DEPTH','FORMATION','TVD_SCS']].groupby(['well','FORMATION']).apply(lambda x: x.iloc[0])\n",
    "df_prq_tvdss = df_prq_tvdss.drop(['well','FORMATION'], axis=1).reset_index()\n",
    "df_prq_tvdss = df_prq_tvdss[df_prq_tvdss.TVD_SCS>0]\n",
    "\n",
    "# Assigning numerical values insted text names\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'DDGG', 'field_num'] = 1\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'DWG', 'field_num'] = 2\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'WEST CHIRAG', 'field_num'] = 3\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'CHIRAG', 'field_num'] = 4\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'WEST AZERI', 'field_num'] = 5\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'CENTRAL AZERI', 'field_num'] = 6\n",
    "df_fu_tst_final.loc[df_fu_tst_final.field == 'EAST AZERI', 'field_num'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataset for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "#Clean dataset for outliers for Balakhany VIII & X  for AZR and CHG fields by rule 1.5 * IQR\n",
    "fm_list_8_10 = ['Balakhany VIII', 'Balakhany VIII sand', 'Balakhany VIII 25','Balakhany VIII 20', \n",
    "                'Balakhany VIII 15', 'Balakhany VIII 10', 'Balakhany VIII 5',\n",
    "                'Balakhany X', 'Balakhany X sand', 'Balakhany X 40', 'Balakhany X 20'] \n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "df_lst = []\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(azr_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} azr IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "for fm in fm_list_8_10:\n",
    "    df_khtst_fm = df_khtst_xy_tvd_fld[(df_khtst_xy_tvd_fld.FORMATION == fm) & (df_khtst_xy_tvd_fld.field.isin(chg_lst))]\n",
    "    Q1 = df_khtst_fm['KHtst'].quantile(0.25)\n",
    "    Q3 = df_khtst_fm['KHtst'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # print(f'bal {fm} chg IQR', IQR, 'bot limit:', (Q1 - 1.5 * IQR), 'top limit:', (Q3 + 1.5 * IQR))\n",
    "    df_khtst_fm_qcl = df_khtst_fm[~((df_khtst_fm['KHtst'] < (Q1 - 1.5 * IQR)) | (df_khtst_fm['KHtst'] > (Q3 + 1.5 * IQR)))]\n",
    "    df_lst.append(df_khtst_fm_qcl)\n",
    "df_khtst_bal_qcl = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting TST-thick Bal VIII & X + uploading df_prq_htst_avgprop_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution tst-thickness Balaknany VIII / X over Chirag and Azeri zones\n",
    "#Calculation of TST-thickness Balakhany VIII & X\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_8bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_8bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany VIII sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_8bal_phhpv = df_8bal_hpv.set_index(['well','FORMATION']).join(df_8bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany X sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_10bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany X sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_10bal_phhpv = df_10bal_hpv.set_index(['well','FORMATION']).join(df_10bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# #Preparing x,y matrices for ML\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_8bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop8_final_wa = df_8bal_phhpv_tstint.copy()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_10bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop10_final_wa = df_10bal_phhpv_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 \n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)]\n",
    "df_avgprop_bal8_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                          df_avgprop8_final_wa.well.isin(well_no_outliers8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation dataset for X_train/x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation dataset for X_train/x_test data splitting based on outliers cleaned data\n",
    "azr_lst = ['CENTRAL AZERI', 'WEST AZERI', 'EAST AZERI']\n",
    "chg_lst = ['CHIRAG', 'DWG', 'DDGG', 'WEST CHIRAG']\n",
    "well_clean_azr = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand') & \n",
    "                                  (df_khtst_bal_qcl.field.isin(azr_lst))].well\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand.\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy_tvd[(df_khtst_xy_tvd.FORMATION == formation) & \n",
    "                            (df_khtst_xy_tvd.X > 0) & (df_khtst_xy_tvd.Y > 0) &\n",
    "                            (~df_khtst_xy_tvd.TVD_SCS.isna())]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EuclDist Dist based dataset Balakhany VIII sand + X sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                 df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                 ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                 ['well','FORMATION'], axis=1)).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')    \n",
    "# Preparation dataset for X_train/x_test data splitting\n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "\n",
    "df_collect8 = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect8.append(result)\n",
    "df_well_kh_dist8 = pd.concat(df_collect8).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist8.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_8)) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_collect10 = []\n",
    "for num, well_name in enumerate(dist_bal10.well):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect10.append(result)\n",
    "df_well_kh_dist10 = pd.concat(df_collect10).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal10 = df_well_kh_dist10.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10_fld[(df_well_kh_dist_bal10_fld.well.isin(well_clean_10)) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_all = pd.concat([df_well_kh_dist_bal8_fld, df_well_kh_dist_bal10_fld])\n",
    "# df_well_kh_dist_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XY based on EuclDist Balakhany VIII sand & X sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting XY based on Euclidean Distances for the top of Balakhany VIII sand.\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()['index']\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == 'Balakhany VIII sand') & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    data[data.well.isin(well_dist3)][['well','X','Y']].T[1:]\n",
    "    well_dist3_x = data[data.well.isin(well_dist3)][['well','X','Y']].T[1:2].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y = data[data.well.isin(well_dist3)][['well','X','Y']].T[2:3].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y.columns =['y1', 'y2', 'y3']\n",
    "    well_dist3_x.columns =['x1', 'x2', 'x3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_x, well_dist3_y, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_xy = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_xy_bal8 = df_well_kh_xy.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal8_fld = df_well_kh_xy_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "# Making up dataset with xy for azeri field\n",
    "df_well_kh_xy_bal8_fld_azr = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.field.isin(azr_lst)) & \n",
    "                                                    (df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# Making up dataset with xy for chirag & azeri fields\n",
    "df_well_kh_xy_bal8_fld_all = df_well_kh_xy_bal8_fld[(df_well_kh_xy_bal8_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_xy_bal8_fld_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting XY based on Euclidean Distances for the top of Balakhany X sand.\n",
    "df_collect = []\n",
    "for num, well_name in enumerate(dist_bal10.well[:]):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()['index']\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == 'Balakhany X sand') & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    data[data.well.isin(well_dist3)][['well','X','Y']].T[1:]\n",
    "    well_dist3_x = data[data.well.isin(well_dist3)][['well','X','Y']].T[1:2].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y = data[data.well.isin(well_dist3)][['well','X','Y']].T[2:3].reset_index().drop('index', axis=1)\n",
    "    well_dist3_y.columns =['y1', 'y2', 'y3']\n",
    "    well_dist3_x.columns =['x1', 'x2', 'x3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_x, well_dist3_y, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect.append(result)\n",
    "df_well_kh_xy = pd.concat(df_collect).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_xy_bal10 = df_well_kh_xy.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal10_fld = df_well_kh_xy_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "# Making up dataset with xy for azeri field\n",
    "df_well_kh_xy_bal10_fld_azr = df_well_kh_xy_bal10_fld[(df_well_kh_xy_bal10_fld.field.isin(azr_lst)) & \n",
    "                                                    (df_well_kh_xy_bal10_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "# Making up dataset with xy for chirag & azeri fields\n",
    "df_well_kh_xy_bal10_fld_all = df_well_kh_xy_bal10_fld[(df_well_kh_xy_bal10_fld.well.isin(well_clean_all)) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_xy_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_xy_bal10_fld_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Storage for obsolte code\n",
    "# svr = SVR(kernel = 'rbf', C=5, coef0=0.001, degree=1, gamma='auto')\n",
    "# sc_X = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# X_test = sc_X.transform(X_test)\n",
    "# y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "# y_test = sc_y.transform(y_test.reshape(-1, 1)) \n",
    "\n",
    "# # If you're using rbf (Radial basis function) kernal, you can use \n",
    "# # sklearn.inspection.permutation_importance as follows to get feature importance.\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# svc =  SVC(kernel='rbf', C=2)\n",
    "# svc.fit(X_train, y_train)\n",
    "# perm_importance = permutation_importance(svc, X_test, y_test)\n",
    "# feature_names = ['feature1', 'feature2', 'feature3', ...... ]\n",
    "# features = np.array(feature_names)\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "# plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 70/30 split for xy-kh of Bal8+10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining vsh_wavg data\n",
    "df_well_kh_xy_bal8_fld_vsh_all = df_well_kh_xy_bal8_fld_all.set_index('well').join(df_avgprop_bal8_wa[['well','vsh_wavg']].set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal10_fld_vsh_all = df_well_kh_xy_bal10_fld_all.set_index('well').join(df_avgprop_bal10_wa[['well','vsh_wavg']].set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal8_fld_vsh_all = df_well_kh_xy_bal8_fld_vsh_all[~df_well_kh_xy_bal8_fld_vsh_all.vsh_wavg.isna()].reset_index()\n",
    "df_well_kh_xy_bal10_fld_vsh_all = df_well_kh_xy_bal10_fld_vsh_all[~df_well_kh_xy_bal10_fld_vsh_all.vsh_wavg.isna()].reset_index()\n",
    "#Joining Bal VIII + Bal X\n",
    "df_well_kh_xy_fld_vsh_all = pd.concat([df_well_kh_xy_bal8_fld_vsh_all,df_well_kh_xy_bal10_fld_vsh_all]).reset_index()\n",
    "df_well_kh_xy_fld_vsh_all.drop(['level_0',\t'index'], axis=1, inplace=True)\n",
    "# Working with 70/30 split and united df Bal VIII and Bal X\n",
    "df_well_kh_xy_fld_vsh_all['FORMATION'] = df_well_kh_xy_fld_vsh_all.FORMATION.astype('string')\n",
    "df_well_kh_xy_fld_vsh_all['field'] = df_well_kh_xy_fld_vsh_all.field.astype('string')  \n",
    "df_kh_xy_vsh_ohe = pd.get_dummies(df_well_kh_xy_fld_vsh_all, columns = ['FORMATION', 'field'])\n",
    "# X_train/x_test data splitting\n",
    "y = np.array(df_kh_xy_vsh_ohe[['well','KHtst']])\n",
    "x = np.array(df_kh_xy_vsh_ohe[['well','x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', 'vsh_wavg', \n",
    "                               'FORMATION_Balakhany VIII sand','FORMATION_Balakhany X sand', 'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', \n",
    "                               'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "num = random.randint(0,100)\n",
    "print('num', num)\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "# Taking well names from train/test datasets\n",
    "x_train_wells = x_train_init[:,1]\n",
    "x_test_wells = x_test_init[:,1]\n",
    "y_train_wells = y_train_init[:,0]\n",
    "y_test_wells = y_train_init[:,0]\n",
    "x_train = x_train_init[:,1:]\n",
    "x_test = x_test_init[:,1:]\n",
    "y_train = y_train_init[:,1]\n",
    "y_test = y_test_init[:,1]\n",
    "# GridSearch for ML-model\n",
    "svr_gr_sr = SVR()\n",
    "grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                  'C' : [10, 100, 500, 1000, 2000, 3000],\n",
    "                  'gamma':[0.005, 0.01, 0.5],\n",
    "                  'epsilon': [0.001,0.01, 1, 5]}\n",
    "scorer = make_scorer(mae, greater_is_better=False)\n",
    "gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 15)\n",
    "gd_sr_SVR.fit(x_train, y_train)\n",
    "GS_setting = gd_sr_SVR.best_params_\n",
    "print(GS_setting)\n",
    "# Applying Pipeline for ML-model\n",
    "svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR(kernel = 'rbf', C=GS_setting['C'], \n",
    "                                                       gamma = GS_setting['gamma'], epsilon=GS_setting['epsilon']))])\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred_train = svr.predict(x_train)\n",
    "y_pred_test = svr.predict(x_test)\n",
    "print('---------------------')\n",
    "print('r2_train', r2(y_train, y_pred_train).round(2), 'x_train', x_train.shape)\n",
    "print('r2_test', r2(y_test, y_pred_test).round(2), 'x_test', x_test.shape)\n",
    "print('mae_train', mae(y_train, y_pred_train).round(0))\n",
    "print('mae_test', mae(y_test, y_pred_test).round(0))\n",
    "# QC of predicted values for train & test datasets\n",
    "df_res_train = pd.DataFrame(zip(y_train_wells, y_train, y_pred_train), columns=['well', 'actual','predict'])\n",
    "df_res_train['l_limit'] = df_res_train.actual*0.75\n",
    "df_res_train['h_limit'] = df_res_train.actual*1.25\n",
    "df_res_train['qc'] = 'out'\n",
    "df_res_train.loc[(df_res_train.predict >= df_res_train.l_limit) & (df_res_train.predict <= df_res_train.h_limit), 'qc'] = 'in'\n",
    "df_res_test = pd.DataFrame(zip(y_test_wells, y_test, y_pred_test), columns=['well', 'actual','predict'])\n",
    "df_res_test['l_limit'] = df_res_test.actual*0.75\n",
    "df_res_test['h_limit'] = df_res_test.actual*1.25\n",
    "df_res_test['qc'] = 'out'\n",
    "df_res_test.loc[(df_res_test.predict >= df_res_test.l_limit) & (df_res_test.predict <= df_res_test.h_limit), 'qc'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance train set\n",
    "result_pi_test = permutation_importance(svr, x_train, y_train, n_repeats=10, random_state=num, n_jobs=2)\n",
    "sorted_importances_idx = result_pi_test.importances_mean.argsort()\n",
    "importances = pd.DataFrame(result_pi_test.importances[sorted_importances_idx].T,\n",
    "                           columns=df_kh_xy_vsh_ohe.drop(['well','KHtst'], axis=1).columns[sorted_importances_idx])\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp (train set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance test set\n",
    "result_pi_test = permutation_importance(svr, x_test, y_test, n_repeats=10, random_state=num, n_jobs=2)\n",
    "sorted_importances_idx = result_pi_test.importances_mean.argsort()\n",
    "importances = pd.DataFrame(result_pi_test.importances[sorted_importances_idx].T,\n",
    "                           columns=df_kh_xy_vsh_ohe.drop(['well','KHtst'], axis=1).columns[sorted_importances_idx])\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permut Imp (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the x-plot for train dataset\n",
    "print('wells total:', df_res_train.shape[0])\n",
    "print('wells unpredicted:', df_res_train['qc'].value_counts()['out'], (df_res_train['qc'].value_counts()['out']/df_res_train.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', df_res_train['qc'].value_counts()['in'], (df_res_train['qc'].value_counts()['in']/df_res_train.shape[0]).round(3), 'v/v')\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(df_res_train, x='actual', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred Train',width=600,height=400, xaxis_title='actual', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the x-plot for test dataset\n",
    "print('wells total:', df_res_test.shape[0])\n",
    "print('wells unpredicted:', df_res_test['qc'].value_counts()['out'], (df_res_test['qc'].value_counts()['out']/df_res_test.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', df_res_test['qc'].value_counts()['in'], (df_res_test['qc'].value_counts()['in']/df_res_test.shape[0]).round(3), 'v/v')\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(df_res_test, x='actual', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred',width=600,height=400, xaxis_title='actual', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loop for XY-dataset of united Balakhany VIII+X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Part for log10(kh)\n",
    "# res['test_nat'] = 10**(res.test)\n",
    "# res['predict_nat'] = 10**(res.predict)\n",
    "# res['l_test'] = res.test_nat*0.75\n",
    "# res['h_test'] = res.test_nat*1.25\n",
    "# res['qc'] = 'out'\n",
    "# res.loc[(res.predict_nat >= res.l_test) & (res.predict_nat <= res.h_test), 'qc'] = 'in'\n",
    "# print('wells total:', res.shape[0])\n",
    "# print('wells unpredicted:', res['qc'].value_counts()['out'], (res['qc'].value_counts()['out']/res.shape[0]).round(3), 'v/v')\n",
    "# print('wells predicted:', res['qc'].value_counts()['in'], (res['qc'].value_counts()['in']/res.shape[0]).round(3), 'v/v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic version of calculation script\n",
    "# # Starting of the loop for Balakhany VIII chirag & azeri\n",
    "# y_test_lst = []\n",
    "# y_pred_test_lst = []\n",
    "# well_exclude_lst = []\n",
    "# gs_settings_lst = []\n",
    "# metrics_r2_mae_lst = []\n",
    "# df_well_kh_xy_bal8_fld_vsh_all = df_well_kh_xy_bal8_fld_vsh_all.sample(frac = 1).reset_index()\n",
    "# for i in tqdm(range(len(df_well_kh_xy_bal8_fld_vsh_all))):\n",
    "#     #Making up the feature and target datasets\n",
    "#     df_wo_well = df_well_kh_xy_bal8_fld_vsh_all.drop([i])\n",
    "#     well_exclude = df_well_kh_xy_bal8_fld_vsh_all.iloc[i]['well']\n",
    "#     well_exclude_lst.append(well_exclude)\n",
    "#     y_train = np.array(df_wo_well['KHtst'])\n",
    "#     x_train = np.array(df_wo_well[['x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', 'vsh_wavg']])\n",
    "#     well_train = np.array(df_wo_well['well'])\n",
    "#     y_test = np.array(df_well_kh_xy_bal8_fld_vsh_all.iloc[i]['KHtst'])\n",
    "#     y_test_lst.append(y_test)\n",
    "#     x_test = np.array(df_well_kh_xy_bal8_fld_vsh_all.iloc[i][['x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', 'vsh_wavg']])\n",
    "#     # GridSearch for ML-model\n",
    "#     svr_gr_sr = SVR()\n",
    "#     grid_param_SVR = {'kernel' : (['rbf']),\n",
    "#                       'C' : [0.1, 1, 10, 100, 300],\n",
    "#                       'gamma':[0.01, 0.5, 1, 5],\n",
    "#                       'epsilon': [0.001,0.01, 1]}\n",
    "#     scorer = make_scorer(mae, greater_is_better=False)\n",
    "#     gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 10)\n",
    "#     gd_sr_SVR.fit(x_train, y_train)\n",
    "#     GS_setting = gd_sr_SVR.best_params_\n",
    "#     gs_settings_lst.append((GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "#     # Statement Pipeline of ML-model\n",
    "#     # svr = SVR(kernel = 'rbf', C=500, epsilon=0.001, gamma=0.5)\n",
    "#     svr = SVR(kernel = 'rbf', C=GS_setting['C'], epsilon=GS_setting['epsilon'], gamma=GS_setting['gamma'])   \n",
    "#     # # Apply StandardScaller to X & Y\n",
    "#     sc_x = StandardScaler()\n",
    "#     sc_y = StandardScaler()\n",
    "#     x_train = sc_x.fit_transform(x_train)\n",
    "#     x_test = sc_x.transform([x_test])\n",
    "#     y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "#     y_test = sc_y.transform(y_test.reshape(-1, 1)) \n",
    "#     ## Fitting the ML-model\n",
    "#     svr.fit(x_train, y_train)\n",
    "#     y_pred_train = svr.predict(x_train)\n",
    "#     y_pred_test = svr.predict(x_test)\n",
    "#     # # Block of data naturalization\n",
    "#     y_pred_test_nat = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "#     y_pred_test_lst.append(y_pred_test_nat[0][0])\n",
    "#     # Metrics computation for the ML-model\n",
    "#     r2_train = r2(y_train, y_pred_train).round(2)\n",
    "#     mae_train = mae(y_train, y_pred_train)\n",
    "#     mae_train_nat = sc_y.inverse_transform([[mae_train]])\n",
    "#     metrics_r2_mae_lst.append((r2_train, mae_train_nat[0][0]))\n",
    "# # Building up of dataframe\n",
    "# res = pd.DataFrame(zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst, metrics_r2_mae_lst), \n",
    "#                    columns = ['test','predict','well_excl','gs_setting', 'metrics_r2_mae'])\n",
    "# res['l_test'] = res.test*0.75\n",
    "# res['h_test'] = res.test*1.25\n",
    "# res['qc'] = 'out'\n",
    "# res.loc[(res.predict >= res.l_test) & (res.predict <= res.h_test), 'qc'] = 'in'\n",
    "# print('wells total:', res.shape[0])\n",
    "# print('wells unpredicted:', res['qc'].value_counts()['out'])\n",
    "# print('wells predicted:', res['qc'].value_counts()['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining vsh_wavg data\n",
    "df_well_kh_xy_bal8_fld_vsh_all = df_well_kh_xy_bal8_fld_all.set_index('well').join(df_avgprop_bal8_wa[['well','vsh_wavg']].set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal10_fld_vsh_all = df_well_kh_xy_bal10_fld_all.set_index('well').join(df_avgprop_bal10_wa[['well','vsh_wavg']].set_index('well')).reset_index()\n",
    "df_well_kh_xy_bal8_fld_vsh_all = df_well_kh_xy_bal8_fld_vsh_all[~df_well_kh_xy_bal8_fld_vsh_all.vsh_wavg.isna()].reset_index()\n",
    "df_well_kh_xy_bal10_fld_vsh_all = df_well_kh_xy_bal10_fld_vsh_all[~df_well_kh_xy_bal10_fld_vsh_all.vsh_wavg.isna()].reset_index()\n",
    "#Joining Bal VIII + Bal X\n",
    "df_well_kh_xy_fld_vsh_all = pd.concat([df_well_kh_xy_bal8_fld_vsh_all,df_well_kh_xy_bal10_fld_vsh_all]).reset_index()\n",
    "df_well_kh_xy_fld_vsh_all.drop(['level_0',\t'index'], axis=1, inplace=True)\n",
    "df_kh_xy_vsh_ohe = pd.get_dummies(df_well_kh_xy_fld_vsh_all, columns = ['FORMATION', 'field'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop for Balakhany VIII chirag & azeri\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_kh_xy_vsh_ohe = df_kh_xy_vsh_ohe.sample(frac = 1).reset_index()\n",
    "for i in tqdm(range(len(df_kh_xy_vsh_ohe))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_kh_xy_vsh_ohe.drop([i])\n",
    "    well_exclude = df_kh_xy_vsh_ohe.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[[ 'x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', \n",
    "                                    'vsh_wavg','FORMATION_Balakhany VIII sand','FORMATION_Balakhany X sand', \n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', \n",
    "                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI', \n",
    "                                    'field_WEST CHIRAG']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_kh_xy_vsh_ohe.iloc[i]['KHtst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_kh_xy_vsh_ohe.iloc[i][[   'x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', \n",
    "                                                    'vsh_wavg','FORMATION_Balakhany VIII sand','FORMATION_Balakhany X sand', \n",
    "                                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', \n",
    "                                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    # GridSearch for ML-model\n",
    "    gbr_gr_svr = SVR()\n",
    "    grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                      'C' : [500],\n",
    "                      'gamma':[0.005],\n",
    "                      'epsilon': [0.01]}\n",
    "    scorer = make_scorer(mae, greater_is_better=False)\n",
    "    gd_sr_SVR = GridSearchCV(estimator = gbr_gr_svr, param_grid = grid_param_SVR, scoring=scorer, cv = 5)\n",
    "    gd_sr_SVR.fit(x_train, y_train)\n",
    "    GS_setting = gd_sr_SVR.best_params_\n",
    "    gs_settings_lst.append((GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "    # Statement Pipeline of ML-model\n",
    "    # svr = SVR(kernel = 'rbf', C=500, epsilon=0.001, gamma=0.5)\n",
    "    svr = SVR(kernel = 'rbf', C=GS_setting['C'],  gamma=GS_setting['gamma'], epsilon=GS_setting['epsilon'])   \n",
    "    # Apply StandardScaller to X & Y\n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform([x_test])\n",
    "    y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_test = sc_y.transform(y_test.reshape(-1, 1)) \n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)\n",
    "    y_pred_test = svr.predict(x_test)\n",
    "    # Block of data naturalization\n",
    "    y_pred_test_nat = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "    y_pred_test_lst.append(y_pred_test_nat[0][0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    mae_train_nat = sc_y.inverse_transform([[mae_train]])\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train_nat[0][0].round(5)))\n",
    "# Building up of dataframe\n",
    "res_loop = pd.DataFrame(zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst, metrics_r2_mae_lst), \n",
    "                   columns = ['test','predict','well_excl','gs_setting', 'metrics_r2_mae'])\n",
    "res_loop['l_test'] = res_loop.test*0.75\n",
    "res_loop['h_test'] = res_loop.test*1.25\n",
    "res_loop['qc'] = 'out'\n",
    "res_loop.loc[(res_loop.predict >= res_loop.l_test) & (res_loop.predict <= res_loop.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_loop.shape[0])\n",
    "print('wells unpredicted:', res_loop['qc'].value_counts()['out'], (res_loop['qc'].value_counts()['out']/res_loop.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_loop['qc'].value_counts()['in'], (res_loop['qc'].value_counts()['in']/res_loop.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_loop.test, res_loop.predict).round(0)\n",
    "r2_df_xy = r2(res_loop.test, res_loop.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_loop, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well_excl'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred xy-kh SVR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawind map distribution of predicted data\n",
    "res_xy = df_khtst_xy_tvd[(df_khtst_xy_tvd.FORMATION == 'Balakhany VIII sand') & \n",
    "                            (df_khtst_xy_tvd.X > 0) & (df_khtst_xy_tvd.Y > 0) &\n",
    "                            (~df_khtst_xy_tvd.TVD_SCS.isna())][['well','FORMATION','X','Y']]\n",
    "res_xy_qc = res_loop.set_index('well_excl').join(res_xy.set_index('well')).reset_index()\n",
    "res_xy_qc['predict'] = res_xy_qc.predict.round(0)\n",
    "field_avg_coord = metadata.groupby('field')[['X_wellhead','Y_wellhead']].mean().reset_index()\n",
    "fig_map = px.scatter(res_xy_qc, x='X', y='Y', \n",
    "                     color='qc', \n",
    "                     hover_data=['well_excl', 'test', 'predict'], \n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig_map.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig_pltfm = px.scatter(field_avg_coord, x='X_wellhead', y='Y_wellhead',hover_data=['field'])\n",
    "fig_pltfm.update_traces(marker=dict(size=15,opacity=0.75,color='black', symbol=\"square\"))\n",
    "fig_final = go.Figure(data = fig_map.data + fig_pltfm.data)\n",
    "fig_final.update_layout(title = 'Comparison Actual vs Pred on map, Balakhany VIII, SVR()', width=1000, height=500,\n",
    "                        margin=dict(l=0, r=0, t=40, b=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loop for dist-dataset of united Balakhany VIII+X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                 df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                 ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                 ['well','FORMATION'], axis=1)).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')    \n",
    "# Preparation dataset for X_train/x_test data splitting\n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "\n",
    "df_collect8 = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect8.append(result)\n",
    "df_well_kh_dist8 = pd.concat(df_collect8).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist8.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_8)) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_collect10 = []\n",
    "for num, well_name in enumerate(dist_bal10.well):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect10.append(result)\n",
    "df_well_kh_dist10 = pd.concat(df_collect10).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal10 = df_well_kh_dist10.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10_fld[(df_well_kh_dist_bal10_fld.well.isin(well_clean_10)) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_all = pd.concat([df_well_kh_dist_bal8_fld, df_well_kh_dist_bal10_fld])\n",
    "# df_well_kh_dist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution average dist for offsets wells into dataset\n",
    "dist_avg_all = df_well_kh_dist_all.iloc[:, :4]\n",
    "dist_avg_all['avg'] = dist_avg_all.iloc[:,1:4].mean(axis=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "              x=dist_avg_all.avg, \n",
    "              xbins=dict(start=0, end=3000, size=50), marker_color='red', name='grey'))\n",
    "fig.update_traces(opacity=0.5)\n",
    "fig.update_layout(title_text='Distribution average dist for offsets wells into dataset',\n",
    "                  xaxis_title_text='tst_thickness', yaxis_title_text='Count',\n",
    "                  autosize=True, width=1000, height=300, margin=dict(l=10,r=10,b=10,t=40))\n",
    "fig.update_xaxes(nticks=40, showgrid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop for Balakhany VIII chirag & azeri\n",
    "df_dist_all_ohe = pd.get_dummies(df_well_kh_dist_all, columns = ['FORMATION','field']).reset_index()\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_dist_all_ohe = df_dist_all_ohe.sample(frac = 1).reset_index()\n",
    "for i in tqdm(range(len(df_dist_all_ohe))[:]):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_dist_all_ohe.drop([i])\n",
    "    well_exclude = df_dist_all_ohe.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[[ 'dist1', 'dist2', 'dist3', 'kh1', 'kh2', 'kh3',\n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand', \n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG',\n",
    "                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI',\n",
    "                                    'field_WEST CHIRAG']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_dist_all_ohe.iloc[i]['KHtst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_dist_all_ohe.iloc[i][[     'dist1', 'dist2', 'dist3', 'kh1', 'kh2', 'kh3',\n",
    "                                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand', \n",
    "                                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG',\n",
    "                                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI',\n",
    "                                                    'field_WEST CHIRAG']])\n",
    "    # GridSearch for ML-model\n",
    "    svr_gr_sr = SVR()\n",
    "    grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                      'C' : [500],\n",
    "                      'gamma':[0.005],\n",
    "                      'epsilon': [0.001]}\n",
    "    scorer = make_scorer(mae, greater_is_better=False)\n",
    "    gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 5)\n",
    "    gd_sr_SVR.fit(x_train, y_train)\n",
    "    GS_setting = gd_sr_SVR.best_params_\n",
    "    gs_settings_lst.append((GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "    # Statement Pipeline of ML-model\n",
    "    # svr = SVR(kernel = 'rbf', C=500, epsilon=0.001, gamma=0.5)\n",
    "    svr = SVR(kernel = 'rbf', C=GS_setting['C'],  gamma=GS_setting['gamma'], epsilon=GS_setting['epsilon'])   \n",
    "    # Apply StandardScaller to X & Y\n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform([x_test])\n",
    "    y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_test = sc_y.transform(y_test.reshape(-1, 1)) \n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)   \n",
    "    y_pred_test = svr.predict(x_test)\n",
    "    # Block of data naturalization\n",
    "    y_pred_train_nat = sc_y.inverse_transform(y_pred_train.reshape(1, -1))\n",
    "    y_pred_test_nat = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "    y_pred_test_lst.append(y_pred_test_nat[0][0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    mae_train_nat = sc_y.inverse_transform([[mae_train]])\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train_nat[0][0].round(0)))\n",
    "# Building up of dataframe\n",
    "res_split = pd.DataFrame(zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst, metrics_r2_mae_lst), \n",
    "                            columns = ['test','predict','well_excl','gs_setting', 'metrics_r2_mae'])\n",
    "res_split['l_test'] = res_split.test*0.75\n",
    "res_split['h_test'] = res_split.test*1.25\n",
    "res_split['qc'] = 'out'\n",
    "res_split.loc[(res_split.predict >= res_split.l_test) & (res_split.predict <= res_split.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_split.shape[0])\n",
    "print('wells unpredicted:', res_split['qc'].value_counts()['out'], (res_split['qc'].value_counts()['out']/res_split.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_split['qc'].value_counts()['in'], (res_split['qc'].value_counts()['in']/res_split.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_split.test, res_split.predict).round(0)\n",
    "r2_df_xy = r2(res_split.test, res_split.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_split, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well_excl'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred dist-kh SVR',width=600,height=400, xaxis_title='test', yaxis_title='pred',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C04-test or Influence of x_train.shape on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "print('well:', df_kh_xy_vsh_ohe.iloc[i][0], 'KHtst:', df_kh_xy_vsh_ohe.iloc[i][10])\n",
    "y_test = np.array(df_kh_xy_vsh_ohe.iloc[i]['KHtst'])\n",
    "x_test = np.array(df_kh_xy_vsh_ohe.iloc[i][[   'x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', \n",
    "                                                    'vsh_wavg', \n",
    "                                                    'FORMATION_Balakhany VIII sand','FORMATION_Balakhany X sand', \n",
    "                                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', \n",
    "                                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "final_lst = []\n",
    "for j in range(len(df_kh_xy_vsh_ohe))[16::5]:\n",
    "    df_wo_well = df_kh_xy_vsh_ohe.iloc[6:j]\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[[ 'x1', 'x2', 'x3', 'y1', 'y2', 'y3', 'kh1', 'kh2', 'kh3', \n",
    "                                    'vsh_wavg', \n",
    "                                    'FORMATION_Balakhany VIII sand','FORMATION_Balakhany X sand', \n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', \n",
    "                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    grid_param_SVR = {  'kernel' : (['rbf']),\n",
    "                    'C' : [500],\n",
    "                    'gamma':[0.005],\n",
    "                    'epsilon': [0.001]}\n",
    "    scorer = make_scorer(mae, greater_is_better=False)\n",
    "    svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR(kernel = 'rbf', C=GS_setting['C'], \n",
    "                                                    gamma = GS_setting['gamma'], epsilon=GS_setting['epsilon']))])\n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)\n",
    "    y_pred_test = svr.predict([x_test])\n",
    "    final_lst.append((y_test, y_pred_test[0], x_train.shape[0]))\n",
    "\n",
    "c04test = pd.DataFrame(final_lst, columns=['actual', 'predict', 'N_dataset'])\n",
    "predict = px.line(c04test, x='N_dataset', y='predict')\n",
    "actual = px.line(c04test, x='N_dataset', y='actual')\n",
    "predict.update_traces(line=dict(color = 'blue'))\n",
    "actual.update_traces(line=dict(color = 'red'))\n",
    "figC04 = go.Figure(data = predict.data + actual.data)\n",
    "figC04.update_layout(title = 'Influence of x_train.shape on prediction ' + str(df_kh_xy_vsh_ohe.iloc[i][0]),\n",
    "                    width=1000,height=300, \n",
    "                    xaxis_title='x_train.shape', yaxis_title='KHtst',\n",
    "                    margin=dict(l=10,r=10,b=10,t=40))\n",
    "figC04.update_yaxes(range=[0,c04test.predict.max()+100])\n",
    "figC04.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadir's dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload df_xr_yr_vsh.csv\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\input\\\\'\n",
    "df_nadir_xy = pd.read_csv(path + 'df_xr_yr_vsh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop for Balakhany VIII chirag & azeri\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_kh_xy_vsh_ohe = df_nadir_xy.sample(frac = 1)\n",
    "for i in tqdm(range(len(df_kh_xy_vsh_ohe))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_kh_xy_vsh_ohe.drop([i])\n",
    "    well_exclude = df_kh_xy_vsh_ohe.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['KHtst'])\n",
    "    x_train = np.array(df_wo_well[[ 'X', 'Y', 'TVD_SCS', 'vsh_avg_md',\n",
    "                                    'X_new', 'Y_new', 'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG',\n",
    "                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI',\n",
    "                                    'field_WEST CHIRAG']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_kh_xy_vsh_ohe.iloc[i]['KHtst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_kh_xy_vsh_ohe.iloc[i][[    'X', 'Y', 'TVD_SCS', 'vsh_avg_md',\n",
    "                                                    'X_new', 'Y_new', 'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG',\n",
    "                                                    'field_DWG', 'field_EAST AZERI', 'field_WEST AZERI',\n",
    "                                                    'field_WEST CHIRAG']])\n",
    "    # GridSearch for ML-model\n",
    "    svr_gr_sr = SVR()\n",
    "    # 2000 0.005 5\n",
    "    grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                      'C' : [500],\n",
    "                      'gamma':[0.005],\n",
    "                      'epsilon': [0.001]}\n",
    "    scorer = make_scorer(mae, greater_is_better=False)\n",
    "    gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 5)\n",
    "    gd_sr_SVR.fit(x_train, y_train)\n",
    "    GS_setting = gd_sr_SVR.best_params_\n",
    "    gs_settings_lst.append((GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "    # Statement Pipeline of ML-model\n",
    "    # svr = SVR(kernel = 'rbf', C=500, epsilon=0.001, gamma=0.5)\n",
    "    svr = SVR(kernel = 'rbf', C=GS_setting['C'],  gamma=GS_setting['gamma'], epsilon=GS_setting['epsilon'])   \n",
    "    # Apply StandardScaller to X & Y\n",
    "    sc_x = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    x_train = sc_x.fit_transform(x_train)\n",
    "    x_test = sc_x.transform([x_test])\n",
    "    y_train = sc_y.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_test = sc_y.transform(y_test.reshape(-1, 1)) \n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)\n",
    "    y_pred_test = svr.predict(x_test)\n",
    "    # Block of data naturalization\n",
    "    y_pred_test_nat = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "    y_pred_test_lst.append(y_pred_test_nat[0][0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    mae_train_nat = sc_y.inverse_transform([[mae_train]])\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train_nat[0][0].round(5)))\n",
    "# Building up of dataframe\n",
    "res_nadir = pd.DataFrame(zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst, metrics_r2_mae_lst), \n",
    "                   columns = ['test','predict','well_excl','gs_setting', 'metrics_r2_mae'])\n",
    "res_nadir['l_test'] = res_nadir.test*0.75\n",
    "res_nadir['h_test'] = res_nadir.test*1.25\n",
    "res_nadir['qc'] = 'out'\n",
    "res_nadir.loc[(res_nadir.predict >= res_nadir.l_test) & (res_nadir.predict <= res_nadir.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_nadir.shape[0])\n",
    "print('wells unpredicted:', res_nadir['qc'].value_counts()['out'], (res_nadir['qc'].value_counts()['out']/res_nadir.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_nadir['qc'].value_counts()['in'], (res_nadir['qc'].value_counts()['in']/res_nadir.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_nadir.test, res_nadir.predict).round(0)\n",
    "r2_df_xy = r2(res_nadir.test, res_nadir.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_nadir, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well_excl'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"green\", \"red\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred Nadirs dataset',width=600,height=400, xaxis_title='test', yaxis_title='pred',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadir's dataset based on ALL Bal8+10 FU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv with initial KHtst_v3, joining xy-coord & TVD_SCS tops of formation\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd = df_khtst_xy.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_khtst_xy_tvd_fld = df_khtst_xy_tvd.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "# Preparation dataset for X_train/x_test data splitting based on outliers cleaned data\n",
    "well_clean_all = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION.str.contains('Balakhany VIII'))].well\n",
    "df_khtst_xy_tvd_fld_bal = df_khtst_xy_tvd_fld[  df_khtst_xy_tvd_fld.FORMATION.str.contains('Balakhany VIII') |\n",
    "                                                df_khtst_xy_tvd_fld.FORMATION.str.contains('Balakhany X')].drop('DEPTH', axis=1)\n",
    "#Calculation of TST-thickness for ALL Balakhany FU\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION.str.contains('Balakhany')][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]     \n",
    "df_bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION.str.contains('Balakhany')].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_bal_phhpv = df_bal_hpv.set_index(['well','FORMATION']).join(df_bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# df_bal_phhpv\n",
    "#Preparing x,y matrices for ML\n",
    "df_bal_phhpv_tstint = df_bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_bal_phhpv_tstint.rename(columns={'gross_tst':'rock_tst'}, inplace=True)\n",
    "df_bal_phhpv_tstint = df_bal_phhpv_tstint[['well','FORMATION','X', 'Y','TVD_SCS','field','interv_tst','rock_tst', 'vsh_wavg', 'kavg_htst']]\n",
    "df_bal_avgprop = df_bal_phhpv_tstint[df_bal_phhpv_tstint.X.notna() & df_bal_phhpv_tstint.Y.notna() & df_bal_phhpv_tstint.TVD_SCS.notna()]\n",
    "df_bal_avgprop_ohe = pd.get_dummies(df_bal_avgprop, columns = ['FORMATION', 'field'])\n",
    "# Rotating field across the middle to reflect x and y more geologically sensible\n",
    "def rotate(x,y): #rotate x,y around xo,yo by theta (rad)\n",
    "    theta = (math.pi/180)*34\n",
    "    xo = st.median(np.array(df_khtst_xy['X'].to_list()))\n",
    "    yo = st.median(np.array(df_khtst_xy['Y'].to_list()))\n",
    "    xr = math.cos(theta)*(x-xo)-math.sin(theta)*(y-yo) + xo\n",
    "    yr = math.sin(theta)*(x-xo)+math.cos(theta)*(y-yo) + yo\n",
    "    return [xr,yr]\n",
    "df_bal_avgprop_ohe[['X_new', 'Y_new']] = df_bal_avgprop_ohe.apply(lambda row: rotate(row['X'], row['Y']), axis=1, result_type='expand')\n",
    "df_bal_avgprop_ohe = df_bal_avgprop_ohe[(df_bal_avgprop_ohe.kavg_htst < 13000) & (df_bal_avgprop_ohe.kavg_htst > 100)]\n",
    "print('features: ',df_bal_avgprop_ohe.columns)\n",
    "print('dataset size: ',df_bal_avgprop_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nadir's dataset 70/30 split SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train/x_test data splitting\n",
    "y = np.array(df_bal_avgprop_ohe[[   'well','kavg_htst']])\n",
    "x = np.array(df_bal_avgprop_ohe[[   'well','X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                    'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                    'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                    'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                    'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                    'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                    'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "num = random.randint(0,100)\n",
    "print('num', num)\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "# Taking well names from train/test datasets\n",
    "y_train_wells = y_train_init[:,0]\n",
    "y_test_wells = y_test_init[:,0]\n",
    "x_train = x_train_init[:,1:]\n",
    "x_test = x_test_init[:,1:]\n",
    "y_train = y_train_init[:,1]\n",
    "y_test = y_test_init[:,1]\n",
    "# GridSearch for ML-model\n",
    "svr_gr_sr = SVR()\n",
    "grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                  'C' : [10, 100, 500, 1000, 2000, 3000],\n",
    "                  'gamma':[0.005, 0.01, 0.5],\n",
    "                  'epsilon': [0.001,0.01, 1, 5]}\n",
    "scorer = make_scorer(mae, greater_is_better=False)\n",
    "gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 15)\n",
    "gd_sr_SVR.fit(x_train, y_train)\n",
    "GS_setting = gd_sr_SVR.best_params_\n",
    "print(GS_setting)\n",
    "# Applying Pipeline for ML-model\n",
    "svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR(kernel = 'rbf', C=GS_setting['C'], \n",
    "                                                       gamma = GS_setting['gamma'], epsilon=GS_setting['epsilon']))])\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred_train = svr.predict(x_train)\n",
    "y_pred_test = svr.predict(x_test)\n",
    "print('---------------------')\n",
    "print('r2_train', r2(y_train, y_pred_train).round(2), 'x_train', x_train.shape)\n",
    "print('r2_test', r2(y_test, y_pred_test).round(2), 'x_test', x_test.shape)\n",
    "print('mae_train', mae(y_train, y_pred_train).round(0))\n",
    "print('mae_test', mae(y_test, y_pred_test).round(0))\n",
    "# QC of predicted values for train & test datasets\n",
    "df_svr_train = pd.DataFrame(zip(y_train_wells, y_train, y_pred_train), columns=['well', 'actual','predict'])\n",
    "df_svr_train['l_limit'] = df_svr_train.actual*0.75\n",
    "df_svr_train['h_limit'] = df_svr_train.actual*1.25\n",
    "df_svr_train['qc'] = 'out'\n",
    "df_svr_train.loc[(df_svr_train.predict >= df_svr_train.l_limit) & (df_svr_train.predict <= df_svr_train.h_limit), 'qc'] = 'in'\n",
    "df_svr_test = pd.DataFrame(zip(y_test_wells, y_test, y_pred_test), columns=['well', 'actual','predict'])\n",
    "df_svr_test['l_limit'] = df_svr_test.actual*0.75\n",
    "df_svr_test['h_limit'] = df_svr_test.actual*1.25\n",
    "df_svr_test['qc'] = 'out'\n",
    "df_svr_test.loc[(df_svr_test.predict >= df_svr_test.l_limit) & (df_svr_test.predict <= df_svr_test.h_limit), 'qc'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop for Balakhany VIII chirag & azeri\n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_bal_avgprop_ohe_gbr = df_bal_avgprop_ohe.sample(frac = 1).reset_index().drop('index', axis=1)\n",
    "for i in tqdm(range(len(df_bal_avgprop_ohe_gbr))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_bal_avgprop_ohe_gbr.drop([i])\n",
    "    well_exclude = df_bal_avgprop_ohe_gbr.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['kavg_htst'])\n",
    "    x_train = np.array(df_wo_well[[ 'X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                    'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                    'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                    'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                    'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                    'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                    'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                    'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_bal_avgprop_ohe_gbr.iloc[i]['kavg_htst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_bal_avgprop_ohe_gbr.iloc[i][[  'X_new', 'Y_new','TVD_SCS', 'interv_tst', 'rock_tst', 'vsh_wavg',\n",
    "                                                        'FORMATION_Balakhany VIII', 'FORMATION_Balakhany VIII 10',\n",
    "                                                        'FORMATION_Balakhany VIII 15', 'FORMATION_Balakhany VIII 20',\n",
    "                                                        'FORMATION_Balakhany VIII 25', 'FORMATION_Balakhany VIII 5',\n",
    "                                                        'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X',\n",
    "                                                        'FORMATION_Balakhany X 20', 'FORMATION_Balakhany X 40',\n",
    "                                                        'FORMATION_Balakhany X 50', 'FORMATION_Balakhany X sand',\n",
    "                                                        'field_CENTRAL AZERI', 'field_CHIRAG', 'field_DDGG', 'field_DWG',\n",
    "                                                        'field_EAST AZERI', 'field_WEST AZERI', 'field_WEST CHIRAG']])\n",
    "    # GridSearch for ML-model\n",
    "    # {'C': 500, 'epsilon': 0.001, 'gamma': 0.005, 'kernel': 'rbf'}\n",
    "    grid_param_SVR = {  'C' : [500],\n",
    "                        'epsilon': [0.01],\n",
    "                        'gamma':[0.005],\n",
    "                        'kernel' : (['rbf'])}\n",
    "    GS_setting = grid_param_SVR\n",
    "    gs_settings_lst.append((GS_setting['kernel'],GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "    # Statement of ML-model\n",
    "    svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR( kernel = GS_setting['kernel'][0], \n",
    "                                                            C = GS_setting['C'][0],\n",
    "                                                            gamma = GS_setting['gamma'][0], \n",
    "                                                            epsilon = GS_setting['epsilon'][0]))])\n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)\n",
    "    y_pred_test = svr.predict([x_test])\n",
    "    y_pred_test_lst.append(y_pred_test[0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train.round(0)))\n",
    "# Building up of dataframe\n",
    "res_svr = pd.DataFrame( zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst), \n",
    "                        columns = ['test','predict','well', 'gs_setting',])\n",
    "res_svr['l_test'] = res_svr.test*0.75\n",
    "res_svr['h_test'] = res_svr.test*1.25\n",
    "res_svr['qc'] = 'out'\n",
    "res_svr.loc[(res_svr.predict >= res_svr.l_test) & (res_svr.predict <= res_svr.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_svr.shape[0])\n",
    "print('wells unpredicted:', res_svr['qc'].value_counts()['out'], (res_svr['qc'].value_counts()['out']/res_svr.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_svr['qc'].value_counts()['in'], (res_svr['qc'].value_counts()['in']/res_svr.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_svr.test, res_svr.predict).round(0)\n",
    "r2_df_xy = r2(res_svr.test, res_svr.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_svr, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred xy-kh rotated full Balakhany GBR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shahriyar request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading k_htst data from csv-file & Calculation of Euclidean Distances\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\'\n",
    "df_khtst = pd.read_csv(path + 'df_prq_khtst_v3.csv')\n",
    "df_khtst_xy = df_khtst.set_index(['well','FORMATION']).join(\n",
    "                                                            df_prq[['well','FORMATION','X','Y','TVD_SCS']].groupby(\n",
    "                                                            ['well','FORMATION']).apply(lambda x: x.iloc[0]).drop(\n",
    "                                                            ['well','FORMATION'], axis=1)\n",
    "                                                            ).reset_index()\n",
    "#Calculation of Euclidean Distances for the top of Balakhany VIII sand & Balakhany X sand\n",
    "def well_dist_calc(formation='Balakhany VIII sand'):\n",
    "    data = df_khtst_xy[(df_khtst_xy.FORMATION == formation) & (df_khtst_xy.X > 0) & (df_khtst_xy.Y > 0)]\n",
    "    row_name = data.well.reset_index().drop(['index'], axis=1)\n",
    "    distance_fm = pd.DataFrame(euclidean_distances(data[['X', 'Y', 'TVD_SCS']]), columns=list(data.well))\n",
    "    distance_fm_well = distance_fm.join(row_name).set_index('well')\n",
    "    distance_fm_well.reset_index()\n",
    "    return distance_fm_well.reset_index()\n",
    "dist_bal8 = well_dist_calc('Balakhany VIII sand')\n",
    "dist_bal10 = well_dist_calc('Balakhany X sand')    \n",
    "# Preparation dataset for X_train/x_test data splitting\n",
    "well_clean_8 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand')].well\n",
    "well_clean_10 = df_khtst_bal_qcl[(df_khtst_bal_qcl.FORMATION == 'Balakhany X sand')].well\n",
    "df_collect8 = []\n",
    "for num, well_name in enumerate(dist_bal8.well[:]):\n",
    "    well_dist3 = dist_bal8[dist_bal8.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany VIII sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect8.append(result)\n",
    "df_well_kh_dist8 = pd.concat(df_collect8).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal8 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany VIII sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal8 = df_well_kh_dist8.set_index('well').join(df_khtst_xy_bal8.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal8_fld = df_well_kh_dist_bal8_fld[(df_well_kh_dist_bal8_fld.well.isin(well_clean_8)) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal8_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_collect10 = []\n",
    "for num, well_name in enumerate(dist_bal10.well):\n",
    "    well_dist3 = dist_bal10[dist_bal10.well == well_name].T[1:].sort_values(by=num)[1:4].reset_index()\n",
    "    well_dist3_res = well_dist3.T[1:].reset_index().drop('index', axis=1)\n",
    "    well_dist3_res.columns =['dist1', 'dist2', 'dist3']\n",
    "    well_kh3 = df_khtst[(df_khtst.well.isin(list(well_dist3['index']))) & \n",
    "                        (df_khtst_xy.FORMATION == 'Balakhany X sand')]['KHtst'].reset_index()\n",
    "    well_kh3 = well_kh3.T\n",
    "    well_kh3_res = well_kh3.reset_index()[1:].drop('index', axis=1).reset_index().drop('index', axis=1)\n",
    "    well_kh3_res.columns =['kh1', 'kh2', 'kh3']\n",
    "    concat_df = pd.concat([well_dist3_res, well_kh3_res], axis=1)\n",
    "    result = concat_df.join(pd.DataFrame([well_name], columns=['well']))\n",
    "    df_collect10.append(result)\n",
    "df_well_kh_dist10 = pd.concat(df_collect10).reset_index().drop('index', axis=1)\n",
    "df_khtst_xy_bal10 = df_khtst_xy[df_khtst_xy.FORMATION=='Balakhany X sand'][['well', 'FORMATION', 'KHtst']]\n",
    "df_well_kh_dist_bal10 = df_well_kh_dist10.set_index('well').join(df_khtst_xy_bal10.set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10.set_index('well').join(metadata[['well','field']].set_index('well')).reset_index()\n",
    "df_well_kh_dist_bal10_fld = df_well_kh_dist_bal10_fld[(df_well_kh_dist_bal10_fld.well.isin(well_clean_10)) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh1>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh2>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.kh3>0) &\n",
    "                                                    (df_well_kh_dist_bal10_fld.KHtst > 0)].reset_index().drop('index', axis=1)\n",
    "df_well_kh_dist_all = pd.concat([df_well_kh_dist_bal8_fld, df_well_kh_dist_bal10_fld])\n",
    "#Calculation of TST-thickness Balakhany VIII & X\n",
    "df_fu_tst = df_prq[(df_prq.FORMATION.str.contains('Balakhany VIII')) | (df_prq.FORMATION.str.contains('Balakhany X'))]\n",
    "df_fu_tst = df_fu_tst[['well', 'DEPTH','FORMATION','TST']]\n",
    "df_fu_tst_top = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[0]).reset_index()\n",
    "df_fu_tst_top.rename(columns={'TST':'TST_top'}, inplace=True)\n",
    "df_fu_tst_bot = df_fu_tst.groupby(['well','FORMATION'])['TST'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "df_fu_tst_bot.rename(columns={'TST':'TST_bot'}, inplace=True)\n",
    "df_fu_tst_final = df_fu_tst_top.set_index(['well','FORMATION']).join(df_fu_tst_bot.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final['TST_interv'] = round((df_fu_tst_final.TST_bot - df_fu_tst_final.TST_top),0)\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well','FORMATION']).join(xy_coord.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index(['well', 'FORMATION']).join(df_prq_tvdss.set_index(['well','FORMATION'])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final.set_index('well').join(df_prq.groupby('well')['field'].apply(lambda x: x.iloc[0])).reset_index()\n",
    "df_fu_tst_final = df_fu_tst_final[(df_fu_tst_final.TST_interv > 0)]\n",
    "#Reading df_prq_htst_avgprop_v1 and getting outliers\n",
    "path = 'C:\\\\jupyter\\\\SPP\\\\inputoutput\\\\' \n",
    "df_htst_avgprop = pd.read_csv(path + 'df_prq_htst_avgprop_v1.csv')\n",
    "well_no_outliers8 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany VIII sand'].well.unique()\n",
    "well_no_outliers10 = df_khtst_bal_qcl[df_khtst_bal_qcl.FORMATION == 'Balakhany X sand'].well.unique()\n",
    "#Preparation weighted average df_htst_avgprop-dataset\n",
    "cutoff_h_tst = 0.5\n",
    "cutoff_perm_avg = 5\n",
    "#Applying filtration to dataset with cutoffs\n",
    "df_htst_avgprop_nz = df_htst_avgprop[(df_htst_avgprop.h_tst > cutoff_h_tst) & (df_htst_avgprop.md_perm_avg > cutoff_perm_avg)]\n",
    "#Multiplaying htst by resprop values\n",
    "df_htst_avgprop_nz['kavg_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_perm_avg\n",
    "df_htst_avgprop_nz['phit_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_phit_avg\n",
    "df_htst_avgprop_nz['vsh_htst'] = df_htst_avgprop_nz.h_tst * df_htst_avgprop_nz.md_vsh_avg\n",
    "#Summarizing h_tst via well & formation\n",
    "df_htst_fm = df_htst_avgprop_nz.groupby(['well','FORMATION'])['h_tst'].sum().reset_index()\n",
    "df_htst_fm.rename(columns={'h_tst':'gross_tst'}, inplace=True)\n",
    "#Calculating weighted averages\n",
    "df_htst_avgprop_nz_avgpropsum = df_htst_avgprop_nz.groupby(['well','FORMATION'])[['phit_htst','vsh_htst']].sum().reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join = df_htst_avgprop_nz_avgpropsum.set_index(\n",
    "                                     ['well','FORMATION']).join(df_htst_fm.set_index(['well','FORMATION'])).reset_index()\n",
    "df_htst_avgprop_nz_avgpropsum_join['phit_wavg'] = df_htst_avgprop_nz_avgpropsum_join.phit_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_htst_avgprop_nz_avgpropsum_join['vsh_wavg'] = df_htst_avgprop_nz_avgpropsum_join.vsh_htst / df_htst_avgprop_nz_avgpropsum_join.gross_tst\n",
    "df_8bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany VIII sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_8bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany VIII sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_8bal_phhpv = df_8bal_hpv.set_index(['well','FORMATION']).join(df_8bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_hpv = df_htst_avgprop_nz_avgpropsum_join[\n",
    "              df_htst_avgprop_nz_avgpropsum_join.FORMATION == 'Balakhany X sand'][['well','FORMATION','gross_tst','phit_wavg','vsh_wavg']]\n",
    "df_10bal_permh = df_htst_avgprop_nz[df_htst_avgprop_nz.FORMATION == 'Balakhany X sand'].groupby(['well','FORMATION'])['kavg_htst'].sum().reset_index()\n",
    "df_10bal_phhpv = df_10bal_hpv.set_index(['well','FORMATION']).join(df_10bal_permh.set_index(['well','FORMATION'])).reset_index()\n",
    "# #Preparing x,y matrices for ML\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_8bal_phhpv_tstint = df_8bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_8bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop8_final_wa = df_8bal_phhpv_tstint.copy()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv.set_index(['well','FORMATION']).join(df_fu_tst_final.set_index(['well','FORMATION'])).reset_index()\n",
    "df_10bal_phhpv_tstint = df_10bal_phhpv_tstint[['well', 'FORMATION', 'X', 'Y', 'DEPTH', 'TVD_SCS', 'field', 'gross_tst',\n",
    "                                             'TST_interv', 'kavg_htst', 'phit_wavg', 'vsh_wavg']]\n",
    "df_10bal_phhpv_tstint.rename(columns={'TST_interv':'interv_tst'}, inplace=True)\n",
    "df_avgprop10_final_wa = df_10bal_phhpv_tstint.copy()\n",
    "#Selecting data for Bal8 & Bal10 \n",
    "df_avgprop_bal10_wa = df_avgprop10_final_wa[df_avgprop10_final_wa.FORMATION.str.contains('Balakhany X sand') & \n",
    "                                          df_avgprop10_final_wa.well.isin(well_no_outliers10)]\n",
    "df_avgprop_bal8_wa = df_avgprop8_final_wa[df_avgprop8_final_wa.FORMATION.str.contains('Balakhany VIII sand') & \n",
    "                                          df_avgprop8_final_wa.well.isin(well_no_outliers8)]\n",
    "df_avgprop_bal_wa = pd.concat([df_avgprop_bal8_wa, df_avgprop_bal10_wa])\n",
    "# For Shahriyar\n",
    "df_dist_kh_bal_shahriayr =  df_avgprop_bal_wa.set_index(['well','FORMATION']).join(\n",
    "                            df_well_kh_dist_all.drop('field',axis=1).set_index(['well','FORMATION'])\n",
    "                            ).reset_index()\n",
    "#rotate x,y around xo,yo by theta (rad)\n",
    "def rotate(x,y): \n",
    "    theta = (math.pi/180)*34\n",
    "    xo = st.median(np.array(df_khtst_xy['X'].to_list()))\n",
    "    yo = st.median(np.array(df_khtst_xy['Y'].to_list()))\n",
    "    xr = math.cos(theta)*(x-xo)-math.sin(theta)*(y-yo) + xo\n",
    "    yr = math.sin(theta)*(x-xo)+math.cos(theta)*(y-yo) + yo\n",
    "    return [xr,yr]\n",
    "df_dist_kh_bal_shahriayr[['X_new', 'Y_new']] = df_dist_kh_bal_shahriayr.apply(lambda row: rotate(row['X'], row['Y']), axis=1, result_type='expand')\n",
    "df_dist_kh_bal_shahriayr_final = df_dist_kh_bal_shahriayr[[ 'well','FORMATION', 'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', \n",
    "                                                            'interv_tst','gross_tst','kavg_htst' ]]\n",
    "df_dist_kh_bal_shahriayr_final = pd.get_dummies(df_dist_kh_bal_shahriayr_final, columns = ['FORMATION'])\n",
    "df_dist_kh_bal_shahriayr_final = df_dist_kh_bal_shahriayr_final[(df_dist_kh_bal_shahriayr_final.TVD_SCS.notna()) &\n",
    "                                                                (df_dist_kh_bal_shahriayr_final.kh1.notna())]\n",
    "# df_dist_kh_bal_shahriayr_final.to_csv('df_dist_kh_bal_shahriayr_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70/30 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train/x_test data splitting\n",
    "y = np.array(df_dist_kh_bal_shahriayr_final[[   'well','kavg_htst']])\n",
    "x = np.array(df_dist_kh_bal_shahriayr_final[[   'well','X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst',\n",
    "                                                'gross_tst', 'kavg_htst', 'FORMATION_Balakhany VIII sand',\n",
    "                                                'FORMATION_Balakhany X sand']])\n",
    "num = random.randint(0,100)\n",
    "print('num', num)\n",
    "x_train_init, x_test_init, y_train_init, y_test_init = train_test_split(x, y, test_size=0.3, random_state=num)\n",
    "# Taking well names from train/test datasets\n",
    "y_train_wells = y_train_init[:,0]\n",
    "y_test_wells = y_test_init[:,0]\n",
    "x_train = x_train_init[:,1:]\n",
    "x_test = x_test_init[:,1:]\n",
    "y_train = y_train_init[:,1]\n",
    "y_test = y_test_init[:,1]\n",
    "# GridSearch for ML-model\n",
    "svr_gr_sr = SVR()\n",
    "grid_param_SVR = {'kernel' : (['rbf']),\n",
    "                  'C' : [10, 100, 500, 1000, 2000, 3000],\n",
    "                  'gamma':[0.005, 0.01, 0.5],\n",
    "                  'epsilon': [0.001,0.01, 1, 5]}\n",
    "scorer = make_scorer(mae, greater_is_better=False)\n",
    "gd_sr_SVR = GridSearchCV(estimator = svr_gr_sr, param_grid = grid_param_SVR, scoring=scorer, cv = 15)\n",
    "gd_sr_SVR.fit(x_train, y_train)\n",
    "GS_setting = gd_sr_SVR.best_params_\n",
    "print(GS_setting)\n",
    "# Applying Pipeline for ML-model\n",
    "svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR(kernel = 'rbf', C=GS_setting['C'], \n",
    "                                                       gamma = GS_setting['gamma'], epsilon=GS_setting['epsilon']))])\n",
    "svr.fit(x_train, y_train)\n",
    "y_pred_train = svr.predict(x_train)\n",
    "y_pred_test = svr.predict(x_test)\n",
    "print('---------------------')\n",
    "print('r2_train', r2(y_train, y_pred_train).round(2), 'x_train', x_train.shape)\n",
    "print('r2_test', r2(y_test, y_pred_test).round(2), 'x_test', x_test.shape)\n",
    "print('mae_train', mae(y_train, y_pred_train).round(0))\n",
    "print('mae_test', mae(y_test, y_pred_test).round(0))\n",
    "# QC of predicted values for train & test datasets\n",
    "df_svr_train = pd.DataFrame(zip(y_train_wells, y_train, y_pred_train), columns=['well', 'actual','predict'])\n",
    "df_svr_train['l_limit'] = df_svr_train.actual*0.75\n",
    "df_svr_train['h_limit'] = df_svr_train.actual*1.25\n",
    "df_svr_train['qc'] = 'out'\n",
    "df_svr_train.loc[(df_svr_train.predict >= df_svr_train.l_limit) & (df_svr_train.predict <= df_svr_train.h_limit), 'qc'] = 'in'\n",
    "df_svr_test = pd.DataFrame(zip(y_test_wells, y_test, y_pred_test), columns=['well', 'actual','predict'])\n",
    "df_svr_test['l_limit'] = df_svr_test.actual*0.75\n",
    "df_svr_test['h_limit'] = df_svr_test.actual*1.25\n",
    "df_svr_test['qc'] = 'out'\n",
    "df_svr_test.loc[(df_svr_test.predict >= df_svr_test.l_limit) & (df_svr_test.predict <= df_svr_test.h_limit), 'qc'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting of the loop \n",
    "y_test_lst = []\n",
    "y_pred_test_lst = []\n",
    "well_exclude_lst = []\n",
    "gs_settings_lst = []\n",
    "metrics_r2_mae_lst = []\n",
    "df_dist_kh_bal_shahriayr_svr = df_dist_kh_bal_shahriayr_final.sample(frac = 1).reset_index().drop('index', axis=1)\n",
    "for i in tqdm(range(len(df_dist_kh_bal_shahriayr_svr))):\n",
    "    #Making up the feature and target datasets\n",
    "    df_wo_well = df_dist_kh_bal_shahriayr_svr.drop([i])\n",
    "    well_exclude = df_dist_kh_bal_shahriayr_svr.iloc[i]['well']\n",
    "    well_exclude_lst.append(well_exclude)\n",
    "    y_train = np.array(df_wo_well['kavg_htst'])\n",
    "    x_train = np.array(df_wo_well[[ 'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst','gross_tst', \n",
    "                                    'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand']])\n",
    "    well_train = np.array(df_wo_well['well'])\n",
    "    y_test = np.array(df_dist_kh_bal_shahriayr_svr.iloc[i]['kavg_htst'])\n",
    "    y_test_lst.append(y_test)\n",
    "    x_test = np.array(df_dist_kh_bal_shahriayr_svr.iloc[i][[    'X_new', 'Y_new', 'TVD_SCS', 'kh1', 'kh2', 'kh3', 'interv_tst','gross_tst', \n",
    "                                                                'FORMATION_Balakhany VIII sand', 'FORMATION_Balakhany X sand']])\n",
    "    # GridSearch for ML-model\n",
    "    # {'C': 500, 'epsilon': 0.001, 'gamma': 0.005, 'kernel': 'rbf'}\n",
    "    grid_param_SVR = {  'C' : [500],\n",
    "                        'epsilon': [0.01],\n",
    "                        'gamma':[0.005],\n",
    "                        'kernel' : (['rbf'])}\n",
    "    GS_setting = grid_param_SVR\n",
    "    gs_settings_lst.append((GS_setting['kernel'],GS_setting['C'],GS_setting['gamma'], GS_setting['epsilon']))\n",
    "    # Statement of ML-model\n",
    "    svr = Pipeline([(\"scaler\",StandardScaler()),(\"svr\",SVR( kernel = GS_setting['kernel'][0], \n",
    "                                                            C = GS_setting['C'][0],\n",
    "                                                            gamma = GS_setting['gamma'][0], \n",
    "                                                            epsilon = GS_setting['epsilon'][0]))])\n",
    "    # Fitting the ML-model\n",
    "    svr.fit(x_train, y_train)\n",
    "    y_pred_train = svr.predict(x_train)\n",
    "    y_pred_test = svr.predict([x_test])\n",
    "    y_pred_test_lst.append(y_pred_test[0])\n",
    "    # Metrics computation for the ML-model\n",
    "    r2_train = r2(y_train, y_pred_train).round(2)\n",
    "    mae_train = mae(y_train, y_pred_train)\n",
    "    metrics_r2_mae_lst.append((r2_train, mae_train.round(0)))\n",
    "# Building up of dataframe\n",
    "res_svr_sha = pd.DataFrame( zip(y_test_lst,y_pred_test_lst,well_exclude_lst, gs_settings_lst), \n",
    "                        columns = ['test','predict','well', 'gs_setting',])\n",
    "res_svr_sha['l_test'] = res_svr_sha.test*0.75\n",
    "res_svr_sha['h_test'] = res_svr_sha.test*1.25\n",
    "res_svr_sha['qc'] = 'out'\n",
    "res_svr_sha.loc[(res_svr_sha.predict >= res_svr_sha.l_test) & (res_svr_sha.predict <= res_svr_sha.h_test), 'qc'] = 'in'\n",
    "print('wells total:', res_svr_sha.shape[0])\n",
    "print('wells unpredicted:', res_svr_sha['qc'].value_counts()['out'], (res_svr_sha['qc'].value_counts()['out']/res_svr_sha.shape[0]).round(3), 'v/v')\n",
    "print('wells predicted:', res_svr_sha['qc'].value_counts()['in'], (res_svr_sha['qc'].value_counts()['in']/res_svr_sha.shape[0]).round(3), 'v/v')\n",
    "mae_df_xy = mae(res_svr_sha.test, res_svr_sha.predict).round(0)\n",
    "r2_df_xy = r2(res_svr_sha.test, res_svr_sha.predict).round(2)\n",
    "print('mae:', mae_df_xy, 'mDm')\n",
    "print('r2:', r2_df_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making up the final x-plot\n",
    "max_val = 14000\n",
    "fig1_ml = px.scatter(res_svr_sha, x='test', y='predict', \n",
    "                     color='qc', \n",
    "                     hover_data=['well'], \n",
    "                     width=400, height=400,\n",
    "                     color_discrete_sequence=[\"red\", \"green\"])\n",
    "fig1_ml.update_traces(marker=dict(size=10,opacity=0.75,line=dict(color='rgb(47, 57, 61)', width=1)))\n",
    "fig2_ml=px.line(x=[0,max_val], y=[0,max_val])\n",
    "fig2_1_ml=px.line(x=[0,max_val], y=[0,max_val*1.25])\n",
    "fig2_2_ml=px.line(x=[0,max_val], y=[0,max_val*0.75])\n",
    "fig2_ml.update_traces(line=dict(color = 'blue'))\n",
    "fig2_1_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig2_2_ml.update_traces(line=dict(color = 'blue', dash='dash'))\n",
    "fig3_ml = go.Figure(data = fig1_ml.data + fig2_ml.data + fig2_1_ml.data + fig2_2_ml.data)\n",
    "fig3_ml.update_layout(title = 'Comparison Actual vs Pred Shahriyar SVR',width=600,height=400, xaxis_title='test', yaxis_title='predict',\n",
    "                      margin=dict(l=10,r=10,b=10,t=40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
